---
layout:     post
title:      Game Theory 笔记
subtitle:   Osborne的博弈论经典
date:       2020-04-18 12:00:00
author:     "tengshiquan"
header-img: "img/post-bg-dice.jpg"
catalog: true
tags:

    - AI
    - Game Theory

---


# An Introduction to Game Theory

"An Introduction to Game Theory"比"A Course in Game Theory" 那本数学上简单



#### 总体结构

<img src="/img/2020-04-18-Game.assets/image-20200505013213150.png" alt="image-20200505013213150" style="zoom:50%;" />



### 1	引论

#### 1.1 何为博弈论？

博弈论旨在帮助找们理解决策者互动的情形。



#### 1.2 理性选择理论 The theory of rational choice

##### 1.2.1 Actions

##### 1.2.2 Preferences and payoff functions

如何描述决策者的**偏好preferences** 呢 ：  **收益函数 payoff function**

payoff function $u$ represents a decision-maker's preferences if, for any actions $a$ in $A$ and $b$ in $A$ ，
$u(a)>u(b)$ if and only if the decision-maker prefers $a$ to $b$.

这里所使用的决策者偏好从某种意义上来说，仅传递了**次序ordinal** 方面的信息。例如，它能告诉我们，决策者喜欢行动α 甚于行动b，但是它并不能告诉我们，和行动b 相比他究竟有多喜欢行动α ，或者他喜好a甚于b 的程度是否"多于"他喜好b 甚于c 的程度。因此，描述决策者偏好的盈利函数仅仅传递了次序的信息。

那么， 很自然想到能不能用数值函数把喜欢的程度表示出来呢 ?  例如，  $u(a)=0, u(b)=1, u(c)=100,$ 那么决策者喜欢 $c$ 远远胜过喜欢 $b$,而对于 $a$ 和 $b$ 之间的差别则不大。
结论是**不能**！！盈利函数并不包涵这些信息！我们从 $u(a)=$ $0, u(b)=1, u(c)=100$ 中得出的唯一结论是,决策者喜欢 $c$ 甚于 $b$ 更甚于 $a$ 。 如果用盈利函数 $v$ 来描述他的喜好,其中 $v(a)=0, v(b)=100, v(c)=101$, 这两个函数是一样的。或者说,任何满足 $w(a)<w(b)<w(c)$ 的其他函数 $w$ 也都是一样的。

从上述讨论中我们可以看到，决策者的偏好可出用各种不同的盈利函数来描述。



##### 1.2.3 The theory of rational choice  理性选择理论

在任何给定情况下，决策者根据自己的偏好好，从A 的可选子集中挑选出最好的方案。在允许存在多个同样吸引
人的最优方案的情况下，理性选择理论定义如下：
**依据决策者的偏好，其所选行动至少如其他可选的行动一样好。 the action chosen by a decision-maker is at least as good, according to her preferences, as every other available action.**

此理论是有其局限性的， 因为现实中很多时候，人们会冲动不理性。



## Part I:  Games with Perfect Information 完全信息博弈

### 2	Nash Equilibrium 纳什均衡：理论  

#### 2.1 Strategic games 策略型博弈 

概念: *players*, *actions* , *preferences* ,  
**action *profile***—the list of all the players’ actions    策略组合， 策略配置
*payoff functions* 收益函数

**DEFINITION 11.1** (*Strategic game with ordinal preferences*) A **strategic game** (with ordinal preferences) consists of

- a set of **players**  
- for each player, a set of **actions**
- for each player, **preferences** over the set of action profiles.

<mark><b>ordinal preferences 序数偏好 的博弈， 即代表着 所采用的策略是纯策略。</b></mark>

请记住，这些payoff只有**序数**意义 ***ordinal* significance**。例如，如果一个玩家对a、b和c这三个动作的payoff分别为1、2和10，我们唯一能得出的结论是，玩家更喜欢c而不是b，b更喜欢a；这些数字并不意味着玩家在c和b之间的偏好比他在a和b之间的偏好更强。

**模型中没有时间的概念。** 它的想法是，每个玩家选择自己的行动是一锤定音 once and for all的，而玩家们选择自己的行动是 "**同时 simultaneously**"进行的。 因此，策略游戏有时被称为 "**同时行动游戏**"。
然而，一个行动可能涉及到的活动会随着时间的推移而延长，并可能考虑了很多的突发事件。例如，一个行动可以规定，"如果X公司的股票跌到10美元以下，买入100股；否则，不要买入任何股票"。(因此，一个行动有时被称为 "**策略strategy**"。)     **action 为什么应该叫做  strategy !!**

模型中没有时间这一事实意味着，当把一个状况作为一个策略博弈case来分析时，我们可以从可能出现的复杂问题(如果允许玩家随着事件的发展而改变他的计划)中抽离出来：我们假设actions are chosen once and for all。 
如果按照 Strategic games 建模， 则各方的策略是一开始就定好了的。



#### 2.2 例：囚徒困境 the Prisoner’s Dilemma

最著名的策略博弈之一是 "囚徒困境" ;  收益矩阵

![image-20201201155437426](/img/2020-04-18-Game.assets/image-20201201155437426.png) 

从左边横着看过去的是P1的action， 从上面横着看下来的是P2的action

|        | 沉默 | *坦白* |
| :---: | :--: | :--: |
|  沉默  | 2,2  |  0,3   |
| *坦白* | 3,0  |  1,1   |

**囚徒困境主要适用于 合作是有益的, 但每个玩家都有投机取巧的动机.** 



##### 2.2.1 Working on a joint project  一起工作

大家都偏好偷懒，虽然厌恶项目失败，但更厌恶自己努力别人偷懒。 收益矩阵跟囚徒困境一样

你正在和朋友一起做一个联合项目。你们可以选择努力工作，也可以选择 "傻乐"。如果你的朋友努力工作，那么你更喜欢 "傻乎乎"（如果你也努力工作，项目的结果会更好，但对你来说，项目的价值增量并不值得额外的努力）。你更喜欢你们两个人都努力工作的结果，而不是你们两个人都傻乎乎的结果（在这种情况下，什么都没有完成），对你来说，最坏的结果是你努力工作，而你的朋友傻乎乎的结果（你讨厌被 "利用"）。如果你的朋友也有同样的偏好，那么你所面临的情况的游戏模型如图14.1所示，正如你所看到的，它与 "囚徒困境 "只是在行动的名称上有所不同. 



##### 2.2.2 Duopoly  双寡头垄断

在一个简单的二元垄断模型中，两家公司生产同样的产品。每家公司都希望获得尽可能高的利润。如果两家公司都选择高价，那么每家公司的利润为1000美元。如果一家公司选择高价，另一家公司选择低价，那么选择高价的公司没有顾客，亏损200美元，而选择低价的公司则赚取1200美元的利润（单位利润很低，但销量很高）。如果两家公司都选择Low，那么每家公司的利润为600美元。每个公司只关心自己的利润，所以我们可以用它所获得的利润来表示它的偏好，得出图14.2中的博弈。

![image-20201210212512767](/img/2020-04-18-Game.assets/image-20201210212512767.png)



##### 2.2.3 The arms race 军备竞赛



##### 2.2.4 Common property 公共财产



#### 2.3 例：欣赏巴赫音乐还是斯特拉文斯音乐？ BoS

这个例子中，玩家们一致认为合作比不合作好，但对最佳结果有不同意见。 例如两个政党制定政策.

这个在现实中比较多见， 大家意见不同，但目标统一后都会去执行。 



![image-20201210212437764](/img/2020-04-18-Game.assets/image-20201210212437764.png)





#### 2.4 例：抛掷硬币打赌  Matching Pennies

两个人同时出示硬币的正面或反。如果出示相同的一面，那么P2 向P1 付1 美元， 否则P1向P2付。

这个例子是 纯粹的冲突性博弈, 玩家的收益是相反的.   **strictly competitive 严格竞争**   

**zero-sum  零和博弈**  u1+ u2= 0



![image-20201210212557794](/img/2020-04-18-Game.assets/image-20201210212557794.png)





#### 2.5 例：猎鹿  the Stag Hunt

一群猎人中的每个人都有两个选择：可以继续专心致志地去追捕一只雄鹿，也可以去抓一只野兔。如果所有的猎人都去追赶雄鹿，那么他们就会抓到雄鹿并平分；如果任何一个猎人把精力放在抓野兔上，那么雄鹿就会逃跑，而野兔就属于叛变的猎人一个人。每一个猎人都喜欢分得部分雄鹿，而不是一只野兔。

2个猎人的情况

|      |  鹿  | 兔子 |
| :--: | :--: | :--: |
|  鹿  | 2,2  | 0,1  |
| 兔子 | 1,0  | 1,1  |





#### 2.6 纳什均衡

在策略型博弈中, 怎么选择行动呢? 

理性决策者理论, 假定每一个玩家选择最优的可行性行动。  

在博弈中, 一般来说,任何已知玩家的最优行动依赖于其他玩家的行动。因此,在 选择行动时,玩家必须考虑到其他玩家将采取的行动。  
这也就是说, 必须对其他玩家的行动形成一个“**信念 belief**”。 在什么样的基础上可以形成这样的信念呢？在本章和下面两章的分析中所隐含的假设是,每个玩家的信念来自于他过去参与博奕的经验,这个经验充分广泛,他知道他的对手将如何行动。没有一个人会告诉他有关对手将选择的行动,可是他凭借以往的博弈经验,对这些行动有所把握。  **经验 to 信念**  

虽然我们假设每个玩家有参与博弈的经验,我们还是要假设他会孤立地考虑每一次博弈。他不熟悉特定对手的习性,因而不会将自己的行动受缚于他的对手;也不会指望自己当前的行动会影响其他玩家将来的行动。

A ***Nash equilibrium*** is an **action profile** $a^∗$ with the property that no player $i$ can do better by choosing an action different from $a^∗_i$ , given that every other player $j$ adheres to $a^∗_j$ .

在理想化的情况下，在任何给定博弈中的玩家都是从一组人群中随机抽取的，**纳什均衡对应于稳定状态*steady state***。无论何时博弈开始时，行动组合是相同的纳什均衡$a^∗$，那么没有任何玩家有理由选择与他的分量$a^∗$不同的行动. 
换个说法，**纳什均衡体现了一个稳定的 "社会规范 social norm"**：如果其他人都遵守这个规范，没有人愿意偏离这个规范。

纳什均衡理论的第二部分玩家关于互相行动的信念是正确的一一意味着，两个玩家关于第三个玩家行为的信念是相同的。出于这个理由，有时候这个条件被称为要求玩家的"预期是一致的"。

我们希望应用纳什均衡理论的情况，通常并不恰好对应于**理想化模型**。例如，在某些情况下，玩家没有太多博弈经验;在另一些情况下，他们并不是孤立地看待每次博弈。
在任何给定的情况中，纳什均衡概念是否适用是需要判断的。**有些情况与理想化模型拟合得很差**，这可以通过别的考虑而得到缓解。例如，一个缺乏经验的玩家可能通过他们在其他场合的经验或从别的渠道对他们对手的可能行为得出结论。 最终，纳什均衡概念适用性的检验是，它是否能让我们洞察手头的问题。



符号表示：  
令 $a$ 是一个action组合,其中每个玩家 $i$ 的行动是 $a_{i}$ , 令 $a_{i}^{\prime}$ 是玩家 $i$ 的任意行动 （要么等于 $a_{i},$ 要么不等于 $a_{i}$ ) 。  
那么 $\left(a_{i}^{\prime}, a_{-i}\right)$ 表示这样的action组合,其中除 了玩家 $i$ 之外,每一个玩家 $j$ 选取由 $a$ 所确定的他的行动 $a_{j},$ 而玩家 $i$ 则选 $a_{i}^{\prime} $  （下标$-i$ 表示“除 $i$ 以外”)。  
这就是说 $\left(a_{i}^{\prime}, a_{-i}\right)$ : 除了 $i$ 之外,所有玩家坚持 $a,$ 而 $i$ 则“偏离”到 $a_{i}^{\prime}$ 。 (如果 $a_{i}^{\prime}=a_{i},$ 那 么当然有 $\left(a_{i}^{\prime}, a_{-i}\right)=\left(a_{i}^{\prime}, a_{-i}\right)=a$ ) 

例如,假设有三个玩家,那么 $\left(a_{2}^{\prime}, a_{-2}\right)$ : P1 和玩家 3 坚持采取 $a$ (P1 选择 $a_{1},$ 3 选择 $a_{3}$ ) , 而玩家2 偏离到 $a_{2}^{\prime}$ 。 



**DEFINITION 21.1** (**Nash equilibrium of strategic game with ordinal preferences**) 

The action profile $$a^{*}$$ in a strategic game with ordinal preferences is a **Nash equilibrium** if, for every player $$i$$ and every action $$a_{i}$$ of player $$i$$ ,    $$a^{*}$$ is at least as good according to player $$i$$ 's preferences as the action profile $$\left(a_{i}, a_{-i}^{*}\right)$$ in which player $$i$$ chooses $$a_{i}$$ while every other player $$j$$ chooses $$a_{j}^{*} .$$ Equivalently, for every player $$i$$,  
$$u_{i}\left(a^{*}\right) \geq u_{i}\left(a_{i}, a_{-i}^{*}\right)$$ for every action $$a_{i}$$ of player $$i$$ ,  
where $$u_{i}$$ is a payoff function that represents player $$i$$ 's preferences.

**纳什均衡** :  $$u_{i}\left(a^{*}\right) \geq u_{i}\left(a_{i}, a_{-i}^{*}\right)$$

纳什均衡就是一个点(也可能是区域), 达到这个稳态后, 任何人自己私自偏离,都会有导致自己收益减少.   

**这个定义既不意味着一个策略博弈一定有纳什均衡，也不意味着它最多有一个纳什均衡。**   纯策略均衡可能不存在。



#### 2.7 纳什均衡例题

##### 2.7.1 Prisoner’s Dilemma

|        | 沉默 | *坦白* |
| :----: | :--: | :----: |
|  沉默  | 2,2  |  0,3   |
| *坦白* | 3,0  |  1,1   |

(*Fink*, *Fink*) is the unique Nash equilibrium.

(告密，沉默) 不满，因为当P1 选择"告密"时，P2 选择"告密"的盈利超过选择"玩默"的盈利,  (沉默,沉默)每个人都有动机偏离.   

当一个人选择坦白, 追求自己的高收益的时候, 需要一个人沉默, 而另外一个也会选择该前提下自己的高收益, 这时会造成前一个人高收益落空.





##### 2.7.2 BoS

two Nash equilibria: (*Bach*, *Bach*) and (*Stravinsky*, *Stravinsky*) 



##### 2.7.3 Matching Pennies

**该问题没有纳什均衡（没有纯策略的纳什均衡）**;  即每个玩家都用确定策略来玩,其中一个玩家如果输了,则改变其策略肯定能获利



##### 2.7.4 The Stag Hunt

two Nash equilibria: (*Stag*, *Stag*) and (*Hare*, *Hare*)



##### 2.7.6 A coordination game  协调博弈

|              |  *Bach*   | *Stravinsky* |
| :----------: | :-------: | :----------: |
|    *Bach*    | 2, 2 | 0,0 |
| *Stravinsky* |    0,0    |     1,1      |



##### 2.7.7 Provision of a public good  公共商品供给



##### 2.7.8 Strict and nonstrict equilibria 严格均衡

在我们迄今所研究的所有纳什均衡的博弈中，玩家的偏离导致的结果比均衡结果**更差**。然而，纳什均衡的定义(21.1)只要求**偏离的结果不比均衡结果好 no better, 不一定需要更差 worse**. 而且，事实上，有些博弈中的平衡状态是，鉴于其他博弈者的行动，玩家在他的平衡行动和其他的行动之间无动于衷。 

<B><mark>自己与对方都在均衡点，自己偏离了，收益不会下降的情况， 叫 非严格均衡 </mark></B>

考虑图31.1中的博弈。这个博弈有一个独特的纳什均衡，即（T，L）。(对于其他每一对行动，其中一个玩家的行动最好是改变他的行动)。当玩家2选择了L，就像他在这个均衡中一样，P1选择T或B是同样快乐的；如果他偏离了B，那么他的情况并不比他在均衡中的情况更糟。我们说，纳什均衡（T，L）不是一个**严格均衡*strict equilibrium***。

|      |  L   |  M   |  R   |
| :--: | :--: | :--: | :--: |
|  T   | 1,1  | 1,0  | 0,1  |
|  B   | 1,0  | 0,1  | 1,0  |

对于一个一般博弈，如果每个玩家的均衡行动都比该玩家其他的行动好，那么这个**均衡是严格**的。  
an action profile $$a^{*}$$ is a **strict Nash equilibrium**  if   
for every player $i$ we have $$u_{i}\left(a^{*}\right)>  u_{i}\left(a_{i}, a_{-i}^{*}\right)$$   
for every action $$a_{i} \neq a_{i}^{*}$$ of player $i$.     
看定义， 是在一个均衡点， 对方仍然采用均衡策略，自己偏移，然后收益下降，叫 严格均衡。

显然， 严格均衡点类似于山峰， 整个山脉但不一定只有一个， 但是平顶或者一条平线就不是严格均衡。



#### 2.8 <mark><b>best response function 最优反应函数,  最佳应对, 占优策略</b></mark>

##### 2.8.1 Definition

Precisely, we define the function $$B_{i}$$ by

$$
B_{i}\left(a_{-i}\right)=\left\{a_{i} \text { in } A_{i}: u_{i}\left(a_{i}, a_{-i}\right) \geq u_{i}\left(a_{i}^{\prime}, a_{-i}\right) \text { for all } a_{i}^{\prime} \text { in } A_{i}\right\}:
$$

any action in $$B_{i}\left(a_{-i}\right)$$ is at least as good for player $$i$$ as every other action of player $$i$$ when the other players' actions are given by $$a_{-i}$$. We call $$B_{i}$$ the **best response function** of player $$i$$ . 

该函数返回, **给定其他人动作的情况下, 玩家i能获得最大回报的那些动作的集合. 显然该函数与其他人的动作策略相关**.   

纳什均衡在这个Br集合里面.



##### 2.8.2 Using best response functions to define Nash equilibrium   用最优应对函数定义均衡

将**纳什均衡定义为**：<mark><B>每个玩家的行动都是对其他玩家行动的最佳反应</B></mark>。  

**纯均衡策略,是对其他人的每个action的最优反应的子集.   如果一个action不是最优反应,那么肯定不可能属于纯策略纳什均衡.**

 

**PROPOSITION 34.1** The action profile a* is a **Nash equilibrium** of a strategic game with ordinal preferences if and only if every player's action is a **best response** to the other players' actions:  
$$
a_{i}^{*} \text{ is in }B_{i}\left(a_{-i}^{*}\right) \text{ for every player }i \tag{34.2}
$$

B这里指Best的集合.



若每个玩家都只有一个最优反应的情况 , 可以简化改写为:  for each player $i$ and each list $a_{-i}$ of the other players' actions, denote the single member of $$B_{i}\left(a_{-i}\right)$$ by $$b_{i}\left(a_{-i}\right)$$ (that is, $$B_{i}\left(a_{-i}\right)=\left\{b_{i}\left(a_{-i}\right)\right\}$$ ). Then (34.2) is equivalent to 
$$
 a_{i}^{*}=b_{i}\left(a_{-i}^{*}\right) \text{ for every player }i  \tag{34.3}
$$



##### 2.8.3 Using best response functions to find Nash equilibria  使用最优反应函数寻找纳什均衡

根据最优反应函数所做的纳什均衡定义提出了一个求纳什均衡的方法：

1. 求每个人的最优反应函数
2. 再找一个action profiles满足公式 34.2 (如果B函数是单值的,则满足 34.3即可).



为了说明这个方法，考虑35.1 中的博弈；   <mark><B> ps, 姑且叫   表格星号法</B></mark>

![image-20201201204340072](/img/2020-04-18-Game.assets/image-20201201204340072.png)

首先,求P1 关于P2 的每个行动的最优反应。如果P2 选择 $L,$ 那么P1 的最优反 应是 $M$  ； 在 $(M, L)$中,P1 的盈 利上标有一个星号代表该行动为最优反应。其次,求P2 关于P1 的每个行动的最优反应（在每一行,求P2 的最高盈利) ;
最后,寻求两个玩家的盈利都被赋予星号的方格。这样的方格是纳什均衡 : 
因此,我们得出结论 : 该博弈有两个纳什均衡 : $(M, L)$ 和 $(B, R)$ 。



<mark><B> ps, 下面这个姑且叫 BR图像相交法</B></mark>    画的是BR的图像,而不是两个人收益的图像!!

下面一个例子， 求收益函数的最值，该最值是对方action的一个函数， 然后将两个玩家的画到一个图中，再求交点，就是纳什均衡。

例题37.1（协同synergistic 关系）两个人参与了一种协同关系。如果两个人都对这种关系付出更多的努力，他们都会得到更好的回报。先固定玩家j的努力，玩家i的回报随着其自身的努力先增加，然后减少。具体来说，努力水平是一个非负数，玩家i的偏好 (for $i=1,2$ ) 由报酬函数$a_{i}\left(c+a_{j}-a_{i}\right)$表示，其中$a_i$是$i$的努力水平，$a_{j}$是另一个人的努力水平，$c>0$是一个常数。

下面建模: 

- Players The two individuals.
- Actions,  set of effort levels (非负数).
- Preferences,  Player $i^{\prime}$ s preferences are represented by the payoff function $a_{i}(c+  a_{j}-a_{i} )$,  for $i=1,2$ 



特别是，每个玩家都**有无限多的动作**，所以我们不能像以前那样用表格来解决. 

为了找到博弈的纳什均衡，我们可以构造和分析玩家的最佳反应函数。给定$a_{j}$，个体$i$的报酬率是$a_{i}$的二次函数，极值点 $b_{i}\left(a_{j}\right)=\frac{1}{2}\left(c+a_{j}\right)$ , 

 最佳响应函数如图38.1所示。

<img src="/img/2020-04-18-Game.assets/image-20200505205335276.png" alt="image-20200505205335276" style="zoom:33%;" />

两条线的交点就是纳什均衡. 



在这个例题的博弈中，每个玩家对于其他玩家的每一个行动都有唯一的最优反应，所以最优反应函数呈现线状。如果一个玩家对于其他玩家的某些行动具有许多最优反应，那么他的最佳反应函数在某些点是"密集的"

图39.1所示是一对BR函数， 黑色以及阴影是Br1，灰色是Br2，它说明了一些可能性。对于P2的  $$a_{2}$$ between $$\bar{a}_{2}$$ and $$\underline{a}_{2},$$  player 1 的阴影部分都是 best responses.  例如，P1 $$a_{1}^{* *}$$ to $$a_{1}^{* * *}$$  的所有action 是 best responses to  $$a_{2}^{* * *}$$ of player2.

set of Nash equilibria consists of  $$\left(a_{1}^{*}, a_{2}^{*}\right)$$ and all the pairs of actions on player $$2^{\prime}$$ s best response function between $$\left(a_{1}^{* *}, a_{2}^{* *}\right)$$ and $$\left(a_{1}^{* * *}, a_{2}^{* * *}\right)$$  。 所以最后的均衡点是  $$\left(a_{1}^{*}, a_{2}^{*}\right)$$以及灰色线与阴影部分的交集，B2线在 $$\left(a_{1}^{* *}, a_{2}^{* *}\right)$$ 与$$\left(a_{1}^{* * *}, a_{2}^{* * *}\right)$$ 之间的部分。

![image-20201202113039161](/img/2020-04-18-Game.assets/image-20201202113039161.png)





##### 2.8.4 Illustration: contributing to a public good 例证;对公共财产局贡献





#### 2.9 Dominated actions 被支配行动, 劣行动

##### 2.9.1 Strict domination  严格支配   严优

在任何博弈中，**假如*不管其他玩家如何做*，玩家的一个行动比另一个行动总是优越(收益大于)**，那么这个行动"**严优 strictly dominates**"于另一个行动。

即某action的收益函数总是大于其他action的收益。    a1 严优于 a2， 则a2 严劣于 a1。

**DEFINITION 43.1** (**Strict domination 严优**)

In a strategic game with ordinal preferences, player $i^{\prime}$ 's action $a_{i}^{\prime \prime}$ **strictly dominates** her action $a_{i}^{\prime}$  , if  
 $u_{i}\left(a_{i}^{\prime \prime}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions,   
where $u_{i}$ is a payoff function that represents player $i$ 's preferences.

例如，在囚徒困境中，Fink的动作严格地支配着Quiet的动作：无论对手的动作如何，玩家选择Fink时的结果比选择Quiet时的结果更倾向于选择Fink的结果。另一方面，在BoS博弈中，两个动作都不能严格地支配另一个动作。如果对方选手选择巴赫，则巴赫比斯特拉文斯基好，但如果对方选手选择斯特拉文斯基，则巴赫比斯特拉文斯基差。

如果一个行动严优于行动 $a_i$，我们说 $a_i$ 是**严格被支配 strictly dominated （严劣）**行动。

**一个严劣的行动并不是对其他玩家的任何行动的最佳反应**：无论其他玩家做什么，其他一些行动都是更好的。
由于一个玩家的纳什均衡行动是对其他玩家的纳什均衡行动的最佳响应。*a strictly dominated action is not used in any Nash equilibrium.* **一个严劣行动不会用在任何纳什均衡中**.   
比如绝对大牌却fold

在寻找博弈中的纳什均衡时，我们可以将所有的**严劣**行动从考虑中**剔除**。



![image-20201201223954805](/img/2020-04-18-Game.assets/image-20201201223954805.png)

图44：只看P1的收益，  M严优于T。  对右边， B严优于M。





##### 2.9.2 Weak domination 弱支配  弱优  

**DEFINITION 45.1** (**Weak domination 弱优**) 

In a strategic game with ordinal preferences, player $i^{\prime}$ s action $a_{i}^{\prime \prime}$ weakly dominates her action $a_{i}^{\prime}$   
if   
 $u_{i}\left(a_{i}^{\prime \prime}, a_{-i}\right) \geq u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions  
and  
$u_{i}\left(a_{i}^{\prime \prime}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for some list $a_{-i}$ of the other players' actions.    

<mark><b>弱优是部分优, 部分一样， 严优是全部优；   严优是大于, 弱优是有的大于有的等于. </b></mark>



![image-20201201225306323](/img/2020-04-18-Game.assets/image-20201201225306323.png)

图45 ： M 弱优于 T， B 弱优于 M。



In a **strict** Nash equilibrium **no** player’s equilibrium action is **weakly dominated** 。  
an action be **weakly dominated**  can in a **nonstrict** Nash equilibrium。 

在**严格纳什均衡**中，**没有**一个玩家的均衡action是**弱劣**于其他action的，即 非均衡action都不会 弱优于 均衡action。  
在**非严格纳什均衡**中的均衡action**可能是弱劣** 的。    该弱劣action的均衡点可能总收益还高于弱优的均衡组合。下面这个特例。



![image-20201201225846707](/img/2020-04-18-Game.assets/image-20201201225846707.png)

图46， 双方而言（每个人，固定对方action，然后只看自己的收益）， 发现 B弱优于 >= C, C弱劣于 <=B， 但(C,C) 仍然是纳什均衡点。 同时另外一个 均衡点(B,B),  在左边博弈，二人的总体收益， (B,B)好于(C,C) ； 但在右边博弈中 (B,B) 差于(C,C)

严优，弱优， 都是 无论对手选什么action， 从自己的角度来看；但均衡策略是涉及两个人的。  
对上图左边， 若碰巧两个人都在上面左边的(C,C)， 都没有动机去改变（比如不知道 (B,B) 是可以达到的）； 但如果两个人积极一点，可能使得慢慢移到 （B,B）。  
上图右边，有点类似于 努力与偷懒。  别人努力，自己偷懒，总是期望上更好一点。



##### 2.9.3 Illustration: voting  例证 选举

##### 2.9.4 Illustration: collective decision-making  例证:共同决策



#### 2.10 Equilibrium in a single population: symmetric games and symmetric equilibria 单一群体中的均衡：对称博弈和对称均衡

大意就是, 一个群体有统一的策略.  那么来自同一个群体的玩家之间达成的平衡是什么样的. 

一个策略博弈的纳什均衡对应于多个种群成员之间相互作用的**稳定状态**，每个博弈中的每个玩家都有一个种群成员参与其中。有时，我们想建立一个模型，在这种情况下，单个同质种群的成员匿名参与到对称互动中。例如，考虑一下，行人在人行道上互相接近，或者汽车司机从不同方向同时到达十字路口。在每种情况下，每次相遇的成员都来自于同一人群：来自单一人群的行人相互相遇，而来自单一人群的汽车司机群体同时接近交叉路口。而在每种情况下，每个参与者的角色都是一样的。

两人博弈为"**对称的 symmetric**"如果每个人有相同的行动集，以及每个人的收益仅依赖于他和对手的行动，不取决于他的角色是P1还是P2.

**DEFINITION 49.3**  (**Symmetric two-player strategic game with ordinal preferences 对称的二人策略博弈**) A two-player strategic game with ordinal preferences is **symmetric** if the players’ sets of actions are the same and the players’ preferences are represented by payoff functions $u_1$ and $u_2$ for which $u_1(a_1, a_2) = u_2(a_2, a_1)$ for every action pair $(a_1, a_2)$.

**关键: 动作对互换位置， 收益一样！**  
**行动集相同, 且收益函数对称, 所以偏好也是相同的.  纳什均衡也是对称的.** 

<img src="/img/2020-04-18-Game.assets/image-20200508043410979.png" alt="image-20200508043410979" style="zoom:50%;" />



**DEFINITION 50.2** (**Symmetric Nash equilibrium**) An action profile $$a^{*}$$ in a strategic game with ordinal preferences in which each player has the same set of actions is a symmetric Nash equilibrium if it is a Nash equilibrium and $$a_{i}^{*}$$ is the same for every player $i$ 

**对称纳什均衡**  即该博弈里的所有玩家的均衡策略都一样.  

例子，考虑一个正在接近的行人的模型。在任意给定的遭遇中，每个参与者有两个可能的行动, 朝右或左, 当参与者都以同样的方向行走，结果好于以不同的方向行走 (在后一种情况，会发生相撞)

<img src="/img/2020-04-18-Game.assets/image-20200508043811278.png" alt="image-20200508043811278" style="zoom:33%;" />

**对称博弈可以没有对称的纳什均衡。**  这个例子中， 均衡策略是， 一个人选了左，另外一个人就必须选右，总是不相同。

<img src="/img/2020-04-18-Game.assets/image-20200508044038682.png" alt="image-20200508044038682" style="zoom:33%;" />







### 3 纳什均衡：例证

#### 3.1 古诺特寡头垄断模型 Cournot’s model of oligopoly

##### 3.1.1 Introduction 

研究厂商竞争的模型.  尽管这些模型并不限制厂商的数量，但是经济学家通常称它们为"垄断竞争"模型(少数几个厂商之间的竞争)

##### 3.1.2 General model

一件商品由$n$个企业生产。对$i$企业来说，生产$q_{i}$个商品的成本是 $C_{i}\left(q_{i}\right),$  $C_{i}$ 是递增函数(产出越多，总成本越高) . 所有的商品都以相同价格出售，价格由对商品的需求和企业的总产出决定。具体来说，如果企业们的总产出是$Q$，那么市场价格就是 $P(Q)$  ; $P$ 被称为 "inverse demand function逆需求函数". 假设$P$为正值时是一个递减函数：如果企业的总产出增加，那么价格就会下降（除非它已经为零).  如果每个企业$i$的产出是$q_{i},$那么价格是$P\left(q_{1}+\cdots+q_{n}\right)$, 其收入为$q_{i} P\left(q_{1}+\cdots+q_{n}\right)$ , 其利润为
$$
\pi_{i}\left(q_{1}, \ldots, q_{n}\right)=q_{i} P\left(q_{1}+\cdots+q_{n}\right)-C_{i}\left(q_{i}\right)
$$


##### 3.1.3 Example: duopoly with constant unit cost and linear inverse demand function

对于函数$C_{i}$和$P$的具体形式，我们可以计算出Cournot博弈的纳什均衡。

对于两个企业(双寡头, duopoly) ,  每个企业的成本以及逆需求函数都一样.  常数成本 $C_{i}\left(q_{i}\right)=c q_{i}$ ,  线性逆需求
$$
P(Q)=\left\{\begin{array}{ll}
\alpha-Q & \text { if } Q \leq \alpha \\
0 & \text { if } Q>\alpha
\end{array}\right.
$$


可以用BR来求均衡.

企业1的利润为: 

$$
\begin{aligned}
\pi_{1}\left(q_{1}, q_{2}\right) &=q_{1}\left(P\left(q_{1}+q_{2}\right)-c\right) \\
&=\left\{\begin{array}{ll}
q_{1}\left(\alpha-c-q_{1}-q_{2}\right) & \text { if } q_{1}+q_{2} \leq \alpha \\
-c q_{1} & \text { if } q_{1}+q_{2}>\alpha
\end{array}\right.
\end{aligned}
$$

对于给定的$q_2$ , 求BR,  下图中, 讨论了$q_2$ =0 , 以及>0 的情况.



![image-20201214164030747](/img/2020-04-18-Game.assets/image-20201214164030747.png)

求出的企业1的BR函数为:

$$
b_{1}\left(q_{2}\right)=\left\{\begin{array}{ll}
\frac{1}{2}\left(\alpha-c-q_{2}\right) & \text { if } q_{2} \leq \alpha-c \\
0 & \text { if } q_{2}>\alpha-c
\end{array}\right.
$$

用于两个企业一样,  $b_{2}(q)=b_{1}(q) .$ 



![image-20201214164926917](/img/2020-04-18-Game.assets/image-20201214164926917.png)

A Nash equilibrium is a pair $$\left(q_{1}^{*}, q_{2}^{*}\right)$$ of outputs for which $$q_{1}^{*}$$ is a best response to $$q_{2}^{*},$$ and $$q_{2}^{*}$$ is a best response to $$q_{1}^{*}:$$

$$
q_{1}^{*}=b_{1}\left(q_{2}^{*}\right) \quad \text { and } \quad q_{2}^{*}=b_{2}\left(q_{1}^{*}\right)
$$

即上图的交点, 可以通过下面求得

$$
\begin{array}{l}
q_{1}=\frac{1}{2}\left(\alpha-c-q_{2}\right) \\
q_{2}=\frac{1}{2}\left(\alpha-c-q_{1}\right)
\end{array}
$$

 $$q_{1}^{*}=q_{2}^{*}=\frac{1}{3}(\alpha-c)$$







#### 3.2 伯川德寡头垄断模型

#### 3.3 竞选

#### 3.4 消耗战

#### 3.5 拍卖

#### 3.6 民事法



### 4 Mixed Strategy Equilibrium 混合策略均衡

大意, 之前一个策略就是确定的一个动作, 现在把一些动作混合在一起, 随机的抽取, 就叫混合策略. 理解为随机策略也可. 纯策略之所以会劣于随机策略, 是因为随机策略里面包含随机因素, 相当于本次出招这块的信息不对称, 对方不知道要出什么招,  所以会有优势. 

ps， 对于一些博弈，由于收益的组合，结局是比较确定性的，这种博弈感觉都是玩的次数比较少的，如果是游戏，则没啥可玩性，比如囚徒困境，只有纯策略均衡。 但一些博弈，没有纯策略均衡，比如猜拳， 可能连续进行很多次，这种博弈，更偏赌博和运气， 则这个时候，需要混合策略均衡。



#### 4.1 引言

##### 4.1.1 Stochastic steady states  随机稳态

之前是理想化的稳态, 在这个稳态中，游戏中的每个玩家都有一个群体，每当游戏进行时，从每个群体中随机抽取一个玩家（见第2.6节）。在稳态下，每当玩家进行游戏时，**每一个**玩家的行为都是一样的，没有一个玩家希望改变自己的行为，因为他知道（根据他的经验）其他玩家的行为。在稳定状态下，每个玩家的 "行为"只是一个动作，而在每个群体中，所有玩家选择的动作都是一样的，在**稳定状态**下，每一次游戏的结果都是**相同的纳什均衡**。

更一般的稳态概念允许玩家的选择有变化，只要选择的模式（概率）保持不变。例如，在一个给定的群体中，不同的成员可能会选择不同的行动，每一个玩家在玩游戏时都会选择相同的行动。或者每个人在每次玩游戏的时候，都可能根据相同的、不变的分布，在概率上选择自己的行动。
这两种更一般的稳态概念是等价的：

- 第一种类型的稳态，其中代表玩家i的群体中占比为p的部分选择行动a，即每个人选择不变，通过群体成员的统计来解释随机策略。
- 第二种类型的稳态，其中代表玩家i的人口中的每一个成员都以概率p选择a。
  为了解释的方便，

在本章的大部分内容中，我将这样的均衡解释为第二种稳态的模型，在这种稳态中，每个玩家都是以概率的方式选择自己的行动；这样的**稳态**被称为**随机的（"涉及概率"）**。   



 

##### 4.1.2 Example: Matching Pennies

两个人同时出示硬币的正面或反



重要例子, 该博弈**没有纯策略纳什均衡**;  但有一个**随机*stochastic*的稳态** : 即有一个混合策略的均衡，即 每个玩家选择他的每一个动作的概率为1/2.  

需要证明, 如果P2 以1/2 的概率选择行动，那么P1最优地以概率1/2选择他自己的行动，反之亦然:  其实P2取1/2的时候, P1 的收益无论怎么样都是0, 也被看成最优, 或者说P1无法做的更好了. 同理, P1选1/2, P2也无法做的更好,所以这是一个稳定状态.

并且，可以证明， 该随机稳态只有一个。





##### 4.1.3 Generalizing the analysis: expected payoffs  推广分析：期望收益

匹配硬币对每个玩家只有两种结局,使得随机稳态状态的分析特别简单,因为它允许我们在较弱的假设下通过玩家对确定结局 (肯定发生的结局)的偏好推断玩家关于随机结局(概率分布) 的偏好。    
如果一个玩家喜欢确定的结局 $a$ 甚于确定的结局 $b$,似乎很合理的是, 若 $p>q$,那么他喜欢这样的随机结局, $a$ 发生的概率是 $p(b$ 发生的概率是 $1-p)$; 而不喜欢那样的随机结局, $a$ 发生的概率为 $q$.

在某些玩家有超过两个结局的博弈中,我们不能以这种方法从确定结局的偏好推导出关于随机结局的偏好。例如,假设博弈有三个可能结果 $a, b$ 和 $c,$ 并且玩家喜欢 $a$ 甚于 $b$ 更甚于 $c_{\circ}$ 他是否喜欢确定的结局 $b$ 胜过“ $a$ 和 $c$ 各以 $\frac{1}{2}$ 的概率发生”的随机结局,或者反过来?  玩家对确定性结局偏好的信息没有提示我们有关这个问题的答案。他可能喜欢 $b$ 甚于“ $a$ 和 $c$ 各以 $\frac{1}{2}$ 概率发生”的随机事件,或者他可能喜欢这样的随机事件甚于 $b ;$ 这两种偏好与“他喜欢 $a$ 甚于 $b$ 更甚于 $c$ ”是相容的。为了研究面临随机结局的选择时他的习性,我们需要给模型添加他关于随机结局偏好的描述。 

**lottery** ， 抽签，彩票，这里表示随机结局， 其实就是说该收益是包含随机因素的。所以用确定性收益的期望表示。

A standard assumption in game theory restricts attention to preferences regarding lotteries over outcomes that may be represented by the  expected value of a payoff function over deterministic outcomes.  博弈论的标准假设只关注“lottery 结果”上的偏好，对这些随机结局的偏好可以用确定性结局的收益函数的期望来表示。  
即,对于每一个玩家 $i,$ 存在一个具有如下性质的盈利函数 $u_{i}:$ 使得玩家 $i$ 喜欢一种随机结局甚于另一种,当且仅当根据 $u_{i}$ 计算的第一种 随机结局的期望值超过第二种随机结局的期望值。 That is, for every player $i$ there is a payoff function $u_i$ with the property that player $i$ **prefers one lottery** over outcomes to another if and only if, according to  $u_i$ , the **expected value** of the first lottery exceeds the expected value of the second lottery.



例, 两种lottery,  P出大奖的几率高于Q, 则偏好选P；

假定有三个结局 outcomes $a, b,$ and $c,$ and lottery $P$  ：yields $a$ with probability $p_{a}$ ， 以 $p_{b}$ 产生b ;  $c$  : $p_{c},$ 而另一个 $Q$： $q_{a}, q_{b},$ and $q_{c} .$  那么假定，对每个玩家 $i$ ， 存在 $u_{i}(a), u_{i}(b),$ and $u_{i}(c)$  使得玩家 $i$ 喜欢 lottery $P$ 大于 lottery $Q$ if and only if $p_{a} u_{i}(a)+p_{b} u_{i}(b)+p_{c} u_{i}(c)> q_{a} u_{i}(a)+q_{b} u_{i}(b)+q_{c} u_{i}(c) $.  

<mark><b>vNM preferences</b>  对随机的情况, 偏好是选 期望结果比较好的那个.    
即对随机的情况，有个统计上的正确的偏好。 拥有该偏好的博弈，玩家使用的是混合策略。</mark>

**Bernoulli payoff function** , $p_{a} u_{i}(a)+p_{b} u_{i}(b)+p_{c} u_{i}(c)$  ,  凸组合, 权重和为1 。   **伯努利收益函数**



假设一个玩家的偏好由一个收益函数的期望值来表示，这并不限制他对风险的态度：一个偏好由这样一个函数表示的人可能对风险有着任意强烈的喜欢或厌恶。

**risk neutral** **风险中性**： compares lotteries according to the expected amount of money involved 。   
比如，稳赚  $100$ 与  $0$ $\frac{9}{10}$  +  $1000$  $\frac{1}{10}$ ， 对其来说一样。  

ps， 风险中性， 只对模型有意义。 因为人的生命是有限的。  偏向稳赚是更符合人类发展的。

**risk averse 风险厌恶**：  更喜欢 稳赚的。 怕失去，更多看失去。  
**risk preferring 风险偏好**： 会去买彩票。       更多看获得。

在这两种情况下，对lottery的偏好并不是用预期的货币价值来表示的，尽管它们仍然可以用报酬函数的预期值来表示（其中结果的报酬与结果的货币价值不同）。 



表述某人nVM偏好的收益函数的数值也不是唯一的。 但一般不用纠结这个。

在确定性结局上，任何给定的偏好可以由许多不同的收益函数来描述（即数值只表示序号关系，不表示程度）。对于随机结局的偏好也是如此。只要相关的期望符合玩家的偏好即可。

例如,假定有三个结 局 $a 、 b$ 和 $c$,某人喜欢 $a$ 甚于 $b$ 更甚于 $c$,并且在 $b$ 与“以概率 $\frac{1}{2}$ 产生 $a$ 和以概率$\frac{1}{2}$ 产生 $c$ ”的随机结果之间表现出无所谓(偏好一样)。那么我们可以选择 $u(a)=3$ 和$u(c)=1,$ 此时 $u(b)=2$; 或者我们可以选择 $u(a)=10$ 和 $u(c)=0,$ 此时 $u(b)=$ $5 ;$ 或者 $u(a)=1, u(c)=-1,$ 此时 $u(b)=0$ 。 



#### 4.2 Strategic games in which players may randomize 有随机行为的策略型博弈

**DEFINITION 103.1**   A **strategic game** (with vNM preferences) consists of

- a set of **players**
- for each player, a set of **actions**
- for each player, **preferences** regarding lotteries over action profiles that may be represented by the expected value of a (“Bernoulli”) payoff function over action profiles.



具有vNM偏好的双人策略博弈，其中每个玩家都有有限的行动，可以用一个类似于第2章中的表格来表示。这样的表格看起来和之前的完全一样，但方框中的数字的解释是不同的。在第2章中，这些数字是收益函数的值，代表玩家对确定性结果的偏好；这里它们是（Bernoulli）收益函数的值，其期望值代表玩家对随机结果的偏好。

鉴于对报酬的解释发生了变化，两张代表同一策略博弈的序数偏好的表格不再一定代表同一策略博弈的vNM偏好。图104， 囚徒困境， 下面两种情况都描述了 相同的序数偏好为 (F,Q) > (Q,Q)>(F,F)>(Q,F) ； 但vNM偏好则不同，左边，$$\left(\frac{1}{2} u_{1}(F, Q)+\frac{1}{2} u_{1}(F, F)=\frac{1}{2} \cdot 3+\frac{1}{2} \cdot 1=2=u_{1}(Q, Q)\right)$$ ,  右边  关于 $(Q, Q)$ 的盈利大于这个随机结局的期望盈利 $\left(3>\frac{1}{2} \cdot 4+\frac{1}{2} \cdot 1\right)$ 。    所以两个表有不同的 vNM 偏好。

![image-20201202201322705](/img/2020-04-18-Game.assets/image-20201202201322705.png)

**如果玩家不被允许随机选择他们的行动，那么报酬表中的数字是代表玩家的序数偏好的收益，而如果玩家被允许随机选择，那么这些数字则是收益，这些收益的期望值代表玩家的偏好。**



#### 4.3 Mixed strategy Nash equilibrium 混合策略纳什均衡



##### 4.3.1 Mixed strategies 混合策略

**混合策略**就是在几个action上有概率的随机选择, 例如,猜拳, 每个1/3. 

混合策略可以将概率1分配给一个单一行动：通过允许玩家选择概率分布，允许其选择确定性行动。我们把这种混合策略称为**纯策略 pure strategy**。



##### 4.3.2 Equilibrium 均衡 

这个定义还是 私自偏离会吃亏 .

**定义 105.1** (**具有 vNM 偏好的策略型博弈的混合策略纳什均衡** *Mixed strategy Nash equilibrium of strategic game with vNM preferences*)  

如果 $$U_{i}\left(\alpha^{*}\right) \geq U_{i}\left(\alpha_{i}, \alpha_{-i}^{*}\right)$$ , 混合策略组合$$\alpha^*$$ 是一个纳什均衡

把之前的收益函数改成mixed strategy profile $$\alpha$$的 期望收益$$U_{i}(\alpha)$$即可.  

这里, 玩家i的所有混合策略中, 在**针对其他人的均衡混合策略时**, 选收益最好的那些.即选别人均衡策略的BR  
如果其他人的混合策略不是均衡策略, 比如猜拳, 石头0.9,布0.1, 则BR是布;  一般针对混合策略的BR就是纯策略.

猜拳, 别人1/3均衡, 自己任何混合策略包括纯策略收益都是一样的.   

混合策略纳什均衡里面,不能包含严劣的策略(概率不能大于0).  占优的action不能只有一个,不然就变成纯策略.




##### 4.3.3 Best response functions 最优反应函数

从混合策略均衡的定义来看，**如果当且仅当每个玩家的混合策略都是对其他玩家的混合策略的最佳反应时，则混合策略组合$\alpha^{*}$ 就是混合策略的纳什均衡**.     
 $$\alpha^{*}$$ is a mixed strategy Nash equilibrium if and only if $$\alpha_{i}^{*}$$ is in $$B_{i}\left(\alpha_{-i}^{*}\right)$$ for every player $i$ 

<mark><b>混合策略, 每个人都对其他人的混合策略使用BR.</b></mark>



##### 4.3.4 Best response functions in two-player two-action games 特殊情况的最优反应函数

4.1.2 匹配硬币的分析证明了，每个玩家关于其他玩家的混合策略的最优反应BR，要么是单一的纯策略，要么是所有混合策略的集合。

2人2action的game, 与匹配硬币的game类似.  每个玩家的BR集合要么只有1个纯策略,要么是所有混合策略的集合.

混合策略pair $\left(\alpha_{1}, \alpha_{2}\right)$在四种可能的游戏结果上产生的概率分布如图, 这个表格里面,没有收益, 下面公式里有

|        |  L(q)  |   R(1-q)   |
| :----: | :----: | :--------: |
|  T(p)  |   pq   |   p(1-q)   |
| B(1-p) | (1-p)q | (1-p)(1-q) |



P1的期望收益为:

$$
p q \cdot u_{1}(T, L)+p(1-q) \cdot u_{1}(T, R)+(1-p) q \cdot u_{1}(B, L)+(1-p)(1-q) \cdot u_{1}(B, R)
$$

改写为:  即，从P1横向看过去，

$$
p\left[q \cdot u_{1}(T, L)+(1-q) \cdot u_{1}(T, R)\right]+(1-p)\left[q \cdot u_{1}(B, L)+(1-q) \cdot u_{1}(B, R)\right]
$$

求两端 : 第一个方括号是P1使用纯策略T, 玩家2使用混合策略$\alpha_{2}$时的预期回报,   第二个是P1使用纯策略B, 玩家2使用混合策略$\alpha_{2}$时的预期回报;  分别记为 $E_{1}\left(T, \alpha_{2}\right)$ and $E_{1}\left(B, \alpha_{2}\right) .$    P1的期望收益改写为:   即在自己的动作上将期望拆分.  

$$
p E_{1}\left(T, \alpha_{2}\right) + (1-p) E_{1}\left(B, \alpha_{2}\right)
$$

给定玩家2的混合策略以后, P1的期望收益就是线性函数.  注意, 这个图里画的是P1 的预期收益.

<img src="/img/2020-04-18-Game.assets/image-20200505221618206.png" alt="image-20200505221618206" style="zoom: 50%;" />

<B><mark>对这种类型的博弈, <I>给定对方采用的混合策略</I>  , 自己的收益函数是线性的, 极值点在两端, 其中收益大的那个是BR.   对2人2action的game,  如果对方在均衡点上, 则自己的线性是水平的, 因为自己的所有混合策略都应该是BR, 都一样好. </mark></B> 

<B><mark> P1的收益E=pE1+(1-p)E2, 调自己P1的p到两端, 令相等(即令p=0,p=1,E1=E2 收益相等), 求得的是对方的均衡策略q的值</mark></B> 

<B><mark>自己在均衡点上, 对方没法单独改变策略来获益.  对方在均衡点上, 不让自己有机可乘; 自己在均衡点上, 不让对方有机可乘</mark></B> 

<B><mark> 下面这个思路不对: P1的收益,调P2的q令收益E(q=0) = E(q=1); 没有理论依据, 下面都BoS就不成立 , 关键要看收益u的定义</mark></B> 

P1的线性预期回报的一个重要结论是，他对玩家2的混合策略有三种可能的最佳反应。

1. P1唯一的最佳反应是纯策略T (if $E_{1}\left(T, \alpha_{2}\right)>E_{1}\left(B, \alpha_{2}\right)$) 

2. P1唯一的最佳反应是纯策略B (if $E_{1}\left(B, \alpha_{2}\right)>E_{1}\left(T, \alpha_{2}\right)$)，在这种情况下，P1的预期回报率与图108.1中的p的函数关系线向下倾斜

3. P1的所有混合策略都会产生相同的预期回报，因此都是最好的反应($E_{1}\left(T, \alpha_{2}\right)=E_{1}\left(B, \alpha_{2}\right)$)，在这种情况下，在图108.1的类比中，代表P1的预期回报率与p的函数的线是水平的

特别是， **混合策略**$(p, 1-p)$ $0<p<1$ **永远不是唯一的最佳反应，要么它不是最佳反应，要么所有的混合策略都是最佳反应**。 因为如图，给定P2策略， P1的最优收益是线性，在两端； 如果P2是均衡策略，则P1的整个中间线段都是最佳反应， 因为这个线是水平的。
实际上也说明了， **在这种类型的博弈中，针对某个混合策略的Br，一般都是纯策略。**



EXERCISE 107.1 (Expected payoffs)  BoS 16.1 以及 19.1  ,画出如图 108.1 的P1 的预期收益.  

如果 p,q 看成 x,y轴, 则变成3d图像,  这里把q作为 线性的参数 , 然后看线性收益的两端.

![image-20201210212437764](/img/2020-04-18-Game.assets/image-20201210212437764.png)

![image-20201210215642017](/img/2020-04-18-Game.assets/image-20201210215642017.png)

![image-20201210212248344](/img/2020-04-18-Game.assets/image-20201210212248344.png)

![image-20201210220339898](/img/2020-04-18-Game.assets/image-20201210220339898.png)

水平了一般就是对方的均衡策略的取值点. 





##### 4.3.5 Example: Matching Pennies 

两个人同时出示硬币的正面或反

4.1.2 已经证明了有唯一的混合策略纳什均衡.  现在用2.8.3节的 **BR相交** 方法

上面的练习, 其实说明, 要把pq画到一个图里不容易.  但是可以通过画BR的方式, **自己的BR完全是由对方的策略来决定的.**  下面图里画的是, BR的时候, 两个玩家的策略的值,即p与q的取值. 

设P1选head几率为p, 玩2选head几率为q.   
则P1选纯策略,head的预期收益为 q · 1 + (1 − q) · (−1) = 2q − 1, 选tail的预期收益为 q·(−1)+(1−q)·1 = 1−2q .  这时的预期收益完全由玩家2的q来决定.    
当知道了玩家2 的q之后, P1的**纯策略**最佳反应函数,即p的取值为: 
$$
B_{1}(q)=\left\{\begin{array}{ll}
\{0\} & \text { if } q<\frac{1}{2} \\
\{p: 0 \leq p \leq 1\} & \text { if } q=\frac{1}{2} \\
\{1\} & \text { if } q>\frac{1}{2}
\end{array}\right.
$$


同理,如果P1采样p的概率, 玩家2的用纯策略, 则相应的最近反应函数也类似.

将这两个函数都画到下图里面, 唯一的交点就是 混合策略的纳什均衡.

<img src="/img/2020-04-18-Game.assets/image-20200508033716605.png" alt="image-20200508033716605" style="zoom:50%;" />

这个解法的思路是, P1表示出自己的收益(固定P2的策略的变量) ,然后求BR;  对P2也如此; 然后求相交.  



##### 4.3.6 Example: BoS

该博弈， 纯策略有两个纳什均衡.   对于这种 2个人分别有2个动作的博弈, 对于混合策略, 因为别人走了随机, 所以只要别人不是在均衡点上, 自己这边肯定需要把策略偏向某个方向. 只有自己也在均衡点上, 就不用管对方怎么变, 自己都是期望最优了.  使用混合策略以后,得到的纳什均衡, 可以使得两个玩家得到的收益一样. 而不是像之前一样, 只有1个人能最大化; 不过这样的**后果就是总收益降低**, 每个人 平均收益是 2/3 ;  之前的纯策略平均每个人是3/2, 不过需要一个人做牺牲. 

<B><mark>而相关均衡则是, 两个人通过通信, 比如轮流的选择对方最喜欢的, 这样可以达到两个人的收益都一样又都最大化的情况, 这里是3/2, 即两个人一起选B一次, 再一起选S一次</mark></B>



<img src="/img/2020-04-18-Game.assets/image-20200508034115026.png" alt="image-20200508034115026" style="zoom:33%;" />


$$
B_{1}(q)=\left\{\begin{array}{ll}
\{0\} & \text { if } q<\frac{1}{3} \\
\{p: 0 \leq p \leq 1\} & \text { if } q=\frac{1}{3} \\
\{1\} & \text { if } q>\frac{1}{3}
\end{array}\right.
$$

<img src="/img/2020-04-18-Game.assets/image-20200508034351923.png" alt="image-20200508034351923" style="zoom:50%;" />

黑点是纯策略纳什均衡, 中间的交点的黑点是混合策略的纳什均衡. 



例, 一个博弈,  

| 1,1  | 0,0  |
| ---- | ---- |
| 0,0  | 1,1  |

这个博弈, 本来就2个纯策略的均衡点,  但混合策略 1/2 , 每个人的收益也变成了1/2 , 这个是混合策略的纳什均衡么.   这个符合混合均衡的定义, 任何一个人单独偏离,都无法获得更好的收益, 所以成立.  但显然这个混合策略,不如任何一个纯策略均衡.  混合策略均衡并不一定就是好的.





EXERCISE 111.1 (Mixed strategy equilibria of Hawk–Dove)

![image-20201210232839330](/img/2020-04-18-Game.assets/image-20201210232839330.png)



EXERCISE 112.1 (A coordination game)

两个人,出力与偷懒,  0<c<1 . 求全部混合策略 

![image-20201211121642104](/img/2020-04-18-Game.assets/image-20201211121642104.png)

均衡策略是 p=1-c 选偷懒.  c解释为努力的成本  ; 当c变大的时候,  大家都倾向于努力. 





##### 4.3.7 A useful characterization of mixed strategy Nash equilibrium 混合策略均衡的有用特征

快速检测是不是均衡策略!!

目前为止，用来研究混合策略纳什均衡集合的方法涉及 构建最佳响应函数。对于简单的博弈，这种方法是有用的，但是对于更复杂一些的博弈，这种方法是有限的。
其他的方法有时也是有用的。现在提出一个混合策略均衡的特征，它为我们**提供了一个简单的方法来检查一个混合策略组合是否是均衡**，并且是寻找一个博弈的所有均衡的程序的基础。

关键是在第4.3.4节中对双人双动博弈的分析：玩家对**混合策略组合的预期回报是他对纯策略的预期回报的加权平均**，其中每个纯策略的权重是玩家的混合策略分配给该策略的概率。这个属性对于**任何action有限个的博弈（有任意数量的玩家）**都适用。我们可以更精确地说明如下： 



玩家对**混合策略组合 $\alpha$ 的预期收益**为, 其对所有形式为 $\left(a_{i}, \alpha_{-i}\right)$ 的混合策略(这里自己的部分是纯策略)的组合的预期收益的加权平均, 权重是  $\alpha_i(a_i)$ , 表示 $\alpha_{i}$ 分配给 $a_i$ 的概率.   即, 固定其他人的策略, 混合策略的收益就是 各个纯策略的收益加权和.

$$
U_{i}(\alpha)=\sum_{a_{i} \in A_{i}} \alpha_{i}\left(a_{i}\right) U_{i}\left(a_{i}, \alpha_{-i}\right)  \tag{113.1}
$$

其中,  $$A_{i}$$ 是玩家 $$i$$ 的纯策略动作集,  $$U_{i}\left(a_{i}, \alpha_{-i}\right)$$ 是玩家执行纯策略 $a_{i}$, 其他人 $$j$$ 使用混合策略$$\alpha_{j}$$ 的预期收益. 

该性质可以推出混合策略均衡的一个有用的特性:   $$\alpha^{*}$$ 为混合策略均衡,   $$E_{i}^{*}=U_{i}\left(\alpha^{*}\right)$$ 为该**均衡策略的预期回报**.  因为 $$\alpha^{*}$$ 为混合均衡, <mark><b>则给定 $\alpha_{-i^{\prime}}^{*}$ 的情况下, 玩家$i$的所有策略(包含纯策略)的预期回报最多是 $E_{i}^{*}$.</b></mark> 由$$(113.1)$$, 可得, $$E_{i}^{*}$$  是 属于混合策略均衡的那些纯策略$$a^*_i$$ (即被分配了正概率)的预期回报的加权平均, 权重是分配给各个纯策略$$a^*_i$$的概率. 于是, **这些纯策略$$a^*_i$$的预期回报都 $$= E_{i}^{*}$$ .**(如果均衡策略中的哪个纯策略的回报小了,则总体的加权平均值肯定要下降).   同时, 其他的那些**不属于混合策略均衡的纯策略$$a_i$$的预期回报$$ \leq E_{i}^{*}$$ .**   

反过来说,  **找到那些纯策略 $$a_{i}^{*}$$的预期回报都是$$E_{i}^{*}$$的, 那么这些纯策略组合起来的混合策略就是纳什均衡.** 

以上的前提是, 对方已经处于 均衡策略了.

**PROPOSITION 113.2 **   ( **Characterization of mixed strategy Nash equilibrium of finite game 有限搏弈的混合策略纳什均衡的特性** )      
策略型博弈中, 混合策略组合 $$\alpha^*$$ 是纳什均衡,当且仅当,   对每个玩家$$i$$,  

- 给定对手策略$$\alpha^*_{-i}$$的情况下, $$\alpha^*$$ 分配正概率的每个行动(即纯策略)的预期收益是相同的 $$ = E_{i}^{*}$$. 说明其他人在均衡点, 自己怎么的均衡策略调都没用,不能额外获利
- 给定对手策略$$\alpha^*_{-i}$$的情况下, $$\alpha^*$$ 分配0概率的每个行动的预期收益 $$ \leq E_{i}^{*}$$。  说明 劣的不能入选均衡.

该结论的重要意义是, 它给出了混合策略纳什均衡的条件，即每个玩家的预期回报跟他的纯策略相关。对于有限多行动的博弈，可以很容易地检验混合策略组合是否是均衡。 

<mark><b>显然, 如果固定P2的策略, P1的每个纯策略收益都一样(这时P1的任意策略都是BR), 那P2肯定在均衡点.  如果P1的部分纯策略最大, 那其余的应该是严劣的.  如果P1只有一个纯策略最大, 那P1针对P2当前的策略就没有混合策略的BR, 证明P2肯定不在混合策略均衡点, 也可能只有纯策略均衡</b></mark>

**即通过固定对方的均衡策略，检查自己均衡策略中的action的纯策略回报是否一样的最大，可以判定是不是双方在均衡点。**

例,  BoS ,  策略对 $\left(\left(\frac{2}{3}, \frac{1}{3}\right),\left(\frac{1}{3}, \frac{2}{3}\right)\right)$ 是混合策略均衡, 因为给定玩家2的策略 $\left(\frac{1}{3}, \frac{2}{3}\right)$, P1的关于B和S的预期收益都是 $\frac{2}{3},$ 说明玩家2在均衡点上;  并且 给定P1的策略 $\left(\frac{2}{3}, \frac{1}{3}\right)$, 玩家2关于B和S的预期收益也都等于 $\frac{2}{3}$ , 说明P1在均衡点上. 



**很有用**  EXAMPLE 114.1 (检测一个策略组合是不是混合策略均衡) 

<img src="/img/2020-04-18-Game.assets/image-20200508172839897.png" alt="image-20200508172839897" style="zoom: 50%;" />

黑点表示， 收益值任意。因为对方坚持不走，所以无所谓。

P1的策略$\left(\frac{3}{4}, 0, \frac{1}{4}\right)$,  玩家2的策略$\left(0, \frac{1}{3}, \frac{2}{3}\right)$ . 下面验证.  
对P1的收益预期为：  
  	$T: \frac{1}{3} \cdot 3+\frac{2}{3} \cdot 1=\frac{5}{3}$  
  	$M: \frac{1}{3} \cdot 0+\frac{2}{3} \cdot 2=\frac{4}{3}$  
  	$B: \frac{1}{3} \cdot 5+\frac{2}{3} \cdot 0=\frac{5}{3}$  
所以P1满足定理113.2  
玩家2 , 两个纯策略的收益为$\frac{5}{2}\left(\frac{3}{4} \cdot 2+\frac{1}{4} \cdot 4=\frac{3}{4} \cdot 3+\frac{1}{4}  1=\frac{3}{4} \cdot 1+\frac{1}{4} \cdot 7=\frac{5}{2}\right),$ 所以也满足条件.

 

命题113.2的一个含义是，<mark>一个<B>非退化 nondegenerate</B>的混合策略均衡（真正的混合策略, 不包含概率为1，0的那种纯策略均衡）从来都不是<B>严格 strict 的纳什均衡</B></mark>：every player whose mixed strategy assigns positive probability to more than one action is indifferent between her equilibrium mixed strategy and every action to which this mixed strategy assigns positive probability. 每个玩家对混合策略里面的选哪个动作无所谓, 因为其他人都在均衡点上. 

<mark><B>ps，形象的说， 非退化混合策略均衡(至少由两个纯策略组成, 并且包含的纯策略必定收益一样,是对方均衡策略的BR)， 不可能是山峰</B></mark>  因为对方在均衡点, 自己必然有一些纯策略是BR , 想一下猜拳, 对面1/3, 自己就全部都是BR. 





EXERCISE 115.1 (Choosing numbers)

玩家1和2各选择一个正整数。 如果玩家选择相同的数字，那么玩家2向玩家1支付1美元，否则不支付。
a. 证明该博弈有一个混合策略纳什均衡，其中每一个玩家以1/K的概率选择K以内的每个正整数。
b. (更难)证明该游戏没有其他混合策略纳什均衡。

EXERCISE 115.2 (Silverman’s game)

两位玩家各自选择一个正整数。看谁取的比对方大,但又不能大太多(超过3倍). 如果玩家i的整数大于玩家j的整数，但小于这个整数的3倍，那么玩家j向玩家i支付1美元，如果玩家i的整数至少是玩家j整数的3倍，那么玩家i向玩家j支付1美元。如果数字一样则平局. 每个玩家的偏好用她的预期货币报酬来表示。

证明,该博弈没有纯策略纳什均衡,并且“每个玩家各以 $\frac{1}{3}$ 概率选择 1, 2 和 5”是混合策略纳什均衡。（事实上，这是唯一的混合策略纳什均衡)





##### 4.3.8 Existence of equilibrium in finite games  有限博弈均衡的存在性

PROPOSITION 116.1 (**Existence ofmixed strategy Nash equilibrium in finite games**)
<mark>Every strategic game with vNMpreferences in which each player has <B>finitely</B> many actions has a <B>mixed strategy Nash equilibrium</B>.</mark>

<mark>玩家有限多个行动的博弈都<B>至少有一个混合策略纳什均衡(可以权重是1)</B>。</mark>  同时，如果在nVM偏好的博弈中，找到一个概率权重是1的混合策略均衡，那么该均衡就等于序数偏好的纯策略均衡。

没说怎么去找，但肯定存在。  有限action的条件是充分条件； 一些无限action的game也有混合纳什均衡。



#### 4.4 Dominated actions 劣行动

之前的严优，弱优， 无论对手什么行动， 自己的某个action总是比其他action收益好或者不差。

注意, **这里的比较, 都是 混合策略与自己的纯策略的比较**.  



**DEFINITION** 117.1 (**Strict domination 严优**)  

注意, 前面是alhpa, 后面是a ;   自己混合策略与自己的纯策略相比， 对方无论纯策略。

混合策略组合 $\alpha_{i}$ **严优strictly dominates** 于 $a_{i}^{\prime}$ ,  if  $U_{i}\left(\alpha_{i}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions . 

即, 无论对方的采取什么纯策略, 玩家$i$的这个混合策略$\alpha_{i}$, 比自己的某个纯策略的收益要好, 严优.     
形象的说, 就是 某个混合策略的vNM收益 > 收益表里面的某列(或者行) 的收益, 看下面的例子. 



重要例子,  方便快速排除!!   图117.1(其中只给出了P1的回报)  ,  行动T不**严劣**于M或者B,   即T 不弱于M或者B, 但T 弱于"1/2 选M ,1/2选B",  玩家2最好的应对是选R, 这时P1的期望回报是 3/2 , 大于1.

<img src="/img/2020-04-18-Game.assets/image-20200508022703992.png" alt="image-20200508022703992" style="zoom:33%;" />

上图的所有严优于T的混合策略为:

assigns to $T$ by $p$ ,  $M$ by $r$ . mixed strategy strictly dominates $T$ if and only if
$$
p+4 r>1 \text { and } p+3(1-p-r)>1
$$
求得 $1-4 r<p<1-\frac{3}{2} r .$ For example, the mixed strategies $\left(\frac{1}{4}, \frac{1}{4}, \frac{1}{2}\right)$ and $\left(0, \frac{1}{3}, \frac{2}{3}\right)$ both strictly dominate $T$ . 



<mark> <b>纯策略 可能严劣于某个混合策略, 在任何混合策略纳什均衡中，严劣行动不被使用</b>。</mark>   纯策略的这个结论在混合策略这边都适用。



**DEFINITION** 118.2 (**Weak domination**) 弱优   
In a strategic game with vNM preferences, player $i^{\prime}$ s mixed strategy $\alpha_{i}$ weakly dominates her action $a_{i}^{\prime}$ if  
$U_{i}\left(\alpha_{i}, a_{-i}\right) \geq u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions  
and  
$U_{i}\left(\alpha_{i}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for some list $a_{-i}$ of the other players' actions,  
where $u_{i}$ is a payoff function whose expected value represents player $i^{\prime}$ s preferences over lotteries and $U_{i}\left(\alpha_{i}, a_{-i}\right)$ is player $i^{\prime}$ s expected payoff under $u_{i}$ when she uses the mixed strategy $\alpha_{i}$ and the actions chosen by the other players are given by $a_{-i}$



求均衡时,不能排除 弱劣. 例如图  46.1 .   

严格纳什均衡没有弱劣. 

**PROPOSITION** 119.2 (**Existence** of **mixed strategy Nash equilibrium** with **no weakly dominated** strategies in **finite** games) Every strategic game with vNM preferences in which each player has finitely many actions has a mixed strategy Nash equilibrium in which no player’s strategy is weakly dominated.

<mark> <b>有限博弈， 存在一个混合策略均衡， 其中每个人的策略都不是弱劣的。</b></mark>          证明困难.

**纯策略的均衡可能包含弱劣策略.   但肯定有一个混合策略均衡, 不包含任何弱劣策略.**





#### 4.5 Pure equilibria when randomization is allowed 随机的纯策略均衡

命题:  **对一般的博弈, 不允许玩家随机选择行动时的均衡，在允许玩家随机选择后仍然为均衡; 并且，允许玩家随机时存在的任何纯策略均衡，在不允许随机后也存在。**  
Pure strategy equilibria survive when randomization is allowed；Pure strategy equilibria survive when randomization is prohibited





#### 4.6 例证：专家诊断



#### 4.7 Equilibrium in a single population 单一总体中的均衡

类似 Section 2.10 ， 定义都与之前一样, 只不过改成了 vNM偏好.

**DEFINITION** 126.1 (**Symmetric two-player strategic game with vNM preferences**) A two-player strategic game with vNM preferences is symmetric if the players' sets of actions are the same and the players' preferences are represented by the expected values of payoff functions $u_{1}$ and $u_{2}$ for which $u_{1}\left(a_{1}, a_{2}\right)=u_{2}\left(a_{2}, a_{1}\right)$ for every action pair $\left(a_{1}, a_{2}\right)$ .



下面的定义，扩展到多人。 之前的纯策略改为混合策略。

**DEFINITION** 126.2 (**Symmetric mixed strategy Nash equilibrium**) A profile $\alpha^{*}$ of mixed strategies in a strategic game with vNM preferences in which each player has the same set of actions is a **symmetric mixed strategy Nash equilibrium** if it is a mixed strategy Nash equilibrium and $\alpha_{i}^{*}$ is the same for every player $i$.



<img src="/img/2020-04-18-Game.assets/image-20200508044620628.png" alt="image-20200508044620628" style="zoom:33%;" />

对路人接近问题, 除了纯策略的两个均衡, (Left, Left) and (Right, Right); 有个对称的混合策略均衡. 即 1/2选择左或右， 但这个混合策略的稳态， 有一半的几率是会相撞的。  

下例中, 没有纯策略对称均衡, 却有混合策略对称均衡 （1/2的几率选X， 1/2 选Y）.

<img src="/img/2020-04-18-Game.assets/image-20200508044816686.png" alt="image-20200508044816686" style="zoom:33%;" />



**PROPOSITION** 127.1 (**Existence** of symmetric mixed strategy Nash equilibrium in **symmetric finite** games) Every strategic game with vNM preferences in which each player has the same finite set of actions has a symmetric mixed strategy Nash equilibrium.

**对称有限博弈必有对称混合策略均衡。**



#### 4.8 例证：报案





#### 4.9 The formation of players’ beliefs 玩家信念的形成

讨论的是怎么 所有人从0开始， 学习到 均衡策略的 问题。

在纳什均衡中，每个玩家在**知道**其他玩家的策略的情况下，选择一个能使其预期收益最大化的策略。到目前为止，我们还没有考虑过玩家是如何获得这些信息的。从非正式的角度来说，前面的分析的基本思想是，玩家们从他们的游戏**经验**中了解到了对方的策略。  在理想化情况下，对于游戏中的每一个玩家，都对应一个群体, 其中大量的个体；在游戏的任何一局游戏中，每个群体中随机抽取一个参与者。在这种情况下，一个新的个体加入一个处于稳定状态的群体（即正在使用纳什均衡策略），他可以通过观察其他玩家在多次博弈中的行动来学习其他玩家的策略。只要玩家的更替率足够小，现有老玩家与新手（可能使用非均衡策略）的相遇就会足够少，以至于老玩家对稳态的信念不会受到干扰，因此，新玩家的问题只是学习其他玩家的行动。 -- 大量老人带个别新人

下面的问题是, 如果博弈中的玩家都是缺乏经验的新手玩家, 那能达到纳什均衡么

##### 4.9.1 Eliminating dominated actions 剔除劣行动

第一个办法, 对某些博弈, 纯推理.  排除法, 先去掉一些差动作, 减少搜索空间.  该方法只适用于部分博弈。

某些博弈中，可以期盼玩家通过对博弈的内在分析，合理选择他们的纳什均衡行动。在极端的情况下，每个玩家的最佳行动可能独立于其他玩家的行动，就像囚徒困境那样。在不太极端的情况下，一些玩家的最佳行动可能取决于其他玩家的行动，但其他玩家将选择的行动可能是明确的,  因为这些玩家都有严优于所有其他行动的行动.

<img src="/img/2020-04-18-Game.assets/image-20200508120053026.png" alt="image-20200508120053026" style="zoom:33%;" />

上例中, 玩家2的R 优于L, 所以P1可以推断自己应该选B, 也就是说, 新手玩家也可以导致这个唯一的纳什均衡.

延伸该思路, 

<img src="/img/2020-04-18-Game.assets/image-20200508141746314.png" alt="image-20200508141746314" style="zoom:33%;" />

上例中， P1的T是严劣的， 所以P1可以推理出:玩家2能考虑到P1不会选T, 玩家2会选择R; 所以P1 会选择B.  即相信大家都是绝对理性的.

在这种推理过程结束时剩下的set of action profiles 包含所有的纳什均衡；对于许多游戏（与这些例子不同），它包含许多其他策略组合。事实上，在许多游戏中，它不会消除任何action profile，因为没有玩家有严优行动。然而，在某些类别的游戏中，这个过程是很有效的。



##### <mark><b>4.9.2 Learning 学习 </b></mark>

重要!!  学习就是 通过 **多次游戏迭代,收敛到纳什均衡**

另一种方法是假设每个玩家在开始时对其他玩家的行为都有一个无法解释的 "先验 "信念，然后根据他收到的信息改变这些信念--"**学习**"。在这里，我简单地讨论了两个理论，即同一组参与者重复地玩一个游戏，每个参与者都会根据自己对其他人的行为的观察，改变自己对其他人的策略的信念。

<mark><b>Best response dynamics 动态最优反应</b></mark> :   一个特别简单的理论假设，在第一个时期之后的每个时期，<mark>每个玩家都相信其他玩家会选择他们在前一个时期选择的行动<B>(相信其他玩家会重复上一把出招)</B>。</mark>  在第一个时期，每个玩家针对其他玩家的行动选择一个任意的确定定性信念，选择一个最佳反应。在随后的每一个时期，每个玩家都会选择一个最佳反应来回应上一时期其他玩家的行动。这个过程被称为**最佳反应动态**。若干时期后一直保持不变的行动组合就是一个**纯策略纳什均衡**。此外，一个纯策略均衡，若干周期保持不变，其中每个玩家的行动是他对其他玩家的行动的**唯一**最佳反应。

在一些博弈中，不管玩家的**初始信念**如何，最优反应动态产生的行动组合序列收敛于一个纯策略纳什均衡。  
另外有一些博弈，**存在一些初始信念**，之后产生的行动组合序列**并不收敛**。例如，在BoS（例16.2）中，如果P1最初相信玩家2会选择斯特拉文斯基，而玩家2最初相信P1会选择巴赫，那么玩家的选择将在（巴赫、斯特拉文斯基、巴赫）和（斯特拉文斯基、巴赫）这两个动作对之间无限期地交替进行。这个例子突出了玩家在model中的推理能力的局限性。即没有考虑到对方的行动总是对自己之前的行动作出最好的反应的这种可能性。 即 相信对方是傻子，总是重复上一把。

在Best response dynamics下，除非出发点是纳什均衡，否则玩家的信念不断地显露出不正确: 玩家的行动随着时间一直在变化。此外，每个玩家都相信其他玩家都在使用纯策略：确信其他人不会采用混合策略。

所以这个方法，有时无法收敛， 因为一些纯策略均衡总是摇摆。 还有一些博弈只有混合均衡。



EXERCISE 133.1 (Best response dynamics in Cournot’s duopoly game)  在3.1.3节的假设下，如果Cournot’s duopoly game中的企业最初都选择了0，那么找出它们所选择的产出的策略对的序列.

The best response functions of both firms are the same, so if the firms' outputs are initially the same, they are the same in every period: $q_{1}^{t}=q_{2}^{t}$ for every $t$. For each period $t,$ we thus have
$$
q_{i}^{t}=\frac{1}{2}\left(\alpha-c-q_{i}^{t-1}\right)
$$
Given that $q_{i}^{1}=0$ for $i=1,2,$ solving this **first-order difference equation** we have
$$
q_{i}^{t}=\frac{1}{3}(\alpha-c)\left[1-\left(-\frac{1}{2}\right)^{t-1}\right]
$$
for each period $t$. When $t$ is large, $q_{i}^{t}$ is close to $\frac{1}{3}(\alpha-c),$ a firm's equilibrium output. In the first few periods, these outputs are $0, \frac{1}{2}(\alpha-c), \frac{1}{4}(\alpha-c), \frac{3}{8}(\alpha-c), \frac{5}{16}(\alpha-c)$




<mark><b>Fictitious play 假想博弈</b></mark> : **统计概率,作为其混合策略**. 假设玩家在形成对对手策略的信念时，会考虑**之前所有时期的行动**。他们把这些行动视为混合策略的表现。考虑一个双人博弈。每个玩家开始时都对对方的行动有一个任意的概率信念。在游戏的第一局中，他选择了一个对这个信念的最佳回应，并观察对方的行动，比如说对方行动是A。然后，他将自己对对方的信念改变为将概率1分配给A；在第二个时期，他选择一个对这个信念的最佳回应，并观察对方的行动，比如说B。 然后，他把自己的信念改成给A和B都分配了1/2概率，并选择了一个最佳回应。 他每个时期都会继续改变自己的信念；**在任何时期，他都认为对手使用的是混合策略，在这种策略中，每个动作的概率与出现的频率成正比**。

在匹配硬币, 这个过程运作如下。假设P1 从"P2 的行动将是反面"的信念出发，玩家2 从"P1的行动将是正面"的信念开始。然后，两个玩家在周期 1 都选择了"反面"。于是, 两个玩家在周期2中都相信对方选了反面, 因此P1选择反面, 玩家2选择正面; 到周期3, P1认为:玩家2选正反的几率是1/2, 玩家2认为: P1肯定选反面; 于是,P1关于其信念的最优反应是正反面两个都可以, 玩家2 唯一的最优反应是正面; 然后一直继续下去...

像 "匹配便士 "这样的双人博弈，玩家的利益是直接对立的，在任何双人游戏中，每个玩家都有两个行动，这个过程从任何初始信念开始都**收敛到混合策略纳什均衡**。也就是说，在足够多的时间段后，**每个玩家选择行动的频率接近于混合策略在纳什均衡中的频率**。对于其他博弈来说，有一些初始信念，其过程并不收敛。(即使最简单的例子太复杂了，无法简单介绍)。



#### 4.10 Extension: Finding all mixed strategy Nash equilibria   延伸: 求混合策略纳什均衡

对于有两个行动的两人博弈，我们可以 通过构**建最优反应函数**，求得所有的混合策略纳什均衡。在更复杂的博弈中，这个方法一般不实用。

下面求博弈中全部混合策略纳什均衡的方法由命题 113.2 中的均衡特征推导出来。

- 对每个玩家$i$, 从其行动集 $A_i$ 中选择一个子集$S_i$  ； 相当于找到所有的 action pair 组合
- 核实是否存在一个混合策略组合$\alpha$ ，使得
  - 每个策略 $\alpha_i$ 分配正概率的行动集是 $S_i$ 
  - $\alpha$ 满足命题113.2 中的条件。  固定对手的均衡策略，自己正概率的action都是收益最大的。
- 对玩家行动集中的每一个子集组合，重复地分析。 



这个方法工作量蛮大的..

**EXAMPLE** 135.1 (Finding all mixed strategy equilibria of a two-player game in which each player has two actions) **2人2action的全部均衡**.

例子, 下图, 每个玩家的动作集有三个非空子集(1,2,(1,2)); 因此存在9个 P1玩家2的行动对.  对每一对($S_1,S_2$) , 核实是否存在一堆混合策略($\alpha_1, \alpha_2$) , 使得每个$\alpha_i$ 仅对$S_i$的行动分配正概率, 并且满足113.2.

<img src="/img/2020-04-18-Game.assets/image-20200508181252013.png" alt="image-20200508181252013" style="zoom:33%;" />

- 考虑其中四对子集，其中每个玩家的子集由一个动作组成，就等于检查是否是纯策略均衡。(对每个玩家来说，自动满足命题113.2中的第一个条件，因为每个子集中只有一个动作)。
- 考虑P1的子集 $\{T, B\}$和玩家2的子集 $\{L\}$ : 对于P1来说，第113.2条中的第二个条件是自动满足的，因为P1没有任何行动的概率为0，而对于玩家2来说，第一个条件是自动满足的，因为他只给一个行动分配了正概率。因此，如果要有一个混合策略均衡，其中P1使用T的概率是p , 我们需要$u_{11}=u_{21}$ , 因为P1的两个动作的期望回报必须一样. 并且, $p v_{11}+(1-p) v_{21} \geq p v_{12}+(1-p) v_{22}$, 即考虑到P1的混合策略，L至少要和R一样好。 如果$u_{11} \neq u_{21}$ , 或者 不存在满足不等式的p, 那么就不存在这种类型的均衡. 其他三组子集也同理.
- 考虑$\{T, B\}$ 和 $\{L, R\}$ . 我们需要找到一对混合策略，并满足命题113.2中的第一个条件（第二个条件是自动满足的，因为两个玩家都给他们的行为赋予正概率）。也就是说，我们需要找到概率p和q(如果有的话), 使得  $q u_{11}+(1-q) u_{12}=q u_{21}+(1-q) u_{22} \quad$ and $\quad p v_{11}+(1-p) v_{21}=p v_{12}+(1-p) v_{22}$

例如，在 BoS 中，检查其中每个子集由单一行动组成的子集对时，发现了两个纯策略均衡; 检查其中一个子集只含有单一行动而另 个子集由两个行动组成的子集对时，发现没有均衡;  剩下的情况, 求得混合策略均衡。



EXERCISE 136.1 (Finding all mixed strategy equilibria of two-player games)

![image-20201214181710265](/img/2020-04-18-Game.assets/image-20201214181710265.png)

- 左边:  没有纯策略,  (1/4,3/4),(2/3,1/3)

- 右边:  
  - 纯策略均衡  (T, R) and (B, L)    
  - **纯 vs 混合** :  T vs LR , 没有 , 因为 P2 收益不一样.  同理 B vs LR , L vs TB ;  
    但对 R vs TB , P1 的收益都是一样的,  P2 取R时,收益为 2p+1−p,  取L时收益为 p+2(1-p),  对P1的混合策略, 只要P2的收益能满足 2p+1−p >=  p+2(1-p) , 即 p>=1/2 ,  即满足均衡; 即P2让P1收益一样, P1的策略只要能不让P2偏移,就是均衡.
  - 混合 vs 混合, 求出 0,  没有.
  - 所以最后均衡为 : (B, L)) and ((p, 1 − p), (0, 1)) for 1/2 ≤ p ≤ 1 (=1 时就是 (T, R))



EXAMPLE 136.2 (Finding all mixed strategy equilibria of a variant of BoS)

![image-20201214184455114](/img/2020-04-18-Game.assets/image-20201214184455114.png)

- 纯 BB  SS 
- 纯  vs 混合 , 没有 , 自己取纯, 对方必须收益一样, 才有机会
- 混合 vs  考虑 P2 选两个混合 
  - BS 不行 
  - SX  不行
  - BX  (3/4, 1/4), (1/5,0,4/5)
- 混合 vs 混合   p1的2个action 以及p2的3个action都要正概率; P2 的3个action的收益需要相同, 为 2p = 4(1 − p) = p + 3(1 − p).   无解







#### 4.11 Extension: Mixed equilibria of games in which each player has a continuum of actions   延伸：每个玩家具有连续动作的博弈

 扩展到连续动作   ,  原来每个action的概率,  变成概率密度函数. 



**PROPOSITION** 140.1 (Characterization of mixed strategy Nash equilibrium 混合策略纳什均衡的特征) 
A mixed strategy profile $$\alpha^{*}$$ in a strategic game with vNM preferences is a mixed strategy Nash equilibrium if and only if, for each player i,

- $$\alpha_{i}^{*}$$ assigns probability zero to the **set** of actions $$a_{i}$$ for which the action profile $$\left(a_{i}, \alpha_{-i}^{*}\right)$$ yields player i an expected payoff less than her expected payoff to $$\alpha^{*}$$   对收益少的action集 分配的概率为0
- for no action $$a_{i}$$ does the action profile $$\left(a_{i}, \alpha_{-i}^{*}\right)$$ yield player i an expected payoff greater than her expected payoff to $$\alpha^{*}$$.   没有动作, 收益大于 均衡策略的收益.

连续动作博弈中很重要的一类是 动作空间是 一维数字区间 one-dimensional interval of numbers.  考虑一个2人博弈, player $$i$$ 's set of actions be the interval from $$\underline{a}_{i}$$ to $$\bar{a}_{i},$$ for $$i=1,2$$  . 每人的混合策略就是这个区间上的 累积概率分布函数 cumulative probability distribution.  即 $$F_{i}\left(a_{i}\right)$$ 是玩家i action最大到 $$a_{i}$$ 的概率.

以下这种形式的博弈, 有一些均衡比较简单. 每个玩家在均衡策略之外的区域指派概率为0.  混合策略pair $$\left(F_{1}, F_{2}\right)$$ 满足:

- 只在 $$x_{i}$$ to $$y_{i}$$ 之间分配概率,  $$F_{i}(z)=0$$ for $$z<x_{i},$$ and
$$
F(z)=1 \text { for } z \geq y_{i}
$$
- 当自己选 $$a_{i}$$ , 对方混合策略 $$F_{j}$$ , 收益为 ,  即 x,y之间的收益是最大的
$$
\left\{\begin{array}{ll}
=c_{i} & \text { for } x_{i} \leq a_{i} \leq y_{i} \\
\leq c_{i} & \text { for } a_{i}<x_{i} \text { and } a_{i}>y_{i}
\end{array}\right.
$$

第二个条件如下图 141.1  即, 玩家都在x,y之间, 收益是到顶的, 同时混合策略在x,y之间分配概率. 则该混合策略是均衡策略.

![image-20201215115928320](/img/2020-04-18-Game.assets/image-20201215115928320.png)



下面这个例子是过分简化的, 分析是不完全的, 因为只求了一个均衡,而不是分析所有均衡(虽然该例只有一个均衡)

EXAMPLE 141.1 (All-pay auction 全部支付拍卖) 

两个人对一个价值 $$K$$的物品提出密封投标。如果出价相同，每个人将得到该物品的一半, 价值 $$\$$ K / 2 .$$ 无论是否赢, 出价都不返还.  这种情况可以建模为 all-pay auction.

收益函数为:
$$
u_{i}\left(a_{1}, a_{2}\right)=\left\{\begin{array}{ll}
-a_{i} & \text { if } a_{i}<a_{j} \\
K / 2-a_{i} & \text { if } a_{i}=a_{j} \\
K-a_{i} & \text { if } a_{i}>a_{j}
\end{array}\right.
$$
where $$j$$ is the other player.

可以作为这种拍卖模型的一种情况是游说过程，在这个过程中，两个利益集团各自花费资源说服政府执行其喜欢的政策，花费最多的集团获胜。另一种可以作为这种拍卖的模型的情况是两个公司竞争在某一期限前开发一种新产品，在这种情况下，花费最多的公司开发出更好的产品，从而占领整个市场。

由如下的讨论，全部支付拍卖没有纯策略纳什均衡。

- $$(x, x)$$ with $$x<K$$  不可能是均衡, 因为任何一个玩家都可以通过略微提高自己的出价来增加自己的收益。
- $$(K, K)$$  不是均衡, 因为其中一个人可以0投入, 从而是收益 $$-K / 2$$ 变成 0
- $$\left(a_{1}, a_{2}\right)$$ with $$a_{1} \neq a_{2}$$  不可能是均衡(首先不对称).  因为出价高的, 会降低自己的报价, 出价低的会不出价,都可以增加收益.

考虑到游戏有一个混合策略纳什均衡的可能性。用$$F_{i}$$表示玩家$$i$$的混合策略（即可能出价区间的累积概率分布）。下面寻找一个均衡，每个混合策略都没有给任何一个投标赋予正概率。记住，可能的出价有无限多。在这种情况下，$$F_{i}\left(a_{i}\right)$$是指玩家$$i$$出价最多为$$a_{i}$$的概率和她出价小于$$a_{i}$$的概率。  下面考虑策略组合$$\left(F_{1}, F_{2}\right)$$  , 在from $$x_{i}$$ to $$y_{i}$$ 的区间上指派正概率.

给定P2的混合策略 $$F_{2}$$ , P1的收益为:
- If $$a_{1}<x_{2}$$ then $$a_{1}$$ 必定 < P2's bid, P1's payoff is $$-a_{1}$$
- If $$a_{1}>y_{2}$$ then $$a_{1}$$ 必定 > P2's bid,  P1's payoff is $$K-a_{1}$$
- If $$x_{2} \leq a_{1} \leq y_{2}$$ , P2's  bid< $$a_{1}$$ 的概率为 $$F_{2}\left(a_{1}\right)$$ , P1's payoff is $$K-a_{1} ;$$ P2's  bid> $$a_{1}$$ 的概率为 $$1-F_{2}\left(a_{1}\right)$$ ,P1's payoff is $$-a_{1}$$; 基于假设, P1 与P2 报价完全相等的几率是0,  所以P1的收益为
$$
\left(K-a_{1}\right) F_{2}\left(a_{1}\right)+\left(-a_{1}\right)\left(1-F_{2}\left(a_{1}\right)\right)=K F_{2}\left(a_{1}\right)-a_{1}
$$
我们需要找到P2的 $$x_{2}$$ and $$y_{2}$$ and a strategy $$F_{2}$$ , 使得P1的收益满足图141.1的左边, 即在 $$x_{1}$$ to $$y_{1},$$  收益是常数, 之外,要小于等于该常数.  即需要 $$\mathrm{KF}_{2}\left(a_{1}\right)-a_{1}=c_{1}$$ for $$x_{1} \leq a_{1} \leq y_{1},$$ 同时$$\bar{F}_{2}\left(x_{2}\right)=0$$ ,  $$F_{2}\left(y_{2}\right)=1$$ 

我们发现, 如果 $$x_{1}=x_{2}=0, y_{1}=y_{2}=K,$$ and $$F_{1}(z)=F_{2}(z)=z / K$$ for all $$z$$ with $$0 \leq z \leq K$$ ,  满足上面所有条件.  每个玩家的预期收益是常数0  for all her actions $$a_{1}$$.

所以,该博弈有一个混合策略均衡, 每个人在其action空间上均匀的随机化. 该均衡中,每个人的预期是0, 即 平均来说,每个人的花费正好等于其收到的物品价值. 





#### 4.12  Appendix: Representing preferences by expected payoffs    附录：以期望盈利体现优先选择



### 5 Extensive games with perfect information: Theory 完全信息展开型博弈：理论

策略型博弈模型没有考虑决策的**时序sequential** 结构。当把这个模型应用到决策者 会有时序行动的情况时，我们假定每一个决策者"一劳永逸"地选择了他的行动计划, 随着事件的展开，他不能修改计划。  
相反，**展开型博弈 extensive games**模型清晰地描述了决策的sequential 结构，随着事件的展开，每个决策者可以自由地改变自己的决策。

反推归纳法, 显然只对完全信息才可行.    game tree的每一步都像下棋, 所以优劣可以从最后反推回来.  

ps , **策略博弈无法建模为完全信息的展开型博弈, 可以建模为不完全信息的展开型博弈**;   因为是回合制, 所以混合策略在这种博弈中没有用武之地.   或者说都时纯策略均衡, 不存在混合策略均衡.



#### 5.2 Extensive games with perfect information 完全信息展开型博弈

##### 5.2.1 Definition

之前只需 玩家集与偏好;  现在需要说明 玩家的动作次序,  和在每个时刻每个玩家可能采取的行动。为了做到这一点，需要详细说明所有可能发生的行动序列的集合，以及在每个序列中每个时刻采取该动作的玩家.  我们称每个可能的动作序列sequence of actions为**终端历史terminal history**.  在 terminal history的每个时刻指出是哪个玩家的函数叫 **player function**.    terminal history 就是包含结束的从头到尾的历史.

一般地说，假设（C，D）和（C，E）是终端历史，玩家函数将P1分配给游戏开始时，玩家2分配给历史C时刻之后，那么P1在游戏开始时选择了C后，玩家2可以使用的两个动作是D和E。一个游戏的终端历史记录被指定为一组序列。但不是每一个序列集都是合法的终端历史集。例如，如果(C，D)是终端历史，那么指定C为终端历史是不对的：事实上，(C，D)是终端历史意味着，在游戏开始时选择了C之后，有的玩家可能会选择D，这样，C的动作就不会结束游戏。更一般地说，作为终端历史的**真子历史 proper subhistory**的序列本身不能成为终端历史。这个限制是我们唯一需要对一个序列集施加的限制，以便这个序列集可以被解释为终端历史的集合。

为了精确地陈述这个限制，定义行动的一个有限序列$\left(a^{1}, a^{2}, \ldots, a^{k}\right)$ 的"**子历史 subhistories**"是 空, $\varnothing$ (表示博弈的开局) , 和 所有形式为 $\left(a^{1}, a^{2}, \ldots, a^{m}\right)$ $1 \leq m \leq k$ ; 同理也可以定义无限序列的. 

不等于整个序列的子历史 称为**真子历史 proper subhistory** ; 一个行动序列，它是某个终端历史的子历史，简单地称作 "**历史 history**"。 

**子历史都是包含开头的 ; 真子历史,  含头不含尾** , 



**DEFINITION** 153.1 (**Extensive game with perfect information**) An extensive game with perfect information consists of   **完全信息的展开型博弈** 的要素

- a set of **players**
- a set of sequences (**terminal histories**) with the property that no sequence is a proper subhistory of any other sequence  终端历史集合;  因为是终端历史, 所以肯定不是其他的真子历史
- a function (**player function**) that assigns a player to every sequence that is a proper subhistory of some terminal history ;  **即P(真子历史) = 该时刻玩家**;  
- for each player, **preferences** over the set of terminal histories.  关于终端历史集合的偏好

就策略型博弈来说，我们可以通过给出一个描述偏好的收益函数来确定玩家的偏好;  某些情况下，结果与每个终端历史相连，玩家的偏好自然地定义在这些结果上，而不是直接地定义在终端历史上。



EXAMPLE 153.2 (Entry game 进入博弈)  建模

- **Players** The challenger and the incumbent. 挑战者和在位者。
- **Terminal histories** $(\text {In, Acquiesce}),(\text {In, Fight}),$ and Out.  
- **Player function** $P(\varnothing)=$ Challenger and $P(\operatorname{In})=$ Incumbent.
- **Preferences**   挑战者的偏好: $u_{1}$ ,  $u_{1}(\text { In, Acquiesce})=2, u_{1}(\text { Out })=1,$ $u_{1}(\operatorname{In}, \text { Fight})=0$  
  在位者的偏好 $u_{2}$ ,   $u_{2}(\text { Out })=2, u_{2}(\text { In, Acquiesce})=1,$ $u_{2}(\operatorname{In}, \text { Fight})=0$

这个博弈可以用一个图表示:  最上层的小圆圈,表示开始时 历史是空. 下面的节点都是黑点.



![154](/img/2020-04-18-Game.assets/image-20201217152126756.png)

Definition 153.1 没有直接指定玩家在其行动时可供选择的行动集。但可以通过推导出该集合，可以由终端历史集以及玩家函数推断出 玩家在某个时刻的可选动作集. 
$$
A(h) = \{a: (h, a) \text{ is a history } \}
$$

如上例, 历史有 $\varnothing, \operatorname{In},$ Out, $(\text { In, Acquiesce})$ and $(I n, \text { Fight})$ ;   
可选动作集:   $A(\varnothing)=\{I n, O u t\},$ $A(I n)=\{\text {Acquiesce}, \text { Fight}\}$



Definition 153.1允许终端历史是**无限长**的。(树的深度是无限的)因此，我们可以使用展开型博弈的模型来研究参与者在做决策时不考虑任何特定的固定长度horizon的情况。  
如果最长的终端历史的长度事实上是有限的，我们就说该博弈有一个**finite horizon**。

即使一个finite horizon的game，仍然可能有 无限多个 terminal histories，  因为玩家可能有 无限多个 action。（刚才是树的深度无限，现在是树的广度无限）。 如果一个博弈有 finite horizon，并且 有限多个 terminal histories， 则称该博弈是 **有限博弈 finite**. 

**完全信息**展开型博弈 extensive game with **perfect information**： 一个玩家在选择action的时候，知道之前所有被选择的action历史（完全信息） ， 并且总是单独行动，不与其他人同时行动（回合制）.



##### 5.2.2 Solutions  完全信息展开型博弈的解法

之前的进入博弈，"挑战者将进入和随后在位者将默许"似乎是很清楚的。挑战者可以这样推理, 如果自己进入，那么在位者将会默许，因为这样做的话对于在位者来说比斗争要好些。考虑到在位者将会以这种方式应对进入，挑战者进入会使自己处境更好。

论证的思路称为<mark><b>反向归纳法 (backward induction)  反推</b></mark>。每当玩家必须行动时，**对于他的每一个可能的行动，他推断玩家(包括他自己)随后会理性采取的行动，并且选择一个行动以产生他最喜欢的终端历史。**虽然反向归纳法可以适用于上例中的博弈，但是它**不能适用于每一个 完全信息展开型博弈**. 

下面就是反向归纳法的缺陷:



- 2个收益一样, 无法确定选哪个:对这个变体, 如果挑战者进入，在位者不在乎默许还是斗争。反向归纳法没有告诉挑战者，在这种情况下在位者将采取什么行动，于是留下来一个未解的问题:挑战者应选择什么行动.     
  ![156](/img/2020-04-18-Game.assets/image-20201217204145528.png) 
- 无限长,无起点: 具有无限长历史的博弈提出了关于反向归纳法的另一个难题:没有一个终端可作为归纳的出发点。  
- 同时行动: 完全信息展开型博弈的一个推广-- 允许玩家同时行动还提出了另一个问题:当玩家同时行动时，我们一般不能直接推断每个玩家的最优行动。   现在是回合制.

另一种定义均衡的方法是从纳什均衡的概念出发。试图对 能够在稳定状态下持续存在的行为模式 建模。由此得出的均衡概念**适用于所有**具有完全信息的展开型博弈。下面讨论的是**稳态方法**。在反向归纳法适用的博弈中，其结果与 稳定状态方法的结果一样. 

稳态方法 > 反向归纳法



#### 5.3 Strategies and outcomes  策略和结果

##### 5.3.1 Strategies 策略

展开型博弈的**关键概念是策略**。玩家的策略表明了对于每一个历史(在这个历史之后轮到他行动)玩家所选择的行动。

**DEFINITION** 157.1 (**Strategy**) A strategy of player i in an **extensive game with perfect information** is a function that assigns to each history h after which it is player i’s turn to move (i.e. P(h) = i, where P is the player function) an action in A(h) (the set of actions available after h).

下图是个例子. 表格是玩家2的所有可能策略.   解释为， 如果P1选C，干啥，P1选D，干啥。 

<img src="/img/2020-04-18-Game.assets/image-20200506185714297.png" alt="image-20200506185714297" style="zoom: 33%;" />



在一些博弈中，**strategies** are **more** than **plans of action**。  strategy 在有很多走不到的node也是要有对策的, 方便理论分析。

<img src="/img/2020-04-18-Game.assets/image-20200507002112934.png" alt="158" style="zoom: 33%;" />

图158， P1， 在每个情况下有2个action，所以有4个 strategies: CG (表示起点选 G, (C, E)后选G), CH, DG, and DH. 特别的是， 每个strategy 都指定了 历史(C, E)之后要选的action，尽管选了D以后， (C, E)不会发生。

**定义157.1 (Strategy) 要求任何玩家的策略在 每一个 历史 之后都指定了一个动作，即使对于 执行该策略过程中没有发生的历史也一样**。  即， **每种情况都要有对策， 无论该情况是不是会发生!**

为什么不使用  "plan of action" , 正如下节讨论的纳什均衡的概念, 的确可以使用   plans of action rather than strategies.  但是,我们将看到, 扩展博弈的均衡概念并不令人满意(该概念取决于玩家的完整战略full strategies), 后面会详细讨论strategy 的解释.   目前，可以把玩家的一个strategy 看作是一个计划(plan of what to do)，不管其他玩家做什么，可能该玩家执行了她的预期行动，也可能她犯了错误，但都要去执行计划。  
上面的DG可以这么理解， "我打算选择D ，可是假使我犯了错误选择了C ，那么之后我将选G " 。 



##### 5.3.2 Outcomes  结果

strategy profile 决定了 **terminal history** (不考虑随机).  记策略组合strategy profile为 $s$ ,   
player function为 $P$.  起始玩家 $P(\varnothing)$ , 其 strategy 记为 $s_{P}(\varnothing),$ 选择 action $s_{P(\varnothing)}(\varnothing)$ , 记为 $a^{1}$.   
如果历史history $a^{1}$ 不是 terminal, 后继玩家 $P\left(a^{1}\right)$ 行动, 策略为 $s_{P\left(a^{1}\right)}$,  action $s_{P\left(a^{1}\right)}\left(a^{1}\right)$, 记为 $a^{2}$.    
若 $\left(a^{1}, a^{2}\right)$ 不是终端, 则继续..直到terminal. 
将 terminal history 称为 $s$ 的**outcome 结局**, 记为 $O(s)$ 

例如158.1, outcome of the strategy pair $(DG, E)$  (DG 表示P1第一次选D，第二次选G) is the terminal history $D,$ and the outcome of $(C H, E)$ is the terminal history $(C, E, H)$    

注意, 策略组合 $s$ 的 **结果$O(s)$ 仅仅依赖于玩家的行动计划plans of action, 而不是他们的全部策略。**为了确定$O(s)$，我们不需要参考任何玩家的策略中指定他在被该策略排除的历史之后的行动的任何组成部分。  即, 有一些节点，已经被玩家的策略排除了，显然这些节点上的策略就没啥实际用处了。 就是上面讨论的 **strategies** are **more** than **plans of action**。 



#### 5.4 Nash equilibrium 纳什均衡

对于策略博弈，纳什均衡是对玩家在**稳定状态steady state**下的行为建模。也就是说，我们寻找的行为模式是，**如果每个玩家都知道其他玩家的行为，那么他没有理由改变自己的行为。**

对展开型博弈, 首先定义了一个纳什均衡：考虑到其他玩家的策略，没有任何一个玩家希望偏离这个策略组合。这个定义是对战略博弈中的纳什均衡的改编（21.1）。

**DEFINITION** 159.2  (**Nash equilibrium of extensive game with perfect information**) The strategy profile $$s^∗$$ in an extensive game with perfect information is a **Nash equilibrium** if, for every player $$i$$ and every strategy $$r_{i}$$ of player $$i$$, the terminal history $$O\left(s^{*}\right)$$ generated by $$s^{*}$$ is at least as good according to player $$i^{\prime}$$ s preferences as the terminal history $$O\left(r_{i}, s_{-i}^{*}\right)$$ generated by the strategy profile $$\left(r_{i}, s_{-i}^{*}\right)$$ in which player $$i$$ chooses $$r_{i}$$ while every other player $$j$$ chooses $$s_{j}^{*} .$$  
Equivalently, for each player $$i$$ ,     
$$u_{i}\left(O\left(s^{*}\right)\right) \geq u_{i}\left(O\left(r_{i}, s_{-i}^{*}\right)\right)$$ for every strategy $$r_{i}$$ of player $$i$$ ;   
where $$u_{i}$$ is a payoff function that represents player $$i$$ 's preferences and $$O$$ is the outcome function of the game. 

**完全信息展开型博弈的纳什均衡** :   $$u_{i}\left(O\left(s^{*}\right)\right)$$ 替换掉之前的 $U_{i}\left(\alpha^{*}\right)$

若 $$u_{i}\left(O\left(s^{*}\right)\right) \geq u_{i}\left(O\left(r_{i}, s_{-i}^{*}\right)\right)$$  	对每个玩家$i$的每个策略$r_i$都成立 , 则策略组合 $$s^∗$$ 是一个纳什均衡.  



> 重要例子！ 走不到的node, 其信念怎么获得.   这个在策略博弈中,大家同时出招的时候是不存在的. 因为现在是回合制, 存在先后出招, 所以先出招的, 怎么判断自己未选取的路径上, 对方会怎么应对, 因为未选取的路径上对方如何应对, 会影响该路径的收益, 进而会影响到当前节点上的策略.

![154](/img/2020-04-18-Game.assets/image-20201217152126756.png)

例 160.1 (Nash equilibria of the entry game) **进入博弈的纳什均衡**.  有两个纳什均衡, (In, Acquiesce) and (Out, Fight).   建模为策略博弈, 收益表如图:   
第一个 可以由backward induction求得.    
第二个均衡，挑战者总是选择"在外"。给定在位者进入后选择斗争的策略，"在外"是最优的策略。 给定挑战者选择"在外"策略，在位者选择"斗争"策略是最优的; 在位者选择"默许" 或"斗争"对于他的收益是一样的。于是，没有一个玩家可以在给定其他玩家策略的情况下，通过选择不同的策略而增加自己的收益。 所以第二个均衡点成立.    
但根据第一个均衡,可知, 如果P1选In, P2只会默许, 所以这个根据 纳什均衡定义得到的均衡是有点问题的,不现实的!!

<img src="/img/2020-04-18-Game.assets/image-20200507014031558.png" alt="image-20200507014031558" style="zoom: 33%;" />

按照策略博弈的模型, 根据上面的收益表，把P2在P1Out之后的action都列出来了，然后按照之前的表格星号法来求均衡。(Out, Fight) 可以理解是虚的。 因为这个点成立的基础是，P2坚持Fight, 这时 P1基于这个信念才选out， 但如果P1选In， P2实际上不会fight ； **robust** 的概念

纳什均衡(Out, Fight) 在展开博弈中出现了一个问题的, 而在策略博弈形式中不会出现。  
该问题是:挑战者如何知道如果他进入的话，在位者将选择"斗争"呢?  如果建模为策略博弈, 那么解释是 :每当挑战者参与博弈时，即使他选择"在外"也会观察在位者的行动。   
相对的，这样解释展开型博弈: 总是选择"Out"的挑战者从未观察到在位者的行动，因为在位者不会行动。  
在策略型博弈中"在给定其他玩家策略时，每个玩家的策略是最优的"。这个纳什均衡条件的基本原理是，在稳定状态中，每个玩家参与博弈的**经验**导致他关于其他玩家行动的**信念**是正确的.  
这个道理不适用于(展开型)进入博弈的纳什均衡点 (Out, Fight) ，因为总是选择"在外"的挑战者绝不会观察到在历史"进入"之后的在位者的行动。所以就**学习不到这个经验**.

通过考虑一个带有稍稍扰动的稳定状态，我们就可以避免解释展开型博弈纳什均衡中的这个困难，在极少数情况下，会采取非均衡的行动(也许犯错误，或者是故意这么试试) ，而这些扰动使得每个玩家最终可以观察到每一个历史后的其他玩家的行动。鉴于这样的扰动，每个玩家最终都会学习到其他玩家的整个策略。 **相当于探索,强化学习的epsilon,并学习.**  
但是，如果将均衡 (Out, Fight)解释为这种带扰动的稳定状态，又会遇到另一个问题。在那些(极端)场合，当挑战者进入后，在位者随后选"斗争", 并不是稳定状态: 如果挑战者进入，在位者 默许 比起 斗争 来会使自己的境况更好一些。也就是说，纳什均衡 (Out, Fight)并不对应于展开型博弈**稳健 (robust)的稳定状态**。 说明某些纳什均衡策略可以在其路径上的node都取到最优，但不够robust，比较虚，可能建立在空想之上，因为必须给定双方的策略，实际走到那些node，可能有人改变策略造成均衡失效。

不**robust**， 是说， 一开始(Out, Fight)， 然后P1突然变成 In，则P2 会偏离to 默许 。 

注意，展开型博弈体现了这样的假设,  在博弈开始时，P2不能先表态"如果P1进入的话就斗争", 则在这种情况下，P2可以自由地选择默认或战斗。如果P2能够保证在P1进入的情况下fight，那么分析就会不同。这种保证**Commitment** 将促使P1不去Enter，而这正是P2更愿意看到的结果。在P2不可能作出保证的情况下，我们可能会想到它在游戏开始时宣布它打算fight；但这种威胁是不可信的，因为在挑战者进入后，现任者的唯一有利的是选默许。(因为P2是绝对理性)



#### <mark><b>5.5 Subgame perfect equilibrium 子博弈完美均衡</b></mark>
纳什均衡 并不一定 会包含  子博弈完美均衡。 两个可能不一样， 第十章有例子。

非常重要!!!!   这里有bellman公式的思想了.  也是因果律, 不管之前发生了什么, 只要从现在开始利益最大化.

##### 5.5.1 Definition
所以，对展开型博弈，去求之前定义的纳什均衡， 不是很合适了， 得求下面的 子博弈完美均衡。

纳什均衡概念忽视了展开型博弈的有序结构，其策略为在博弈开始之前一劳永逸地做出选择。结果是，前一节所提到的，纳什均衡对应的稳定状态可能不稳健 **robust**。

现在，定义 **equilibrium** that models a **robust steady state**。这个概念要求在**给定其他人的策略**情况下，每个人的策略<mark>不仅在博弈开始时，而且在<b>每一个历史(每个子博弈)上</b>都是最优的</mark>。

先定义**子游戏 subgame** :  对于任意非终端历史$h$，跟随在$h$后的子博弈(subgame)是发生$h$之后留存下来的博弈部分。 即某时刻h之后剩下的全部.

**DEFINITION** 162.1(**Subgame**)​  Let $\Gamma$ be an extensive game with perfect information, with player function $P .$ For any **nonterminal history** $h$ of $\Gamma,$ the **subgame** $\Gamma(h)$ **following** the history $h$ is the following extensive game.     subgame就是h之后的subtree。

- **Players**  The players in $\Gamma$ 
- **Terminal histories**  The set of all sequences $h^{\prime}$ of actions such that $\left(h, h^{\prime}\right)$ is a terminal history of $\Gamma$

- **Player function** The player $P\left(h, h^{\prime}\right)$ is assigned to each proper subhistory $h^{\prime}$ of a terminal history.

- **Preferences**  Each player prefers $h^{\prime}$ to $h^{\prime \prime}$ if and only if she prefers $\left(h, h^{\prime}\right)$ to $\left(h, h^{\prime \prime}\right)$ in $\Gamma$

注意, 空历史 $\varnothing$ 的后面的子博弈是**整个博弈自身**. 其他的每个子博弈都称为**真子博弈 proper subgame**. 由于对每一个非终端历史都存在一个子博弈，所以<mark><b>子博弈个数等于非终端历史的个数</b></mark>。



图157有3个非终端历史histories (the initial history, C, and D) ,因此有3个 subgame , 2个真subgame

<img src="/img/2020-04-18-Game.assets/image-20200506185714297.png" alt="157" style="zoom: 33%;" />

![image-20201203230003286](/img/2020-04-18-Game.assets/image-20201203230003286.png)

图158 有3个非终端节点, , 2个真subgame

<img src="/img/2020-04-18-Game.assets/image-20200507002112934.png" alt="158" style="zoom: 33%;" />

![image-20201204114634454](/img/2020-04-18-Game.assets/image-20201204114634454.png)



下面每个人不光应对整个博弈, 而是要先应对各个子博弈. 

<mark><b>子博弈完美均衡</b></mark>,   一个策略组合$$s^*$$, **在任何的子博弈中, 都是纳什均衡**.	A **subgame perfect equilibrium** is a strategy profile  $$s^*$$  with the property that in no subgame can any player $i$ do better by choosing a strategy different from $$s^*_i$$ , given that every other player j adheres to  $$s^*_j$$. 

子博弈完美均衡，要求一个策略组合， 对**所有的子博弈**，都是纳什均衡。

> 首先， 展开博弈与策略博弈，不一样的一个点是， 策略博弈的均衡，某个人偏移一下，那之后进入的格子就是最终结果，会造成主动偏移的人损失。 而展开博弈不一样，通过 策略博弈表格法算出来的均衡, 可能不robust, 即 某个人从  (Out, Fight) 偏移之后，还有后继的发展，可能会让最早偏移的人得利，所以 (Out, Fight)就不是完美均衡点。
>

Nash equilibrium (Out, Fight)  (Example 152.1) 就不是一个 完美均衡.  因为在"进入"之后的子博弈中，策略"斗争"对在位者并不是最优的, 在这个子博弈中，在位者选择"默许"比选择"斗争"会使自己的处境 更好一些。 (In, Acquiesce) 则是一个完美子博弈均衡， 给定另外一个人的策略，无论在整个游戏，还是在In之后的subgame，都是最优。



为了精确地定义子博弈完美均衡概念，需要一个新的记号, 表示 subgame的收益  $u(O_{h}(s))$.  
$h$ :  history ;    $s$  :  strategy profile ;    
假设 $h$ 发生了( not necessarily consistent with  $s$ , h 不一定与 s 相容,  即大家按照策略s不一定走到h ) ， 之后的玩家们坚持策略组合  $s$ ， 从而产生 结局  $O_{h}(s) $  ；  
$O_{\varnothing}(s)=O(s)$ (where $\varnothing,$ as always, denotes the initial history).

再次考虑 entry game， 令 $s$ = strategy profile (Out, Fight) ， $h$ = history In.   
If $h$ occurs, and afterwards the players adhere to $s,$ the resulting terminal history is $O_{h}(s)=(I n, Fight  )$.



**DEFINITION** 164.1 (**Subgame perfect equilibrium 子博弈完美均衡**)    
The strategy profile $$s^{*}$$ in an **extensive game with perfect information** is a **subgame perfect equilibrium** if, for every player $$i$$, **every history** $$h$$ after which it is player $$i$$ 's turn to move (i.e. $$P(h)=i$$ ), and every strategy $$r_{i}$$ of player $$i,$$ the terminal history $$O_{h}\left(s^{*}\right)$$ generated by $$s^{*}$$ after the history $$h$$ is **at least as good** according to player $$i^{\prime}$$ s preferences as the terminal history $$O_{h}\left(r_{i}, s_{-i}^{*}\right)$$ generated by the strategy profile $$\left(r_{i}, s_{-i}^{*}\right)$$ in which player $$i$$ chooses $$r_{i}$$ while every other player $$j$$ chooses $$s_{j}^{*} .$$   
Equivalently, for every player $$i$$ and every history $h$ after which it is player $i$ 's turn to   
$$
u_{i}\left(O_{h}\left(s^{*}\right)\right) \geq u_{i}\left(O_{h}\left(r_{i}, s_{-i}^{*}\right)\right) \text { for every strategy } r_{i} \text { of player } i
$$

where $u_{i}$ is a payoff function that represents player $i^{\prime}$ s preferences and $O_{h}(s)$ is the terminal history consisting of $h$ followed by the sequence of actions generated by s after $h$.

<mark>这个定义的<b>关键</b>是要求每个玩家的策略对于<b>每个历史</b>(在该历史之后轮到该玩家行动)是最优的，而不是像(159.2)纳什均衡的定义那样<b>只是在博弈开头</b>是最优的。  即对<b>所有节点h后的subgame</b>，策略都要收益最优。</mark>



##### 5.5.2 Subgame perfect equilibrium and Nash equilibrium 子博弈完美均衡和纳什均衡

在子博弈完美均衡中，每个人的策略是最优的。特别地，其在空历史($O_{\varnothing}(s)=O(s)$)之后是最优的. 

**每个子博弈完美均衡都是纳什均衡。**

**子博弈完美衡是在每个子博弈中导致纳什均衡的策略组合。**

在纳什均衡中，给定其他玩家的均衡策略，对整个博弈(即从起始点出发$O_{\varnothing}(s)$)，每个玩家的策略都是最优的。我们已经看到，在某些subgames下，它可能不是最优的。然而，可以断言，**当玩家们遵守这些均衡策略的时候， 在任何一个 可以到达 的subgame中，它都是最优的。** 根据这个断言,  相对于纳什均衡定义中的要求，  **子博弈完美均衡要求在 不能到达 的历史上也是最优。** 其意义在于，每个玩家的子博弈完美策略在未发生的历史之后都是最优的，如果玩家遵循他们的策略 (比如在进入博弈开始时, P1的行动是Out时的 历史In)。

书里对上面的断言做了简单的证明。 其实就是每个人都按次序走自己的均衡策略，最大化自己的收益。	这个一般性原理就是动态规划中的"最优化准则" Principle of Optimality in dynamic programming。

##### 5.5.3 Examples 例题

EXAMPLE 165.1 (Entry game)  考虑例 152.1 ,2个纳什均衡: (In, Acquiesce) , (Out, Fight).   (Out, Fight) 不是子博弈完美均衡. 

证明:  For $$s^{*}=(Out, Fight)$$,  $$i=Incumbent $$, $$r_{i}= Aquiesce $$, and $$h=In,$$ we have $$O_{h}\left(s^{*}\right)=(I n, Fight )$$ and $$O_{h}\left(r_{i}, s_{-i}^{*}\right)=(In,Acquiesce)$$ , 因为 $$u_{i}\left(O_{h}\left(s^{*}\right)\right)=0$$ and $$u_{i}\left(O_{h}\left(r_{i}, s_{-i}^{*}\right)\right)= 1$$ 违反了上面定义中的不等式.

纳什均衡 (In, Acquiesce) 是子博弈完美博弈, 因为   
(a) 它是纳什均衡, 所以起点开始, P1是最优的. 给定P2选Acquiesce 
(b) 历史 $$I n$$ 之后, P2选Acquiesce 在subgame 里是最优.    
用数学语言描述,  略. 

**EXAMPLE** 166.1 (Variant of entry game)  考虑进入博弈的变体，如果挑战者P1进入，P2在战斗和默许之间无所谓（见图156.1）。这个博弈和原始版本的博弈一样，有两个纳什均衡，（进入，默许）和（Out，战斗）。但现在这两个均衡都是子博弈的完美均衡，因为在历史In后,  Fight和Acquiesce都是P2的最优策略 ;  
这里跟之前相反, 这个(Out,Fight) 如果按策略走是走不到In这个node的, 但子博弈完美要求所有历史都完美!!

![156](/img/2020-04-18-Game.assets/image-20201217204145528.png) 



##### 5.5.4 Interpretation 解释

策略型博弈的纳什均衡相当于理想化模型的一个**稳定状态**。  
**子博弈完美均衡**对应于一个**稍有扰动的稳定状态**，其中， 所有人在很少的极端情况下采取非均衡行动，这样，经过长期的经验积累，每个人对于其他人的整个策略形成正确的信念，知道其他人在每个子博弈中将如何动作。给定了这些倍念，没有一个人会在博弈开始或任何历史之后希望偏离自己的策略。  可以理解为 epsilon-greedy 探索慢慢收敛.  
子博弈完美均衡的这个解释，如同纳什均衡为稳定状态的解释一样，不要求知道其他人的偏好，也不要求先考虑其他人的理性。它需要将策略解释为一个计划，该plan不仅在与策略相容consistent 的历史之后，而且在玩家选择任意的替代行动时产生的历史之后 , 指定玩家的行动 .   即 子博弈完美策略, 可以视为一个 带点探索的 策略.(因为需要在那些不相容的node上也取到最优). 

一些展开博弈的子博弈完美均衡可以被赋予其他解释。下面这个比较好, 考虑一个完全信息的展开博弈，其中每个玩家在每一个该自己行动的历史上都有一个独特的最佳动作，并且该博弈是有限的。在这样的游戏中，一个知道其他玩家喜好的玩家 并知道其他玩家都是理性的，可以用 反向归纳法 推导出她的最优策略，如5.2.2节所述。 因此，可以将子博弈完美均衡解释为玩家对彼此策略的理性计算结果。   
这个解释是有局限性的 , 不适用于无限博弈以及 信息不完全展开博弈. 但其延伸可以用于求解有限博弈的全部子博弈完美均衡. 



#### 5.6 Finding subgame perfect equilibria of finite horizon games: backward induction 
Examples 165.1 and 166.1 可以使用之前的求均衡策略的方法，再验证每一个是不是subgame完美均衡；    
对有限长(finite horizon)的game tree求完美均衡，可以使用反向归纳法。



<mark>求有限范畴博弈的子博弈完美均衡：<b>反向归纳法</b> , 先从最短长度的子博弈求最优开始..   </mark>   

定义"子博弈的长度 length of a subgame"为子博弈中**最长**的历史长度。反推自纳法操作如下: 
通过寻找长度为 1 的子博弈("最后的"子博弈) 中玩家的最佳行动开始。然后，把这些行动看作为**给定**的;  
再找长度为 2 的子博弈中首先行动的玩家的最佳行动。
继续直到博弈的起始阶段.   有点类似minimax

例子: 

<img src="/img/2020-04-18-Game.assets/image-20200507045804072.png" alt="168" style="zoom:50%;" />
1.先考虑长度为1的subgame，P2行动，得到 C后选E，D后选H  
2.再考虑长度2的subgame， P1行动， 因为两个子节点的值分别为2，1， 选C  
反向归纳法得到的策略对strategy pair 是 (C,EH)  ,  EH的含义是，面对C选E，面对D选H，不是同时选。

另外一例： 图158.1

<img src="/img/2020-04-18-Game.assets/image-20200507002112934.png" alt="158" style="zoom: 33%;" />

1. 长度1的subgame，在(C,E)之后，P1选G  
2. 选 E  3.  选D   最后得到 (DG,E)



通过反推归纳法得到策略， 如果对每个subgame开始时 , 玩家都只有一个最优action，则该策略组合是该subgame的**唯一** 子博弈完美均衡。

**非常重要！！** 如果， 在subgame开始时， 有超过一个action是最优的，对这种类型的game， **反向归纳法的一个扩展**，可以得到所有的subgame 完美均衡。方法是, 将当前subgame的多个最优action的排列组合反向递推上去.  This extension traces back separately the implications for behavior in the longer subgames of every combination of optimal actions in the shorter subgames.

例子: 图170

<img src="/img/2020-04-18-Game.assets/image-20200507050304696.png" alt="image-20200507050304696" style="zoom:50%;" />

1. 长度1subgame， 有3个，都是P2行动，  E后选K，  其他的分别在C，D后无所谓。  所以有 FHK FIK GHK GIK 四种 （按面对CDE的顺序）
2. 长度2 subgame，即整个game tree， 对长度为1 的subgame P2的每个策略组合， 求P1 的最优action。有如下：
(C, FHK), (C, FIK), (C, GHK), (D, GHK), (E, GHK), and (D, GIK).

<mark><b>反推归纳法</b> </mark>， 下面把该程序整理如下：

1. 对长度1，将subgame编号，记作 $j$，当前玩家的最优action集，记作$$S_j^*(1)$$
2. 通过$$S_j^*(1)$$集合的每一个策略组合 求 长度2的subgame当前玩家的最优action集，然后并成 长度2的subgame的最优策略集，记$$S_l^*(2)$$，$l$ 为subgame编号
3. 以此类推，直到博弈起点;   
这个过程最后产生的整个博弈的策略组合就是 完美均衡集。

**PROPOSITION** 170.1 (Subgame perfect equilibrium of finite horizon games and backward induction) The set of subgame perfect equilibria of a finite horizon extensive game with perfect information is equal to the set of strategy profiles isolated by the procedure of backward induction.
**定理，反推归纳法求出的就是子博弈完美均衡集。**

**PROPOSITION** 171.1 (Existence of subgame perfect equilibrium) Every **finite** extensive game with perfect information has a subgame perfect equilibrium.
**每个有限信息完全博弈，至少有一个子博弈完美均衡。**



<mark><b>必须强调<span style="color:red;">有限 (finite horizon game)</span>，  如果玩家可以有无限多action的，可能没有完美均衡。</b></mark> 
例子，一个平凡博弈trivial game， 只有一个玩家，选择一个小于1的数，并且收益是这个数； 因为找不到小于1的最大数，所以无最优action，也无完美均衡。



### 6 完全信息展开型博弈：例







### 7 完全信息展开型博弈：延伸与讨论

#### 7.1 Allowing for simultaneous moves  同时行动

##### 7.1.1 Definition

回合制与即时制混合， 之前是回合制，其历史大家都共知，决策的时候可能是同时出招。

完全信息的展开型博弈(定义 153.1)模型，假设在每一系列事件后，**单个决策者在已知每个决策者以前行动的情况下采取行动**。现在，我们描述一个更为复杂的模型，它允许我们去研究在某些事件系列后，一组决策者的成员"同时"选择他们的行动。每个成员知道每个决策者以前的行动，但是不知道该组中其他成员同时发生的行动。

例如这样的情况, 即P1选择C或D，然后玩家2和3同时采取行动，各自选择E或F。那么 (C, (E, E))是一个 terminal history. 在一般模型中，玩家函数为每个非终端历史分配了**一组**玩家。在刚才描述的例子中，这组玩家包括初始历史的P1，以及历史C的玩家2和3。



DEFINITION 202.1 **完全信息且同时行动的展开型博弈** An extensive game with perfect information and simultaneous moves consists of

- a set of **players** 一样
- a set of sequences (**terminal histories**) with the property that no sequence is a proper subhistory of any other sequence 一样
- a function (the **player function**) that assigns a **set of players** to every sequence that is a proper subhistory of some terminal history   映射到多个玩家
- for each **proper subhistory** h of each terminal history and each player i that is a member of the set of players assigned to h by the player function, a set $A_i(h)$ (the set of **actions available** to player i after the history h)    在t时刻能行动玩家的所有可用动作集
- for each player, **preferences** over the set of terminal histories  一样



##### 7.1.2 Strategies and Nash equilibrium

例子, BoS变体.  首先，P1决定是留在家里看书还是参加音乐会。如果他读了一本书，游戏就结束了。如果他决定参加一场音乐会，那么，就像在BoS中一样，他和P2在不知道对方的选择的情况下，自主选择是去欣赏巴赫还是斯特拉文斯基。

<img src="/img/2020-04-18-Game.assets/image-20200507114542432.png" alt="image-20200507114542432" style="zoom: 33%;" />



完全信息同时行动的展开型博弈的纳什均衡 定义与 没有同时行动的博弈中的定义(Definition 159.2)一样

EXAMPLE 204.1 (Nash equilibria of a variant of BoS) In the game in Example 203.1 

3个 pure Nash equilibria: ((Concert, B), B), ((Book, B), S), and ((Book, S), S).

记住，玩家的策略比行动计划多 。  下表，把book之后两个人的action都复制到表里了。

<img src="/img/2020-04-18-Game.assets/image-20200507115050848.png" alt="image-20200507115050848" style="zoom: 33%;" />



##### 7.1.3 Subgame perfect equilibrium 子博弈完美均衡

为了求有限的具有完全信息和同时行动的展开型博弈的子博弈完美均衡集，我们可以像以前那样，使用后向归纳法。  一个替换， 同时行动节点的策略对 代替之前某人行动的策略。

EXAMPLE206.1(BoS 变体的纳什均衡) 考虑图204.1中的游戏。逆向归纳的过程如下。

- Concert 后, 有两个纯策略均衡 (S, S) and (B, B) 
- 如果Concert之后的子博弈的结果是 (S, S), 那P1在开始时的最优选择是 Book
- 如果Concert之后的子博弈的结果是 (B, B), 那P1在开始时的最优选择是 Concert

所以结论是, 有两个子博弈完美均衡subgame perfect equilibria: ((Book, S), S) and ((Concert, B), B).





### 8 Coalitional Games and the Core  联合博弈及其核心
主要研究的是怎么分配收益。  **核 core ** 是联盟的纳什均衡。  TODO

#### 8.1 Coalitional games 联合博弈


我们把每一组玩家称为**联盟coalition**，把所有玩家的联盟称为**大联盟grand coalition**。



DEFINITION 235.1 (**Coalitional game 联合博弈**) A coalitional game consists of

- a set of **players**
- for each **coalition**, a set of **actions**
- for each player, **preferences** over the set of all actions of all **coalitions** of which she is a member. 每个玩家, 在所有(其作为成员)的联盟里所有动作集上的偏好. 

常用 $N$ 表示大联盟, 以$S$表示任意一个联盟。可以通过一个描述偏好的收益函数，确定玩家的偏好。

在下面几个例子中，每个联盟控制着某种数量的物品，这些物品可以在其成员之间分配。在这样一个博弈中，联盟S的每一个行动都是S的成员之间对S所控制的物品的分配，我把它称为**S分配**的物品 **S-allocation**。我把N次分配简单地称为**分配 allocation**。

对于每一个人来说，大联盟可能达到的结果比较好(>=)。我的称这样的博弈 为"有凝聚力的cohesive"。



EXAMPLE 236.2 (**Two-player unanimity game 两人一致博弈**)  两个人一起生产一个单位(比如1公斤)的产品，他们以自己希望的任何方式分享。没有一个人可以独自生产任何产品。每个人仅关心自己获得的产品量，并且希望多多益善.

- **Players**  The two people (players 1 and 2).
- **Actions**  每个人单独行动, 但没有产出. 两个人的联合行动集 {1, 2} 是所有非负数集合($x_1, x_2$), 且$x_1 + x_2 = 1 $ 
- **Preferences**  每个人的偏好由其得到的产量来表示.

两个人组成联盟，或者两个人不结盟。action是分配。 


玩家集的可能划分是$$\{\{1, 2\}\}$$，由两个玩家的单一联合组成，以及$$\{\{1\},\{2\}\}$$，其中每个玩家单独行动。后者只有一种行动组合可供其使用，其产出为0。因此，这个游戏是有凝聚力的。

 

EXAMPLE 237.1 (**Landowner and workers 地主和工人**) 当使用是k个工人时，地主的庄园产量为 f(k+1)的食物，其中f是递增函数，且f(0)=0。工人的总数是m;  地主和每个劳动者只关心自己的产量多少，宁多勿少。

- **Players**  landowner and the m workers  地主与m个农民
- **Actions**  一个完全由工人组成的联盟只有一个行动，其中没有成员收到任何产量的产品。一个由地主和k个工人组成的联盟$S$的行动集合是关于产量$f(k+1)$ 在S的成员中间的所有$S$分配的集合。
- **Preferences**  每个人的偏好由其得到的产量来表示.

这个游戏是有凝聚力的，因为大联盟的产出比其他任何一个联盟的产出都要多，而且，对于所有玩家的任何一个划分的集合，只有一个联盟有产出。



EXAMPLE237.2 (**Three-player majority game 三人多数博弈**)   三个人有 1 个单位产品的分配权。组成的任何多数的联盟可以支配该产品的分配。每个人只关心他得到的量。

- **Players**   三个人
- **Actions**   由一个玩家组成的每个联盟都有一个动作，这个动作对玩家没有输出。每个由两个或三个玩家组成的联盟S的行动集就是分配一个单位产品的S分配集。
- **Preferences**  每个人的偏好由其获得量来表示.

这个游戏是有凝聚力的，因为每一个划分的玩家集最多包含一个多数联盟，而这样的联盟的每一个动作，都有一个大联盟的动作，每个玩家的产出至少是一样多的。



在这些例子中，每个联盟S的行动集就是S所能获得的产量的S分配集，每个玩家的偏好用他所获得的产量来表示。因此，我们用一个数字来概括每个联盟的行动集，这个数字等于该联盟所能获得的总产量，可以把这个数字解释为可能在联盟成员之间分配的总 "报酬"。这就是**可转移的收益transferable payoff**。



DEFINITION 236.1 ( **Cohesive coalitional game 有凝聚力的联合博弈**)   



#### 8.2 The core 核

DEFINITION 239.1 (**Core**) The core of a coalitional game is the set of actions $a_N$ of the grand coalition N such that no coalition has an action that all its members prefer to  $a_N$ .

最好的联盟行为集就是核. 





## Part II:  Games with Imperfect Information  不完全信息博弈

### 9 贝叶斯博弈

<mark><b>贝叶斯博弈= 策略博弈+不完全信息 </b></mark>  

贝叶斯博弈可以建模为 不完全信息展开博弈, 不完全信息的部分是不知道对方的偏好类型. 这章随便看看.

#### 9.1 Introduction

贝叶斯博弈,对应于这样的情况 : 博弈开始时, 某些玩家都有一些**状态**, 每个状态对结果的偏好是不一样的. 由于信息不完全,每个人对别人(甚至自己)所处于的状态是不确定的, 只能收到一个 **信号t**,  信号t 就是**类型type**, 即所有人处于哪些状态, 然后再根据自己的 **belief** 对这个type的所属那些state 分配概率. 

state --  与结果的偏好直接相关,  网友玩家的 state的乘积 就是 收益表的个数.

玩家自己可能也不知道自己处于哪个state, 也是看信号, 然后通过 type+belief 确定所有人的state的概率分布.  type与belief 是绑定在一起的, 可以认为 type是belief的key.  



之前的博弈都是基于对对手有着充分的了解， 信念是完全正确。 本章讨论， 对对手了解程度有限， **对手的偏好不确定， 其实就是对对方策略的不确定**，是个概率函数， 该怎么处理。  

核心概念： state， type， signal ，    概念很绕。 优先看例子。

直接的思路， 统计， 推理， 对手建模。

**纳什均衡有一条基本的假设，每个人对其他人的行动持有正确的信念 correct belief。**为此，玩家必须了解他正在参与的博弈;特别是要了解其他人的偏好。在许多情况下, 玩家并不完全了解对手的特征, 比如，讨价还价者可能不太清楚其他人对谈判物品的估价，企业可能不知道对方的成本函数等等。有时候，玩家可能很了解对手的特点，但可能不知道这些对手对自己的特点了解的程度。

本章将介绍"贝叶斯博弈" , 它推广了策略型博弈，将帮助我们去分析如下的情况，**每个玩家不完全了解与他的行为选择有关的环境**。  



#### 9.2 Motivational examples 启发性例子

EXAMPLE 271.1 (**Variant of BoS with imperfect information 不完全信息的 BoS 变体**) 

state, 在这个例子里, 可以指 P2的心理状态, 心情或者其他客观特殊状况,造成了P2选择的偏好是不一样. P1不了解,只能凭经验知道概率.

P1 不能肯定P2 是否愿意一起外出，还是想躲开自己，而P2 和以前例子一样，知道P1 的偏好. 具体地讲，假设P1认为P2愿意与自己外出的可能性有1/2，躲开自己的可能性有1/2(这种判断可能是P1 的经验).  即使我们只对纯策略均衡感兴趣，但由于涉及概率，分析这种情况需要知道玩家关于随机结局的偏好;表格中的数字代表玩家的贝努利收益。



![image-20200507163912064](/img/2020-04-18-Game.assets/image-20200507163912064.png)

这个例子 ，每个方框的label表示相关玩家的视角，1表示是无法区分里面的state。P2的策略是不能确定的； 但如果能确定其类型， 则其策略是确定的。即 当P2处于某个确定性的类型之后， 其对结果的偏好就是固定的，P1的问题是无法确定P2的类型。 处于某个类型的玩家可以使用的是混合策略.

 

我们可以认为存在两种**状态states** , 一个是上图左边对应的伯努利收益, 一个是右边. 玩家2知道自己的状态, P1不知道, 只能每个状态给1/2的几率.

以 1 的角度，P2 有两种可能的"**类型types**"，一种类型的偏好由上图的左表给出，另一种类型的在右边。 1 不知道 2 的类型，所以为了理性地选择自己的行动，必须对每种类型的行动形成一个信念。鉴于这些信念（每种类型的收益表）和他对每种类型的可能性（属于哪种类型的概率）的信念，他可以计算出他对每一个动作的预期回报。例如, P1 觉得如果对方是讨厌自己的类型,对方会选B, 如果对方是喜欢自己的类型,对方会选S, 则自己选B的话, 对方1/2选S, 1/2选B, 所以预期收益为1/2 * 2+1/2 * 0 = 1. 自己选S, 预期收益为 1/2. 计算各种组合, 则得到下表.  其中每一列是两种类型的玩家2的行动组合, 其中第一项是想一起的, 第二项是想回避的.



<img src="/img/2020-04-18-Game.assets/image-20200507164759512.png" alt="image-20200507164759512" style="zoom:50%;" />
这个表，把P2的两种类型的，各种可能策略组合都穷举列出来。
对于这种情况，我们定义**纯策略纳什均衡**为包含三个行动的行动组，其中一个行动是P1 的，还有两个行动分别是P2的两个类型的，具有如下性质:
该均衡策略要求：对P2的各种策略组合都要考虑，都要均衡。

- 给定 两个类型的 P2 的行动， 以及P1 关于状态的信念(即P2在属于哪个状态的概率分布) , P1 的行动是最优的。
- 给定P1 的行动，每一个类型的P2 的行动是最优的。

我们断言，(B, (B, S))是一个纳什均衡； 给定P2的action为（B，S），P1的最优策略为B。 给定P1的策略是B， 从图272中可知， 愿意相遇的类型，最优策略是B，讨厌的最优是S。  所以， 虽然P2的类型是喜欢还是讨厌未知，但都是可以推导出其对P1的最优策略是什么。  
Ps， 这个例子,P2的最优策略非常容易求， P1需要看P2属于那种类型的概率分别是多少。



#### 9.3 General definitions  一般定义

##### 9.3.1 Bayesian games  贝叶斯博弈：信息不完全的策略博弈
A **strategic game with imperfect information** is called a “**Bayesian game**”.  

核心概念 : **state**.    
在不完全信息的定义中，一个关键的组成部分是**状态集**。  
每一个状态都是对玩家相关**特征characteristics**的一个**集合**的完整描述，包括他们的偏好preferences和信息information。 对于玩家认为可能的每一个特征集合，都必须有一个状态。    
ps， 一个state，相当于描述了 一个玩家的一种个性，该个性提现了对各个结果的偏好的集合。

在博弈开始时，一个状态被实现 (即某个玩家的特征被确定了)， 所有玩家观察不到这个状态，不过随后各个玩家收到一个**信号 signal**。  

Denote the **signal** player $i$ receives in **state**  $\omega$ by $\tau_{i}(\omega)$ .   function $\tau_{i}$ is called player $i$ 's **signal function**。 (信号是状态的确定性函数 signal is a **deterministic** function of the state) 。

如果一个状态生成给定的信号 $t_i$ ，则称为与 $t_i$ 一致 (The states that generate any given signal $t_i$ are said to be **consistent** with $t_i$ )。与玩家信号一致的 状态集合的大小，代表了**信息的质量**。The sizes of the sets of states consistent with each of player  $i^{\prime}$  signals reflect the **quality** of player $i^{\prime}$ information.      

- 例如， $\tau_{i}(\omega)$ 对每个 $\omega$ 有不同的返回值,  这时玩家 $i$ 收到信号，表示 state发生了， 根据这个信号， 就可以知道所有玩家相关个性的完全信息
- 另一个极端例子， $\tau_{i}(\omega)$ 对所有 states返回值一样, 那玩家$i$的信号没有传达任何关于状态的信息。
- 如果 $\tau_{i}(\omega)$在某些状态上一样，例如，3个状态，$\omega_{1}, \omega_{2},$ and $\omega_{3},$ 且 $\tau_{i}\left(\omega_{1}\right) \neq \tau_{i}\left(\omega_{2}\right)=\tau_{i}\left(\omega_{3}\right),$ 然后当state是$\omega_{1}$ 的时候，玩家 $i$ 知道是 $\omega_{1},$  其他情况只知道是$\omega_{2}$ or $\omega_{3}$ 中的一个.  

**type + belief = 所有人的state的概率分布**

将 玩家 $i$ 接收到信号$t_i$， 称为玩家 $i$ 的**类型type** $t_i$。 每个玩家都有一个 **置信 belief** 关于 他收到的信号与真实的state 相一致的可能性 likelihood 。   
例如，if $t_{i}=\tau_{i}\left(\omega_{1}\right)=\tau_{i}\left(\omega_{2}\right),$ then type $t_{i}$ of player $i$ assigns probabilities to $\omega_{1}$ and $\omega_{2}$.  给两个状态分配概率。  (A player who receives a signal consistent with only one state naturally assigns probability 1 to that state.)

每个玩家要关注其他人选择的action以及所处的state。 可能不确定state， 所以确定在state概率分布上的偏好 $(a, \omega)$ ， action profile $a$ ， state $\omega .$   可以确定每个 player $i^{\prime}$ 的偏好 preferences，通过 Bernoulli payoff function $u_{i}$ over pairs $(a, \omega) .$  





**DEFINITION** 277.1  A **Bayesian game** consists of

- a set of **players** 
- a set of **states**

and for each player

- a set of **actions**
- a set of **signals**  that she may receive and a **signal function** that associates a signal with each state 每个玩家都会收到信号， 该信号相当于是一个给对手分配 可能处于哪些state
- for each signal that she may receive, a **belief** about the states consistent with the signal (a probability distribution over the set of states with which the signal is associated)  就是各个状态的概率
- a **Bernoulli payoff function** over pairs (a, ω), where a is an **action profile** and ω is a **state**, the expected value of which represents the player’s **preferences among lotteries** over the set of such pairs.



对 例 271.1 建模 

- **Players** The pair of people.
- **States** The set of states is $\{\text {meet, avoid}\}$
- **Actions** The set of actions of each player is $\{B, S\}$
- **Signals**  P1可能收到一个信号，$z$ ; 其 **signal function** $\tau_{1}$ satisfies $\tau_{1}(\text {meet})=\tau_{1}(\text {avoid})=z$ .两个状态的值一样,无法区分;  P2 收到两个信号($m$ and $v$ )中的一个， 其signal function  $\tau_{2}(\text { meet})=m$ and $\tau_{2}(\text {avoid})=v$
- **Beliefs**  P1 收到信号$z$ 后，  给每个state分配概率 $\frac{1}{2}$ ； P2  收到 $m$ 后，概率 1 给state meet， 收到 $v$ ，1给avoid 
- **Payoffs**  每个玩家的收益函数 $u_{i}(a, \text { meet})$ 在图272左边， payoffs $u_{i}(a, \text { avoid })$ 在右边

![image-20200507163912064](/img/2020-04-18-Game.assets/image-20200507163912064.png)



##### 9.3.2 Nash equilibrium

在贝叶斯博弈中，每个玩家选择一组action，对应于其收到的每个信号。 也就是 每个玩家的每个类型都选一个action。

在贝叶斯博弈的纳什均衡中， 每个玩家的每种类型，选的都是最优action， 给定 actions chosen by every type of every other player. 

考虑玩家$i$的类型 $t_{i}$: 对于每一个状态 $\omega$，他知道其他玩家的类型（即知道其他玩家收到的信号）。这些信息，加上他对状态的belief，使他能够计算出他的每一个行动 和 各种类型的其他玩家的每一组行动集 的预期报酬。  
例如，在例 271​ 中，玩家1的信念是每个状态的概率是$\frac{1}{2}$，他知道玩家2的状态是$meet$时类型是$m$ ，状态是$avoid$ 时类型是$v$。因此，如果玩家2的类型$m$选择$B$，玩家2的类型$v$选择$S$，玩家1认为，如果他选择$B$，那么他的预期报酬是$$ \frac{1}{2} u_{1}(B, B, \text { meet })+ \frac{1}{2} u_{1}(B, S, \text { avoid }) $$  
其中$u_{1}$是他在贝叶斯博弈中的报酬函数。(一般来说，他的收益可能取决于状态，但在本例中没体现)。 图 273.1 中第二列的顶层方框给出了这个收益；其他方框给出了玩家 1 的收益。图 273.1 中第二列的顶部方框给出了这个报酬；其他方框给出了玩家 1 选择其他行动 时，与玩家 2 的其他行动组合的报酬。

 在一般贝叶斯博弈中，将类型是 $t_i$ 的玩家$i$ 属于状态 $\omega$ 的belief表示为 $\operatorname{Pr}\left(\omega \vert t_{i}\right) $ ,  每个 类型是 $t_j$ 的玩家$j$  选的action记为 $a\left(j, t_{j}\right) $ ， 玩家$j$ 在state  $\omega$ 的信号是 $\tau_{j}(\omega)$  ,  所以其在state  $\omega$ 的action是 $a\left(j, \tau_{j}(\omega)\right)$ ，(因为玩家不知道其他人的state，只能看到信号). 对每个 state $\omega,$ 这样取action的策略组合记为 $\hat{a}(\omega)$ ;  则 $t_{i}$ 的玩家 $i$ 选择 $a_{i}$ 的期望收益 

$$
\sum_{\omega \in \Omega} \operatorname{Pr}\left(\omega | t_{i}\right) u_{i}\left(\left(a_{i}, \hat{a}_{-i}(\omega)\right), \omega\right)  \tag{279}
$$

$\Omega$  set of states ,  $$\left(a_{i}, \hat{a}_{-i}(\omega)\right)$$ action profile,  every other player $j$ chooses $$\hat{a}_{j}(\omega) $$  

其实就是多了一个 每个人处于什么state的期望加权。   自己的状态概率??



**DEFINITION** 280.1 A **Nash equilibrium of a Bayesian game** is a Nash equilibrium of the strategic game (with vNM preferences) defined as follows.

- **Players** The set of all pairs $\left(i, t_{i}\right)$ where $i$ is a player in the Bayesian game and $t_{i}$ is one of the signals that $i$ may receive. 
- **Actions** The set of actions of each player $\left(i, t_{i}\right)$ is the set of actions of player $i$ in the Bayesian game.
- **Preferences** The Bernoulli payoff function of each player $\left(i, t_{i}\right)$ is given by (279.1)   收益函数是上式. 

就是之前的加上了Bernoulli期望. 





#### 9.4 Two examples concerning information

贝叶斯博弈的概念可以用来研究信息模式如何影响策略互动的结果。

##### 9.4.1 More information may hurt   掌握更多信息也可能不利

若P1知道信息较多，而P2知道这个情况，则P1可能情况更糟。

![image-20201207220512453](/img/2020-04-18-Game.assets/image-20201207220512453.png)

考虑上图的博弈， 其中$0<\epsilon<\frac{1}{2}$ ,   在这个游戏中，有两个state，但没有人知道。  对P1的每一个action，P2的唯一最佳反应是$L$ (收益是 $2-2(1-\epsilon)p$) ,其中$p$表示P1选T的概率。 而P2选$M$和$R$的收益都为 $\frac{3}{2}-\frac{3}{2}(1-\epsilon) p$ ； 然后P1对$L$的BR是$B$。 所以$(B, L)$ 是游戏的唯一纳什均衡，每个玩家的收益为 2。 此博弈没有其他混合策略均衡。

现在博弈有稍微改动， P2可以知道state，即P2的signal 满足  $\tau_{2}\left(\omega_{1}\right) \neq \tau_{2}\left(\omega_{2}\right) .$  这个版本中，唯一均衡是$(T,(R, M))$ ,  P2选的都是严优。 之前P2的收益是2， 现在变成了 $3 \epsilon$ ， 变差了。

为什么会变差， P2的action R, 只在state为  $\omega_{1}$的时候好， action M 只在$\omega_{2}$ 的时候好。 当他不知道state，最优策略是$L$, 收益 好过 M,R 的平均水平,无论P1怎么选.  当P2完全掌握信息后 , 根据信息来制定action, 将导致P1 走向 T. 



##### 9.4.2 Infection  

贝叶斯博弈的概念不仅可以用来模拟玩家对彼此的偏好不确定的情况，也可以用来模拟玩家对彼此的**知识knowledge**不确定的情况。



![image-20201207224344862](/img/2020-04-18-Game.assets/image-20201207224344862.png)

图282中博弈,  唯一均衡点, 都选R

请注意，玩家2的偏好在所有三种状态下都是一样的，而玩家1的偏好在状态$\beta$和$\gamma$下也是一样的。特别是，在状态$\gamma$中，每个玩家都知道另一个玩家的偏好(P1虽然不知道P2是在$\beta$  或 $\gamma$ ,但碰巧这两个状态P2的偏好是一样的)，而玩家2知道玩家1知道她的偏好。在状态$\gamma$中玩家信息的缺陷是玩家1不知道玩家2知道她的偏好：玩家1只知道该状态是$\beta$或$\gamma$，而在状态$\beta$中玩家2不知道该状态是$\alpha$还是$\beta$，因此不知道玩家1的偏好（因为玩家1在这两个状态中的偏好不同）。

游戏者1对游戏者2信息的不完全了解会显著影响游戏的均衡。如果在状态$\gamma$中信息是完美的，那么$(L, L)$和$(R, R)$都会是纳什均衡。然而，整个博弈只有一个纳什均衡，其中$\gamma$状态下的结果是$(R, R),$在下一个练习中证明这一点。这个论证表明，玩家1在状态$\alpha$中面临的激励措施会 "感染 "游戏的其余部分。  TODO



#### 9.5 Illustration: Cournot’s duopoly game with imperfect information 不究全信息的古诺双寡头垄断博弈



#### 9.6 Illustration: providing a public good 提供公共物品



#### 9.7 Illustration: auctions 拍卖

用贝叶斯博弈来分析 不完全知道其他人估价时的拍卖。



#### 9.8 Illustration: juries  陪审团



#### 9.9 Appendix: Analysis of auctions for an arbitrary distribution of valuations 任意估价分布下的拍卖





### 10 Extensive Games with Imperfect Information 不完全信息展开型博弈



**不完全信息:  不知道chance节点的随机结果 ;  当每个人选择行动时，可能不知道其他人以前的行动。**

引入了 信念  .

#### 10.1   Extensive games with imperfect information  不完全信息展开型博弈

为描述不完全信息展开型博弈， 相比完全信息博弈 , 必须添加 : 当下的历史的信息。以 $H_i$ 表示历史的集合，玩家 i 在这之后采取行动。通过将$H_i$划分为若干**信息集 information set** 的collection来确定玩家 $i$ 的信息。这种集成称为玩家的**信息划分 information partition**。玩家在作出决策时，知道所发生的信息集，但不知道在该信息集中发生的是哪个历史。

**信息集之间可以区分, 信息集内部无法区分!!**

**Definition**: An **information set (信息集)** of a player is a collection of **decision nodes** (or **histories**) satisfying the following two conditions:

1. the player has the move at every node in the information set  每个node都是该玩家行动
2. when the play of the game reaches a node in the information set, the player with the move does not know which node in the information set has been reached, unless the information set is a singleton (单点, containing only one decision node).  玩家对信息集里的node无法区分



例如，假设玩家 i 在历史 $C, D$ 和 $E$ , 即 $[H_i=\{C, D, E\}]$ 之后行动 。 

- 如果历史 C 发生过，那么他知道 C 已经发生，而如果D 或者 E 发生过，那么他只知道 D 或E 中有一个发生, 但不能明确知道是哪一个。于是玩家 $i$ 的**信息划分**由两个**信息集**组成: $\{C\}$ 和 $\{D, E\}$ 。
- 若他对哪个历史发生过全都不知道，那么他的信息划分由单一的信息集组成，即$\{C, D, E\}$.  
- 如果他正确地知道历史,那么他的信息划分就由三个信息集 $\{C\}$, $\{D\}$, $\{E\}$  组成

如前所述,将在历史 $h$ 之后行动的玩家的**可使用行动集**合记作 $A(h)$ 。只有当 $A(h)=A\left(h^{\prime}\right)$ 时 $,$ 我们认为两个历史 $h$ 和 $h^{\prime}$ 在同一个信息集中。为什么呢？ 如果 $A(h) \neq A\left(h^{\prime}\right),$ 则在这个信息集上采取行动的玩家可以通过观案他可使用的行动来推断在这两个历史中发生了哪一个历史。   
如果包含 $h$ 和 $h^{\prime}$ 的信息集是 $I_{i}$ ,那么记 $A(h)$ 和 $A\left(h^{\prime}\right)$ 的共同部分为 $A\left(I_{i}\right)$ ; 也就是说，$A\left(I_{i}\right)$是玩家 i 在他的信息集 $I_{i}$ 上可供选择的行动集。 

许多不完全信息展开型博弈含有**随机**的行动， 考虑到随机节点的出现，结局outcome就是在terminal终端历史集上的随机结果**lottery**,每个玩家的偏好必须在这些随机结局上被定义。 

**定义** 314.1(**展开型博弈**) （具有不完全信息和随机行动的）展开型博弈包含:

- **玩家**集合
- (终端**历史**的)序列集 
- **玩家函数 player function** : 它将玩家或“**机会 chance**"分配给某些终端历史的真子历史的每一个序列; 如果是chance, 则chance **随机**选择动作. 
- 对于玩家函数分配给“机会chance”的每个历史,有一个**函数**对这个历史之后的可**选择行动**分配一个**概率分布**。它具有如下性质:每一个这样的概率分布独立于每一个其他的分布 。
- 对于每个玩家，由玩家函数分配给这个玩家有关历史集合的划分(玩家的**信息划分 information partition**)，使得对于在划分的任何给定成员中的每一个历史， 可使用的**行动集** $A(h)$是一样的
- 对于每个玩家，有终端历史的随机结局集合上的**偏好** 



先考虑最简单案例, 一个imperfect展开型博弈可以 建模 为 imperfect 策略型博弈 的情况，其中每个玩家只行动一次，并且没有一个玩家在行动时知道任何其他人的行动.   
例,  将BoS建模为imperfect 展开型博弈. 玩家相继选择各自的行动,但第二个行动者不知道第一个人的选择.

- 玩家:  1, 2
- terminal history:   (B，B)、(B，S)、(S，B) , (S，S)
- 玩家函数:  $P(\varnothing) = 1, P(S) = P(B) = 2$ 
- 机会行动:  无
- 信息划分:  P1的信息划分只包含 $\varnothing$ ;  玩家2的信息划分包含单一的信息集 $$\{B, S\}$$
- 偏好   

EXAMPLE 314.2 博弈如图所示，在每个终端历史下方的数字是伯努利收益，其期望值描述了玩家关于随机结局的偏好。连接 B和S 的**虚线**表示这两个历史处于玩家2 的**同一个信息集中**。

![315](/img/2020-04-18-Game.assets/image-20201216164614445.png)

重要例子, 理解**chance** 节点

EXAMPLE 315.1 (Card game) (一个纸牌游戏) : 两个玩家各bet 1 美元开始游戏。然后P1发到一张牌,P1可以看到牌面，这张牌有同等概率为"王牌"与"小牌", 玩家2 看不到这张牌。P1可以"摊牌"，或"追加bet"。如果他选择前者就就向P2 展示他的牌。 *如果大王, P1赢钱, 如果小牌,玩家2赢钱*, 玩家2过程中没有动作就结束.    如果P1追加赌注, 再押1美元, 玩家2可以放弃或者跟注. 如果放弃, P1赢钱; 若跟进, 也再押1美元, 然后P1必须摊牌. 

如图, P1有两个 单元素信息集,  (王牌), (小牌);   玩家2 有一个信息集, 里面有2个node: (王牌, 追加) , (小牌, 追加) ; 这个信息集 反映了P2 不能看到手牌这一事实。注意，对玩家2, 在信息集内每一个历史的行动集是相同的。

![316](/img/2020-04-18-Game.assets/image-20201216165025798.png)

在这些例子中，其中一个玩家拥有包含不止一个历史的信息集。每个玩家的每个信息集包含单个历史的博弈等价于其有完全信息的展开理博弈。   **如果每个信息集的size=1,相当于没有未知信息**

例 317.1 ,  进入博弈的变种 , 挑战者有三种选择: 在外面，准备好了再进入，无准备地进入。准备是昂贵的，但减少了斗争的损失。 不管进入者准备与否，在位者宁愿默许而不想斗争。在位者观察到挑战者是否进入，但现察不到进入者准备与否。 建模如下图.  挑战者的信息集由空集组成，在位者的信患集由"准备" 和"无准备"这两个历史组成. 这里少了Out后的结果

![317](/img/2020-04-18-Game.assets/image-20201216161810439.png)

Exercise 316.1 Variant of card game 纸牌的变体

把上例改为: 开始每人bet 1 元, 然后发到一张牌,  大小牌的几率一样. P1可以 see 或 raise, P1如果 see, 则比牌, 牌大的赢钱, 平局则平分.  P1如果 raise, 可以再押 k 元,  这时 P2可以 pass 或 meet ,  P2 pass, P1 通吃. P2 meet, P2也得押 k 元,  然后比牌, 大牌通吃, 平局则平分.  画出game tree. (将起始点画中心, 则画一个图就可以)

![image-20201215154345824](/img/2020-04-18-Game.assets/image-20201215154345824.png)





#### 10.2	Strategies  策略

策略确定了每当轮到玩家行动时所来取的行动. 

**DEFINITION** 318.1 (**展开型博弈的策略**) 在展开型博弈中，玩家$i$ 的一个(纯)策略是这样的一个函数，它对玩家$i$ 的每一个信息集 $I_i$ 分配一个$A(I_i)$   (在信息集 $I_i$ 中所有可以选择的行动的集合)中的行动。

上面例子中,  BoS中, 每个玩家有两个策略, B和S ;   纸牌, P1 有两个信息集 大牌,小牌, 每个信息集上有两个行动, 加注,摊牌 , 因此有4个策略 ((大)加注, (小)加注), ((大)加注, (小)摊牌), ((大)摊牌, (小)加注),((大)摊牌,(小)摊牌); 玩家2有2个策略: 跟进, 放弃



如果博弈允许混合策略. 

**DEFINITION** 318.3 (**展开型博弈的混合策略**) 在展开型博弈中，玩家的混合策略是在纯策略上的一个**概率分布**。

所以, 混合策略包含了概率为1的纯策略.



#### 10.3	Nash equilibrium   纳什均衡

**DEFINITION** 318.4 (**展开型博弈的纳什均衡**) 展开型博弈的混合策略组合$$\alpha^*$$ 如果满足下述条件，则称为**(混合策略)纳什均衡**: 对于每一个玩家 $i$ , 他的每一个混合策略$\alpha_i$, 关于$$\alpha^*$$的期望收益至少与$$(\alpha_i, \alpha_{-i}^*)$$的期望收益一样大。

**方法一** : (把game tree 变成 收益表格) 求展开型博弈纳什均衡的一个方法是**构造博弈的策略型形式**，并且将它作为一个策略型博弈来分析.  

> 即,玩家2如果看不到P1的行动, 那么跟一起行动其实差不多.

EXAMPLE 319.1 (BoS 作为展开型博弈)   例314.2 博弈有两个纯纳什均衡(B,B)和(S,S),  以及一个混合均衡，P1 以 $\frac{2}{3}$ 采用 $B$, P2 以 $\frac{1}{3}$ 采用 $B$  .  

这个例子, P2 在采取行动时, 不知道P1 所选择的行动, 所以其信息集包含了历史S和B。但是, 即使P2 不知道P1 的行动，他的**经验**也会告诉他**预期发生的历史**(或关于历史的概率分布)。例如，在稳定状态下，无论P1,P2, 其中选B的那个人,都知道另外一个人会选B.   她并不知道这一事实，但她长期的游戏经验使她得出了关于其他玩家行动的(正确)结论.  
同样，在稳定状态下，扮演P2的人中有1/3的人选择B，每个扮演P1的人的经验 让其知道, 其对手会以1/3的概率选择B.  
关键在于，玩家的**信息分区**反映了她 观察 其他玩家在游戏过程中采取的行动所获得的信息；她的游戏经验可能会让她获得更多关于其他玩家稳定状态行动的信息。



**这个解法, 需要完全展开成  纯策略的收益表.  关键!! chance节点的概率要一路乘下来** 

![316](/img/2020-04-18-Game.assets/image-20201216165025798.png)

EXAMPLE 319.2 (纸牌游戏)   315.1 的例子, 策略形式如下图.  0和博弈. 

![320.1](/img/2020-04-18-Game.assets/image-20201216165635390.png)

P1的策略表示为: (大牌时action, 小牌时action)

该例没有纯策略的均衡, 因为各个点都会跑向其他地方.    

先去掉严劣的以及不是BR的   
P1的(摊牌，摊牌) **严劣**于 1/2(加注,加注), 1/2(加注,摊牌) 的混合策略. 因此, 任何纳什均衡, P1不会选择该纯策略.     
P1的(摊牌,加注) 对于P2 分配正概率给“跟进”的任何混合策略不是一个最优反应( 弱劣于 bet,bet  , 有一个混合策略均衡无弱劣 ) , 这个一下子难看出来  
所以, 考虑到没有纯策略的均衡，在所有的纳什均衡中，P1一定在(加注，加注)和(加注，摊牌)之间随机选择。  
令p为P1选择(加,加)的概率, q为玩家2 选放弃的概率.   
因为每个玩家从她指派正概率的每个策略中(使得对方)获取相等期望盈利.  即达到均衡以后,  P1的每个动作(使得对方)的预期收益都是一样; 玩家2也同样. 所以有 $q=\frac{1}{2}(1-q)$ 和 $-p=-\frac{1}{2}(1-p)$  ,   求得 $p=q=\frac{1}{3}$ .



**下面是重要例子,说明, 同一个收益表, 不同的策略形式, 均衡策略可能完全不一样.  以及  信息不完全的 意义!** 

EXAMPLE 320.2 (承诺与可观察性 Commitment and observability)  两个人各有两个动作，X 和 Y。他们关于四个行动对的收益如下:

![320.2](/img/2020-04-18-Game.assets/image-20201216170002180.png)

1. 假设他们同时选择行动。模拟该情况的策略型博弈有唯一的均衡,   Y, Y。(注意,对于P1 来说, X 严劣于 Y) 

2. 假设玩家先后选择行动，P1 最先选择, P2 在 选择自己的行动之前观察到P1 的行动。将这种情况建模而成的完全信息展开型博弈有单一的子博弈完美均衡，X, X。在这个均衡中,P1 的收益好于他在同时行动博弈的均衡中的。
   YY 是个纳什均衡，即给定P1选Y，P2必选Y，给定P2选Y，P1肯定选Y，在YY这个策略的路径上，该策略是最优的。但不是子博弈完美均衡。 **特别的，说明 建模为策略博弈的纳什均衡与 建模为完全信息展开博弈的 子博弈完美均衡， 可能不一样， 不是包含与被包含的关系** 
   这里, 后行动的未必比一起行动时候, 收益大.  先行动的也未必收益会小. 

3. 假设P1 最先行动，不过他的行动没有被P2 完全观察到。如果P1 选择了 X，P2 可能认为他选择的是 Y,或者情况正 好相反。我们可以将这种情况建模为不完全信息展开型博卒,其中P1 的行动后面跟随一个**随机行动**，它选择可被P2 观察到的**信号**。**P2 观察到的是信号**而不是P1 的行动。假定信号为正确的概率关于两个行动是一样的，且小于1。将此概率记作 1 - $\varepsilon$ 。(于是,如果P1 选择 $X$, 那么信号为 $X$ 的概率是 $1-\varepsilon$,信号为 $Y$ 的概率是 $\varepsilon$ ; 对Y也一样 ) 。假设 $0 \leqslant \varepsilon<\frac{1}{4}$  

这个展开型博弈和它的策略型形式，以及它的纳什均衡都显示在图10.6中。 玩家2的策略,$IJ$,表示玩家2看到了信号X之后,选择$I$, 看到信号Y之后,选择$J$ ;      因为玩家2没法看到P1的情况, 其extensive策略只能以这种方式表现.

特别地，我们看到,对所有满足 0 $\leqslant \varepsilon<\frac{1}{4}$ 的 $\varepsilon,$  有一个纯策略纳什均衡 ( $Y, Y Y)$ 


![321](/img/2020-04-18-Game.assets/image-20201215223850337.png)

概括地说，P1 先行动以及他的行动完全可被观察的博弈有唯一的子博弈完美均衡，X, X.   P1的行动可观察, 但存在误差的博弈有一个纯策略纳什均衡，其结局是不管误差有多小, **甚至是0** ,两个人都选Y.   

**这里的混合策略, 当误差=0的时候, 也是成立的, 等同于那两个纯策略了.  其中 X,X 还不是纯策略均衡, 怎么解释**    

因此，在完全信息博弈的子博弈完美均衡中所反映的作为先行者P1带来的承诺所获得的优势，在P2对P1的行动的观察哪怕是稍微不全面的博弈的纯策略均衡中就丧失了，为什么呢？  
假定P1 和 P2 都选择Y，并且考虑P1 转向 X 的含义。在完全信息博弈中，P2"观察到 X"与均衡是不相容的: 他会将这种情况解释为发生了 偏离deviation。对此，P2通过选择 X 做出最优反应，使得P1 的这个"偏离" 是值得的。在不完全信息博弈中，P2"观察到X"与均衡是相容的: 他将这种情况解释为一个错误的信号(无论这样的信号多么不可能) ，并继续选择 Y，使得P1 的偏离不利于P1 自己.  
即, 对完全信息, P1从Y换X,P2会以为P1改变策略, 因为P2一直采用的是BR,会逼迫P2从Y走到X; 如果P2的观察有误差, 则P1切换策略可能是自己的观察出错, 可能是chance, P2仍然坚持当前策略,要通过统计观察的错误率才能改.

信息不完全展开博弈, 建模为 策略型博弈, 关键是策略型博弈是同时出招的.  

我们看到，在完全信息展开博弈中，纳什均衡概念是不够的，我们提出了子博弈完美均衡的概念去处理问题。我们怎样把子博弈完美均衡的思想延伸到更广泛的 具有(可能)不完全信息的展开型博弈中去呢?



EXAMPLE 322.1 (Entry Game 进入博弈) 

![322](/img/2020-04-18-Game.assets/image-20201216170146824.png)

博弈有两个纯策略纳什均衡， (无准备，默许) 和(在外，斗争) ,还一个混合策略纳什均衡，其中，P1采用 Out，而P2给 默许 的概率至多为1/2 (纯 vs 混合)  

如在第五章中研究的具有完全信息的进入博弈的版本中，纳什均衡(在外，斗争) 似乎是不合理的。倘若事实上挑战者进入，在位者的最优反应是"默许"。在具有完 全信息的博弈中，我们通过定义**子博弈完美均衡**概念剔除了这种均衡，因为 子博弈完美均衡要求，对于轮到玩家行动的**每个历史**，在给定其他玩家 的策略时，当前行动的玩家的策略是最佳的，无论 玩家们坚持他们的策略时这个历史是否发生。 

这个思想关于不完全信息博弈的自然推广，要求每个玩家在其**每个信息集**上的策略是最优的。

在其他博弈中，这个想法的实现就不那么直接了，因为在一个**信息集上的行动的最优性可能取决于已经发生的历史**。 即，信息集中的一些node可以走向收益最优的，而一些node的收益很差。

下面一个变体，其中在位 喜欢斗争甚于 默许一个无准备的进入者. 

![323.1](/img/2020-04-18-Game.assets/image-20201215230020407.png)



#### 10.4	Beliefs and sequential equilibrium    信念和顺序均衡

一个战略博弈的纳什均衡可以由两个要求来描述：每个玩家根据自己对其他玩家的信念选择最佳行动，以及每个玩家的信念是正确的. 现在为展开型博弈定义的均衡概念体现了同样的两个要求，并且，就像具有完全信息的展开博弈的子博弈完美均衡概念一样，坚持它们在玩家必须选择行动的每一个点上都成立。  
在精确定义策略型博弈的纳什均衡时，我们不必将玩家的信念与他们的策略分开来考虑，因为"**信念是正确的**"这个要求完全确定了它们:**每个玩家关于其他玩家策略的信念简单地等于那个策略**。  
对于展开型博弈，正如我们在 图323.1中的博弈中已经看到的那样，玩家的策略可能并不完全决定他们的信念。因此，因此我们对策略组合和信念集合组成的"组合" 来定义均衡概念。



##### 10.4.1 信念 beliefs

我们假设在一个包含多个历史的信息集中，当前行动的玩家会形成一个关于已经发生的历史的信念，我们将这个信念建模为信息集上的 历史的概率分布（若一个信息集中包含一个单一的历史，唯一可能的信念对该历史赋予概率1）。我们把每个玩家的每个信息集的一个信念集合称为**信念体系 belief system**。

**DEFINITION** 324.1 A **belief system** in an extensive game is a function that assigns to each information set a probability distribution over the histories in that information set.   
展开型博弈中的**信念体系 belief system**是一个函数，它给每个信息集分配一个在那个信息集上的历史的模率分布。

例如，考虑 Example 317 中的进入博弈。有两个信息集:一个包含 空历史，另一个包含"准备"和"无准备"这两个历史。因此，博弈的信念体系由 一对概率分布组成:一个分配概率 1 到空历史(挑战者在博弈起始时的信念) , 另一个分配概率到历史"准备"和"无准备"(挑战者进入之后，在位者的信念)。



##### 10.4.2 策略  strategies

对一个信息集分配一个该信息集中可使用行动的概率分布。称这样的映射为"**行为策略"**  (***behavioral* strategy**) 。

**DEFINITION** 324.2(**Behavioral strategy** in extensive game)A **behavioral strategy** of player i in an extensive game is a function that assigns to each of i's information sets $I_i$ a probability distribution over the actions in $A(I_i)$, with the property that each probability distribution is independent of every other distribution.  
展开型博弈中玩家 i 的**行为策略**是一个函数，为玩家 i 的每一个信息集$I_i$ 分配一个 $A(I_i)$中行动上的概率分布，具有"每个概率分布与其他每个分布独立"的性质。

 分配概率 1 至单一行动的行为策略与纯策略等价 ; 在所有博弈中，混合策略与行为策略是等价的 , 但行为策略在这里使用方便. 

**Difference** between **behavioral strategy** and **mixed strategy**: a mixed strategy refers to a probability distribution over pure strategies, whereas a behavioral strategy refers to the collection of probability distributions over the actions at the information sets.

在例315.1中的游戏（纸牌游戏）中，玩家1有两个信息集，所以她的行为策略由一对概率分布组成，每个概率分布都在集合{Raise,See}上。 然而，在这个游戏中，玩家1的混合策略是在她的四个纯策略集{(Raise,Raise),(Raise,See),(See,Raise),(See,See)}上的一个概率分布。因此，该行为策略由两个数字来指定, 而混合策略则由三个数字来指。在这个意义上，行为策略比混合策略更简单。 但行为策略跟做到跟混合策略一样的效果.



##### 10.4.3 均衡

**DEFINITION** 325.1(**Assessment 评估**) An **assessment** in an extensive game is a pair consisting of a profile of **behavioral strategies** and a **belief system**.  
展开型博弈中的"评估"是由行为策略组合和信念体系组成的"对"

如果 评估 满足下述两个条件, 那么它是一个均衡:

- **Sequential rationality (顺序理性; 序贯理性)**: Each player's strategy is optimal whenever she has to
  move,given her belief and the other players'strategies.  策略最优.
- **Consistency of beliefs with strategies(信念与策略一致)**: Each player's belief is consistent with the
  strategy profile.   

顺序理性的要求推广了子博弈完美均衡的要求，后者要求 给定策略组合后, 每个玩家的策略在她行动的每个历史(**node**)之后的博弈部分都是最优的，不管这段历史是否发生。在更广泛的博弈里，顺序理性要求 给定策略组合，并给定玩家对已发生的信息集中的历史的信念，如果玩家遵循他们的策略, 每个玩家的策略在她的每个信息集(**info set)**之后的那部分博弈中是最优的，而不管这个信息集是否被达到。  
ps, 这里的达到, 应该就是当前这轮博弈, 是不是会走到这个节点或者信息集. 就算走不到, 我指定的策略也要在万一走到的情况下,是最优的. 

下图中的例子,  假设P1 的策略(表示为黑色粗线)为,  起始点选 E，在历史 (C，F)之后选择 $J$ ; P2关于P1的信念P1会2/3选C, 1/3选D; 顺序理性要求:给定由P1的策略所确定的后续行为，即使当P1遵循自己的策略时P2的信息集达不到，但是P2在这个信息集上的策略应当是最优的.   给定了P2 的信念,在从P2的信息集出发的博弈部分,关于策略 $F$ 的期望盈利是 $\frac{2}{3} \cdot 0+\frac{1}{3} \cdot 1=\frac{1}{3}$ , 关于策略$G$ 的期望盈利是 $\frac{2}{3} \cdot 1+\frac{1}{3} \cdot 0=\frac{2}{3}$ 。 因此,顺序理性要求他选择 $G$ . 在给定 P2 的策略下, 顺序理性也要求 P1 在他的两个信息集上的策略是最优的。P1 在历史(C,F)之后的最优行动是 $J$ ; 如 P2 的策略是 G , 那么 P1 在开始时的最优行动是 $D$ 和 $E$  ; 于是,给定了 P2 的策略 G,  P1 有两个最优策略一 $DJ$ 和 $E J$

![326](/img/2020-04-18-Game.assets/image-20201216122021219.png)

其实就是有包含了概率的 反推. 

记 $(\beta, \mu)$ 为博弈的一个 评估 assessment  ( $\beta$ **behavioral strategy profile** , $\mu$  **belief system**),  $I_i$ 为玩家$i$的一个信息集. 若$I_i$中每个历史发生的概率就是玩家的信念 $\mu_i$ (不必是玩家坚持 $\beta$ 时该历史发生的概率) , 并且之后玩家坚持策略组合 $\beta$ , 那么得到终端历史上的一个概率发布,记为  $O_{I_{i}}(\beta, \mu)$ . 

与完全信息展开博弈的 $O_{h}(s)$ 相比较:  对信息集 $\{C, D\}$ , 以及上图中的P1的策略和P2的信念,  
若P2使用策略 $F,$  得到终端历史 $(C, F, J)$ 的概率 $\frac{2}{3}$ ,  $\frac{1}{3}$ to $(D, F)$ 
若P2使用策略 G,  $\frac{2}{3}$ to $(C, G)$ , $\frac{1}{3}$ to $(D, G)$ .

现在可以精确表述 **sequential rationality** 的需求: for each player $i$ and each of her information sets $I_{i},$ her expected payoff to $O_{I_{i}}(\beta, \mu)$ is at least as large as her expected payoff to $O_{I_{i}}\left(\left(\gamma_{i}, \beta_{-i}\right), \mu\right)$ for each of her behavioral strategies $\gamma_{i}$  ,    对每个信息集取最优策略, 最优的标准  期望收益最大.

玩家的**信念与策略一致**的要求是新的。其思想是，在一个稳定状态中，每个玩家的**信念必须是正确的: 玩家认为任何历史发生的概率必定 等于 当玩家坚持他们的策略时这个历史真实发生的概率**。 如果玩家遵循策略，那么在达到的信息集中，这一思想是显然的; 但是，在玩家遵循策略而没有能够达到的信息集上，这一思想就不那么清楚了。  
如果玩家遵循他们的策略，这类信息集里的每个历史的概率为0，但如果达到这样的信息集，则在那个信息集上行动的玩家必须相信某个历史已经发生了.我们通过允许在这样的信息集上行动的玩家在该信息集持有**任意**信念来处理这个困难。 

下面精确地阐述一致(相容)要求，**把信念体系 限制在 仅仅那些 每个玩家坚持自己的策略 将以正概率达到的信息集上**。明确地讲，要求 在这样的信息集上行动的玩家的信念指派给该信息集中某个历史$$h^*$$的概率， 应该等于  到达该信息集后, 再按照策略使$$h^*$$发生的概率,  根据贝叶斯公式, 则下式
$$
\frac{P\left(h^{*} \text { according to } \beta\right)}{\sum_{h \in I_{i}} P(h \text { according to } \beta)}  \tag{327.1}
$$

再考虑上图的博弈,  如果P1的策略在开始时只选行动 E，则根据一致性要求, 对 P2的信念没有限制, 没要求, 因为P2的信息集都不会走到, 只要P1坚持该策略.  
然而，如 P1 在开始时,以 概率p 选C ,  q选D, 1-p-q 选E;  那么 $Pr(C  \text { according to } \beta)=p$,  $Pr(D   \text { according to } \beta) = q$ , 那么根据上面公式,  玩家2的信念则为 : p/(p+q) 到C,  q/(p+q) 到D. 



EXAMPLE 327.2 (BoS 中的一致信念) 例314.2, 对于P1 的每一个策略, P2 的信息集以概率 1 达到。在这个博弈中,一致性(或相容性)要求 P2 的信念总是正确的。对于所有同时行动的任何博弈,这个结论都成立。

EXAMPLE 327.3(纸牌游戏中的一致信念)  例315.1, 如果P1 不管自己的牌是“王牌”还是“小牌”,他的策略都是选取“摊牌”,  那么相容性条件不限制P2 的信念,因为P2 的信息集达不到。 如果 1 的牌是“王牌”,选“加注”的概率记作 $p_{H},$ 如果P1 的牌 是“小王”, 选择“加注”的概率记为 $p_{L}$ 。因此 $Pr(  \text {High according to }\beta)=p_{H}$ and 此 $Pr(  \text {Low according to }\beta)=p_{L}$ , P2 的信念指派概率 $p_{H} /\left(p_{H}+p_{L}\right)$ 到历史 $H$ ,  指派概率 $p_{L} /\left(p_{H}+p_{L}\right)$ 到历史 $L$ .

![316](/img/2020-04-18-Game.assets/image-20201216165025798.png)



EXAMPLE 327.4 (进入博弈的一致信念)  例323.1 记 $p_{R}, p_{U}$ 和 $p_{O}$ 为挑战者指派到“准备”、"无准备”和“在外”的概率。  
如果 $p_{O}=1,$ 信念一致条件不限制 在位者的信念。  
否则, 条件要求指派概率 $p_{R} /\left(p_{R}+p_{U}\right)$ 到“准备”,指派概率 $p_{U} /\left(p_{R}+p_{U}\right)$ 到“无准备”。

![323](/img/2020-04-18-Game.assets/image-20201215230020407.png)



**DEFINITION** 328.1 (**Weak sequential equilibrium**)   An  **assessment 评估** $(\beta, \mu)$ is a **weak sequential equilibrium 弱顺序均衡** , 如果满足:

1. **Sequential rationality 顺序理性**: 每个玩家在其行动的信息集上的策略都是最优的,给定策略组合和已经发生的信息集中的历史的信念.   
   数学描述为,  for each player $i$ and each information set $I_{i}$ of player $i,$ player $i$ 's expected payoff to the probability distribution $O_{I_{i}}(\beta, \mu)$ over terminal histories generated by her belief $\mu_{i}$ at $I_{i}$ and the behavior prescribed subsequently by the strategy profile $\beta$ is at least as large as her expected payoff to the probability distribution $O_{I_{i}}\left(\left(\gamma_{i}, \beta_{-i}\right), \mu\right)$ generated by her belief $\mu_{i}$ at $I_{i}$ and the behavior prescribed subsequently by the strategy profile $\left(\gamma_{i}, \beta_{-i}\right),$ for each of her behavioral strategies $\gamma_{i}$   
   对每个人, 在该评估下, 预期收益是最好的.
2. **Weak consistency of beliefs with strategies 信念与策略弱一致性** : For every information set $I_{i}$ reached with positive probability given the strategy profile $\beta,$ the probability assigned by the belief system to each history $h^{*}$ in $I_{i}$ is given by (327.1)  
   给定策略组合, 只考虑每个可以达到的信息集中的历史(概率>0), 信念分配的概率由公式 (327.1) 给出



该例, 体现了弱顺序均衡.  

![326](/img/2020-04-18-Game.assets/image-20201216122021219.png)

- 给定 P2 的策略 G，P1 的策略 EJ 是顺序理性的;  给定图上P2的信念以及P1的策略 EJ, P2的策略G是 顺序理性的.  进而, P2的信念与策略组合(EJ,G) 一致, 因为该策略组合走不到P2的信息集, 所以P2任意信念都OK. 因此,该博弈有一个弱顺序均衡, 其中策略是(EJ,G), 信念是上图中的(或者其他信念使得能选G的信念). 

- 考虑 策略组合(DJ,G) ,  对P2的G, P1是顺序理性的; 给定P2的信念与P1的策略, P2 策略是顺序理性; 但P2信念与策略组合不一致.   唯一一致的信念是P1以概率1选D, 使得P2的F是最优.  所以该博弈没有策略组合是(DJ,G)的弱顺序均衡. 

在完全信息的展开型博弈中，只有一个信念体系是可能的: 每一个玩家在每个信息集上相信"单一适合的历史以概率 1 发生"。

**在完全信息的展开型博弈中，任意弱顺序均衡的策略组合就是子博弈完美均衡。**

在一般的展开博弈中，顺序理性的要求意味着，每个玩家的策略在博弈开始时是最优的，given the other players' strategies and the player's belief about the history at each information set.  进一步,  信念一致性 要求,  对每个可以到达的信息集里的历史, 每个玩家的信念是正确的. 因此, 如果一个评估是 弱顺序均衡, 那么给定其他人的策略, 那个这个评估中的玩家的策略在博弈起始点是最优的.  即

**任何弱顺序均衡的策略组合是纳什均衡。**



下面讨论如何求:  为求得博弈的弱顺序均衡﹐我们可以把在完全信息展开型博弈中求**子博弈完美均衡**与求**策略型博弈的纳什均衡**这两种技巧相结合。例如,考虑图326中的博弈。顺序理性要求在任何弱顺序均衡中, P1在历史(C,F)之后选择J。现在我们可以考虑以下两种情况。

- P1选 E 有弱顺序均衡么?  若P1选$E$, P2的belief 可以任意, 所以问题变为, P2的任意策略能否使得P1选E是最优的? 如果是, 那么是否P2存在这样信念, 使得自己的策略是最优的?  可以看到, 如P2最多以2/3选F, P1选E是最优.  任何P2这样的策略是最优的,如果P2相信历史是C的概率是1/2; 若P2相信历史是C的概率>=1/2,则P2以概率0选F是最优的.  
- P1选C或者D有弱顺序均衡么? 设P1选C以p, 选D以q. 由于一致性的要求, P2的信念, 分配概率 $p /(p+q)$ to $C$, $q /(p+q)$ to $D$ . 那么 $G$ 是最优的,  if $p>q$;   $F$ is optimal if $p<q$ ; 任何混合都是最优,  if $p=q .$ Now, if player 2 chooses $G,$ the only optimal strategy of player 1 that assigns positive probability to $C$ or $D$ assigns probability 1 to $D,$ so that $q=1,$ making $G$ not optimal for player $2 .$ If player 2 chooses $F$, player 1 's only optimal action at the start of the game is $C,$ making $F$ not optimal for player $2 .$ If player 2 chooses a mixture of $F$ and $G,$ then player 1 must assign the same probability to both $C$ and $D,$ and hence must choose $D$ with positive probability, which is incompatible with the fact that her expected payoff to $D$ is less than her



#### 10.5	Signaling games   信号博弈

**Signaling game**: 有些玩家对影响到每个人的变量都是知情的，而其他玩家则不知道。知情的玩家（"发送者sender"）先采取行动，而不知情的玩家（"接收者receiver"）在观察到知情玩家的行动后采取行动。知情玩家的行动可能会给他们的信息（例如，他们的类型）发出 "信号signal"。 

这样的情况可以建模为展开型博弈，其中发送者有若干个可能的"类型"，每一个类型对应于他知道的变数的一个值。他观察到的值，也就是他的类型，由随机的方式确定。接收者观察不到发送者的类型，可是能看到发送者所采取的行动，然后接收者自己再采取行动。



例10.27(进入作为信号博奔)  挑战者 呈现"强"的概率等于p，而呈现"弱"的概率为 1-p ;挑战者知道自己的类型，可是在位者并不知道。挑战者要么"准备"，要么保持"无准备"状态。(没有 "外面"的选择。) 在位者观察到挑战者是否准备就绪，但观察不到他的类型 . 

<img src="/img/2020-04-18-Game.assets/image-20200511120127099.png" alt="image-20200511120127099" style="zoom:50%;" />

<img src="/img/2020-04-18-Game.assets/image-20200511120206589.png" alt="image-20200511120206589" style="zoom:50%;" />

现在求这个博弈的纯弱序贯均衡。  



概括来说，博弈有两类弱序贯均衡。 倘若挑战者强，他就选择"准备"，而如果挑战者是弱的, 就选择"无准备"。在位者相信，有准备的挑战者是强的，而无准备的为弱的，并且默许有准备的挑战者, 对无准备的挑战者斗争。



这个例子描述了可能存在于信号博弈中的两类纯策略均衡: 











#### 10.6	Illustration: conspicuous expenditure as a signal of quality   

#### 10.7	Illustration: education as a signal of ability   

#### 10.8	Illustration: strategic information transmission   

#### 10.9	Illustration: agenda control with imperfect information   







## Part III: Variants and Extensions  变体和推广

### 11 Strictly Competitive Games and Maxminimization 严格竞争博弈和最大最小化

**minimax: 悲观保守**  非常重要的方法.



纳什均衡, 其思想是，每个玩家通过自己与各种对手的博弈经验，知道游戏中其他玩家会采取的行动，并根据这些知识选择自己的行动。
在本章和下一章中，我们从不同的角度来研究博弈的可能结果。我们考虑每个博弈者对其他博弈者的行动所形成的信念，不是从他的经验出发，而是从他对博弈的分析出发，来考虑其意义。
这一章重点讨论的是严格意义上的二人游戏，在这种游戏中，玩家的利益是截然相反的。在这种博弈中，一个简单的决策程序导致每个玩家选择一个纳什均衡行动。



#### 11.1  Maxminimization  最大最小化

你**第一次**面临博弈;**对于你的对手**将采取什么行动**没有任何信念**。你应该怎样选择你的行动呢?给你一个非常**保守的方案** :对于你的每一个行 动，当其他玩家的行动变化时，找出对你来说是最差的结局，然后在这些最差的结局中找出一个最好的，相应的行动就是你的选择。这种方法称为 "**最大最小化maxminimization**"法。

DEFINITION 336.1  A **maxminimizing mixed strategy** for player $i$ in a strategic game (with vNM payoffs) is a mixed strategy $\alpha_{i}^{*}$ that solves the problem

$$
\max_{\alpha_{i}} \min_{\alpha_{-i}} U_{i}\left(\alpha_{i}, \alpha_{-i}\right)
$$

where $U_{i}$ is player $i$ 's vNM payoff function.

一句话，玩家$i$的最大最小化策略是, 无论他做什么，其他玩家都会以最小化他的预期回报的方式行动, 在这样**悲观的假设下**, 去最大化了自己的回报. 



另一个角度看到minimax.  如果一个混合策略保证玩家i 的回报保障是$$\bar{u}_{i}$$ , 那么不管其他玩家采样什么策略, 即:
$$u_{i}\left(\alpha_{i}, \alpha_{-i}\right) \geq \bar{u}_{i}$$ for every list $$\alpha_{-i}$$ of the other players' mixed strategies. 

minimax策略能够最大限度地保证玩家的回报: 如果 $\alpha_{i}^{*}$ 是minimax策略, 则有
$$\min _{\alpha_{-i}} u_{i}\left(\alpha_{i}^{*}, \alpha_{-i}\right) \geq \min _{\alpha_{-i}} u_{i}\left(\alpha_{i}, \alpha_{-i}\right)$$ for every mixed strategy $\alpha_{i}$ of player $i$

**就是说, minimax是所有策略里面,  玩家能得到最好的回报保障.**



EXAMPLE 337.1  maxminimizers的例子. 

<img src="/img/2020-04-18-Game.assets/image-20200508011853619.png" alt="image-20200508011853619" style="zoom:33%;" />

显然, 如果策略限制P1要么选择T,要么选择B, 最坏的情况, 收益保障是-1.  然后, P1在T和B中随机化, 收益可能更好一点. 比如1/2选T, 1/2选B, 则玩家2固定选择L,P1的预期收益是1/2, 玩家2选择R,P1的预期收益是0;   令$p$ 为P1选择T的概率.  下图中两条线分别表示玩家2选择L,R时候,P1的随着p的改变的收益. 黑色的倒V线表示P1所能获得的被玩家2针对下的收益保障,即 $\min_{\alpha_2}u_1(\alpha_1,\alpha_2)$  , 而P1需要max这个保障, 所以选择p=2/5. 

<img src="/img/2020-04-18-Game.assets/image-20200508012459016.png" alt="image-20200508012459016" style="zoom: 33%;" />



#### 11.2  Maxminimization and Nash equilibrium  最大最小化与纳什均衡

下面讨论纳什均衡与minimax策略之间的关系.  重要结论

**LEMMA 338.1**  **对策略博弈, 任何纳什均衡策略的收益都大于等于minimax策略的收益**.  *The payoff of each player in any Nash equilibrium of a strategic game is at least equal to her maxminimized payoff*. 
Proof.  Let $$\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right)$$ be a Nash equilibrium. Consider player 1. First note that by the definition of a Nash equilibrium, 
$$U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right) \geq U_{1}\left(\alpha_{1}, \alpha_{2}^{*}\right)$$ 	for every mixed strategy $$\alpha_{1}$$ of player 1
so that
$$U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right) \geq \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)$$ 	for every mixed strategy $$\alpha_{1}$$ of player 1
since the inequality holds for every mixed strategy $$\alpha_{1}$$ of player 1,  we conclude that
$$
U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right) \geq \max _{\alpha_{1}} \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)
$$



#### 11.3 Strictly competitive games 严格竞争博弈

在许多博弈中，玩家没有充分的理由去相信其他人将采取使其收益最小化的行动。可是在玩家的利益完全对立的两人博弈中，这个假设是合理的 . 

DEFINITION 339.1 (**序数偏好的严格竞争策略型博弈 Strictly competitive strategic game with ordinal preferences**)  一个策略型博弈是严格竞争的, 如果有两个玩家, 并且有
$$
u_{1}\left(a_{1}, a_{2}\right) \geqslant u_{1}\left(b_{1}, b_{2}\right) \quad \text { 当且仅当 } \quad u_{2}\left(b_{1}, b_{2}\right) \geqslant u_{2}\left(a_{1}, a_{2}\right)
$$
其中 $\left(a_{1}, a_{2}\right)$ 和 $\left(b_{1}, b_{2}\right)$ 是一对行动;  主要就是这两个人的收益函数是方向相反的.

注意，如果 $u_{1}$ 是描述严格竟争博弈中P1偏好的收益函数,那么收益函数$-u_1$ 则描述了玩家2 的偏好。也就是说，在任何严格竟争博弈中,**存在**玩家的收益函数$u_1$ 和 $u_2$,  使得对于任意的行动组合 $\left(a_{1}, a_{2}\right)$ 成立 $u_{1}\left(a_{1}, a_{2}\right)+u_{2}\left(a_{1}, a_{2}\right)=0$ 。出于这个原因, 严格竞争博弈有时叫作"**零和 zerosum**" 博弈。 零和博弈是严格竞争博弈在收益函数为0时的特殊情况. 因为收益函数是序数偏好, 其实 (-1,2) 这种的也是严格竞争的. 但肯定可以设计出sum为0的收益函数.

囚徒困境,BOS都不是严格竞争;  匹配硬币是的. 

下例,  也是严格竞争, 纯策略的时候.  P1喜欢(B, R) > (T, L) > (B, L) > (T, R) , 玩家2正好相反. 但考虑混合策略,则不是严格竞争.

<img src="/img/2020-04-18-Game.assets/image-20200509020106893.png" alt="image-20200509020106893" style="zoom:50%;" />



DEFINITION 339.2 (**vNM 偏好的严格竞争策略型博弈 Strictly competitive strategic game with vNM preferences**) 一个具有 vNM 偏好的策略型博弈是严格竞争的，如果它有两个玩家,并且 

$$
U_{1}\left(\alpha_{1}, \alpha_{2}\right) \geqslant U_{1}\left(\beta_{1}, \beta_{2}\right) \quad \text { 当且仅当 } \quad U_{2}\left(\beta_{1}, \beta_{z}\right) \geqslant U_{2}\left(\alpha_{1}, \alpha_{2}\right)
$$

这里，( $\alpha_{1}, \alpha_{2}$ ) 和 $\left(\beta_{1}, \beta_{2}\right)$ 是一对混合策略 ;并且对于 $i=1,2$,  $U_{i}$ 是描述玩家 $i$ 关于随机结局偏好的期望收益函数。

如同具有有序数偏好的博弈那样，在具有 vNM 偏好的严格竞争博弈中， 存在具有如下性质的描述玩家偏好的收益函数:对于每个行动组合，玩家的收益之和等于 0。即，如果$u_1$是伯努利收益函数，它的期望值描述了P1关于随机结局的偏好，那么$-u_1$ 就是其期望值描述了玩家2偏好 的伯努利收益函数。

当混合策略时为严格竟争的任何博弈，在限于纯策略时 显然也是严格竞争的,但是反之不成立。例如,考虑图339.1中的博奕，现在将方框内的数字解释为伯努利盈利。P1对于如下两种结果感觉没有差别 : 一种是结局 ( $T, L$ ); 另一种是“( $T, R$ ) 以概率 $\frac{3}{5}$ 发生和$(B, R)$以概率$\frac{2}{5}$ "的随机结局, 因为$\frac{3}{5} \cdot 0+\frac{2}{5} \cdot 5=2$,  可是玩家2 对于这两个结局感觉有差异[他关于(T,L)的盈利是 1，而相应于那个随机结局，他的期望盈利是 $\left.\frac{3}{5} \cdot 5+\frac{2}{5} \cdot 0=3\right]$



##### 11.4	Maxminimization and Nash equilibrium in strictly competitive games  严格竞争博弈中的最大最小化与纳什均衡

在任何博弈中，纳什均衡盈利 >= 最大最小化盈利

下面证明，在具有混合策略纳什均衡的严格竞争博弈中，这两个盈利是相同的。事实上有:

在具有混合策略纳什均衡的严格竞争博弈中，一对混合策略组合是混合策略纳什均衡，当且仅当每个玩家的策略是最大最小化解。



PROPOSITION 341.1 (**严格竟争博弈中的纳什均衡策略和最大最小化解**) 考虑具有 vNM 偏好的严格竟争策略型博亲。令$U_1$ 为描述P1偏好的期望收益函数,令$U_{2}=-U_{1}$ ,$U_{2}$ 描述玩家2的偏好  
a. 如果 $$ (\alpha_{1}^*, \alpha_{2}^*)$$是混合策略纳什均衡,  那么  $$\alpha_{1}^*$$是P1的最大最小化解 , $$\alpha_{2}^*$$是玩家2的最大最小化解, 并且:
$$
\max _{\alpha_{1}} \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)=\min _{\alpha_{2}} \max _{\alpha_{1}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)=U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right)
$$

b. 如果$$\max _{\alpha_{1}} \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)=\min _{\alpha_{2}} \max _{\alpha_{1}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)$$ , [特别地,如果博弈有一个混合策略纳什均衡,那么 a 条件满足(见 a 部分)], $$\alpha_{1}^*$$ 是P1的最大最小化解, $$\alpha_{2}^*$$ 是玩家2的最大最小化解,  那么($$\alpha_{1}^{*}, \alpha_{2}^{*}$$)是混合策略纳什 均衡。



**首先**，结果的a部分意味着在严格竞争博弈中，每个人的混合策略纳什均衡**收益是唯一**的。

COROLLARY  342.1  严格竞争博弈中的每个混合策略纳什均衡产生相同的期望盈利组合。 Every Nash equilibrium of a strictly competitive game yields the same pair of payoffs.

如同我们已经着到的，在非严格竞争博弈中，不是所有的纳什均衡都必然产生相同的收益组合(例,考虑 BoS)



**其次**，假设 $\left(\alpha_{1}, \alpha_{2}\right)$  和 $\left(\alpha_{1}^{\prime}, \alpha_{2}^{\prime}\right)$ 都是严格竞争博弈中的混合策略纳什均衡。 那么由命题341.1 中的a部分可知，策略$\alpha_{1}$ 和$ \alpha_{1}^{\prime}$ 是P1 的最大最小化解，$\alpha_{2}$ 和$ \alpha_{2}^{\prime}$ 是玩家2 的最大最小化解。然而由 b部分的结果可知，$\left(\alpha_{1}, \alpha_{2}^{\prime}\right)$和$\left(\alpha_{1}^{\prime}, \alpha_{2}\right)$ 都是博弈的混合策略纳什均衡。也就是说，我扪有下述结果。

如果P1有两个套路, 则每个都适用.

COROLLARY 342.2  严格竞争博弈中的混合策略纳什均衡是可以**互换**的: 如果  $\left(\alpha_{1}, \alpha_{2}\right)$ 和$\left(\alpha_{1}^{\prime}, \alpha_{2}^{\prime}\right)$  是混合策略纳什均衡，那么$\left(\alpha_{1}, \alpha_{2}^{\prime}\right)$和$\left(\alpha_{1}^{\prime}, \alpha_{2}\right)$ 也是博弈的混合策略纳什均衡。

博弈 BoS 显示，非严格竞争博弈的纳什均衡不一定可以互换。



**第三**，记严格竞争博弈中P1 的均衡盈利为$$U_1^*$$ ,  命题 341.1 中的 a 部分意味着，P1的任何纳什均衡策略确保其盈利至少为$$U_1^*$$，P2 的任何纳什均衡策略确保其收益至少是 $$-U_1^*$$ 。第二个含义是，P2 的任何纳什均衡策略保证P1的收益至多为$$U_1^*$$ .

COROLLARY 343.1  在严格竞争博弈中，P1的任何纳什均衡策略可以保证他的收益至少是其均衡收益; 玩家2的任何纳什均衡策略可以保证P1的收益至多是其均衡收益。 

**均衡收益0和**.





### 12 Rationalizability 理性化



### 13  Evolutionary equilibrium  演化均衡

用博弈论来研究生物演化.

本章中我们描述了基于策略盟博弈的模型。玩家是进化中生物总体 的成员(人类、动物、植物、细菌......) ，彼此相互影响。每个玩家的行动集 由生物体通过变化获得的行为模式组成，它的盈利度量了它的生物学适应性或繁衍能力〈健康后代的期望个数〉。







### 14  Repeated games: The Prisoner’s Dilemma 重复博弈: 囚徒困境

**无名氏定理（Folk Theorem）**即在[重复博弈](https://wiki.mbalib.com/wiki/重复博弈)中，只要博弈人具有足够的耐心（[贴现因子](https://wiki.mbalib.com/wiki/贴现因子)足够大），那么在满足博弈人个人理性约束的前提下，博弈人之间就总有多种可能达成合作均衡。存在无穷多对有限自动机策略，可以成为[无限重复博弈](https://wiki.mbalib.com/wiki/无限重复博弈)的平衡点，并同时实现双方的合作。无名氏定理之所以得名，是由于[重复博弈](https://wiki.mbalib.com/wiki/重复博弈)促进合作的思想，早就有很多人提出，以致无法追溯到其原创者，于是以“无名氏”命名之。



#### 14.1 The main idea 

之前的博弈对应一次性关系;  重复博弈对应 长期关系. 

**理论的主要思想是，玩家可能会因为 "惩罚"的"威胁": 降低自己的长期回报, 而不敢利用自己的短期优势.   要开始考虑长期利益以及什么时候跑路.**    



给定一个基本博弈G (静态博弈或动态博弈)，重复进行T次G，并且在每次重复G时博弈方都
能观察到之前博弈的结果，这样的博弈过程称为“G的T次重复博弈”,记为G(T)。而G则称为G(T)的“原博弈, G(T)中的每次重复称为G(T)的一个“**阶段**”。





例如，假设两个人重复地"玩"囚徒困境, 

<img src="/img/2020-04-18-Game.assets/image-20200509035308686.png" alt="image-20200509035308686" style="zoom:33%;" />

这个策略型博弈有唯一的纳什均衡，其中，每个玩家选择 D;  现在我们来考虑重复博弈中的下述策略，被称为**"冷酷触发策略" *(the* *grim trigger strategy)*** *:*

- 只要另一个玩家选择 C，就一直选择 C 
- 如果在任何周期中，另一个玩家选择 D，那么在以后的每一个周都选择 D。

这个策略从双方合作开始，并且继绩合作下去，直至对方背叛;  对手的一次背叛触发了无情的背叛，我们可以把这解释为对对手的报复性"惩罚" . 如果对手采用这种策略，他应该怎样反应呢? 如果 他在每一个周期选择 C，那么结果是(C, C) ，他在每一周期的盈利为 2。倘若他在某个周期转向 D，那么他在那个周期得到盈利 3(短期的获利) ，并且在以后每一个周期得到盈利1(长期的损失)。只要他赋予未来盈利的值比起他赋予当前盈利的值不会太小，那么对于他来说，盈利系列 (3，1，1，...)比起盈利系列 (2，2，2，...)要糟糕些，因此，他在每一个周期选择 C 比在某个周期转而选择 D ，情况要好得多。

然而，这个"策略对"不是重复博弈中唯一的纳什均衡。另外一个纳什均衡是在每个历史之后每个玩家都选择 D的"策略对":  如果一个玩家采取这个策略，那么另一个玩家只能选D. 



这个分析提出了许多问题:

- 为了重复囚徒困境有每个周期的结局都是 (C，C) 的纳什均衡，确切地，玩家必须有多大耐心?  对未来的预期
- 其他什么结局是由纳什均衡产生的? 
- 在第五章中，展开型博弈的纳什均衡直觉上并不总是吸引人，因为在发生偏离的历史之后，他们指令的行动可能不是最优的。 子博弈完美均衡要求在每个可能的历史之后的策略是最优的，不仅是那些玩家坚持自己的策略而达到的历史，因此这个概念更加吸引 人。每个玩家都使用冷酷触发策略的"策略对"是子博弈完美均衡 吗?也就是说，每个玩家会最优地惩罚其他玩家的偏离吗?如果不会，博弈有支持称心合意结局的子博弈完柴均衡吗?
- 冷酷触发策略规定了相当严厉的报复。是否存在"玩家的策略惩罚偏离不太严厉"的纳什均衡或子博弈完美均衡?
- 论证如何适用于非囚徒困境的博弈?



#### 14.2 Preferences 偏好

##### 14.2.1 Discounting  折扣

对未来预期的数学表达方式.  **discounted sum**  折扣和,**贴现**和;   
有局限性, 偏好不一定是这样的,但能体现重视当下的偏好特征.
$$
u_{i}\left(a^{1}\right)+\delta u_{i}\left(a^{2}\right)+\delta^{2} u_{i}\left(a^{3}\right)+\cdots+\delta^{T-1} u_{i}\left(a^{T}\right)=\sum_{t=1}^{T} \delta^{t-1} u_{i}\left(a^{t}\right)
$$

假设是玩家关于盈利序列$\left(w^{1}, w^{2}, \cdots\right)$的偏好由这些盈利的"贴现和" $\sum_{t=1}^{\infty} \delta^{t-1} w^{t}$ 进行描述,这里 $0<\delta<1$ 。对于任何给定的序列 $\left(w^{1}, w^{2}, \cdots\right)$ 是否存在一个 c 值使得玩家认为收益序列和常数序列 $(c, c, \cdots)$ 之间是**等价**的.  记 $\left(w^{1}, w^{2}, \cdots\right)$  的和为V,  $(c, c, \cdots)$ 的和是$c /(1-\delta)$ , 因此,若 $c=(1-\delta) V$,那么玩家认为这两个序列之间不存在差异。所以被称为**贴现平均值discounted average**. 

准确的说, 贴现平均值为 $(1-\delta) \sum_{i=1}^{\infty} \delta^{i-1} w^{\prime}$ 。 注意,对于任何位于 0 与 1 之间的贴现因子 $\delta$以及任何数 c，常数盈利序列$(c,c,\cdots)$的贴现平均值 $(1-\delta)(c+\delta c+ \delta^2 c+ \dots) =c$。



##### 14.2.2 Equivalent payoff functions 等价收益函数

考虑在不受时间影响的**确定性**结局上的偏好时，我们发现许多收益函数描述了同一个偏好。尤其是，假如 $u$ 是描述决定性结局上的偏好的收益函数，那么  $u$ 的任意递增函数也描述了该偏好. 

当考虑不受时间影响的随机结局的偏好时，发现收益函数的等价性更具有局限性, 如果 $u$ 是一个的伯努利收益函数，它的期望值描述了关于随机结局的偏好，那么每一个期望值描述了他的偏好的其他盈利函数是 $u$ 的递增线性函数 .  (4. 12. 2) 下面证明.

对重复博弈 , 收益是序列的, 考虑等价函数.  如果两个结果序列 $\left(x^{1}, x^{2}, \ldots\right)$ and $\left(y^{1}, y^{2}, \ldots\right)$ 是等价的, 有
$$
\sum_{t=0}^{\infty} \delta^{t-1} u\left(x^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1} u\left(y^{t}\right)
$$
令 $v$  为一个 increasing affine function of $u: v(x)=\alpha+\beta u(x)$ with $\beta>0$ ,  即线性正相关.
$$
\sum_{t=0}^{\infty} \delta^{t-1} v\left(x^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1}\left[\alpha+\beta u\left(x^{t}\right)\right]=\sum_{t=0}^{\infty} \delta^{t-1} \alpha+\beta \sum_{t=0}^{\infty} \delta^{t-1} u\left(x^{t}\right)
$$

$$
\sum_{t=0}^{\infty} \delta^{t-1} v\left(y^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1}\left[\alpha+\beta u\left(y^{t}\right)\right]=\sum_{t=0}^{\infty} \delta^{t-1} \alpha+\beta \sum_{t=0}^{\infty} \delta^{t-1} u\left(y^{t}\right)
$$

则有, 
$$
\sum_{t=0}^{\infty} \delta^{t-1} v\left(x^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1} v\left(y^{t}\right)
$$


LEMMA 393.1 (**折扣收益函数的等效性Equivalence of payoff functions under discounting**) The discounted sum of payoffs with the **payoff function u** and discount factor δ represents the **same preferences** over streams of payoffs as the discounted sum of payoffs with the **payoff function v** and discount factor δ if and only if there exist α and β > 0 such that u(x) = α + βv(x) for all x.



这个结果的意义在于，对重复博弈的策略型博弈中,  即使结果是deterministic，收益也不再是简单的序数。  例如, 囚徒困境, 将下图中收益表 (0, 3),(0, 3) 换成 (0, 5), (0, 5) , 基于这个得到一个新的囚徒重复博弈, 则这两个重复博弈的玩家偏好是不一样的.   比如，当折扣因子接近于1时，在第一种情况下，每个玩家喜欢结局序列((C, C), (C, C)) 超过((D, C), (C, D))  , 在第二种情况下则不是这样。

<img src="/img/2020-04-18-Game.assets/image-20200509035308686.png" alt="image-20200509035308686" style="zoom:33%;" />



所以, 下面都要用收益函数来定义策略型博弈, 而不是偏好. 



#### 14.3 Infinitely repeated games 无限重复博弈

将一次性的strategic博弈的重复博弈,  看成perfect信息的extensive博弈. 

DEFINITION 394.1   	G , a strategic game.  **The infinitely repeated game** of $G$ for the discount factor $\delta$ is the **extensive game** with **perfect information** and **simultaneous moves** in which
- the set of players is $N$
- the set of terminal histories is the set of **infinite** sequences $\left(a^{1}, a^{2}, \ldots\right)$ of action profiles in $G$
- the player function assigns the set of all players to every proper subhistory of every terminal history
- the set of actions available to player $i$ after any history is $A_{i}$
- each player $i$ evaluates each terminal history $\left(a^{1}, a^{2}, \ldots\right)$ according to its discounted average $(1-\delta) \sum_{t=1}^{\infty} \delta^{t-1} u_{i}\left(a^{t}\right)$



把上面的无限改为T, 则为T周期重复博弈 ;

terminal history 也被 称为 结局路径. 



#### 14.4 Finitely repeated *Prisoner's Dilemma* 有限重复囚徒困境

<img src="/img/2020-04-18-Game.assets/image-20200509035308686.png" alt="image-20200509035308686" style="zoom:33%;" />

考虑囚徒困境的T周期重复博弈。假设对于每一个可能的历史，一个玩家的策略是在每一个周期选D, 那么其他人肯定也选D. 因为其他人选C更差.  因此，(D,D) 的"策略对" 是T 周期的纳什均衡。

每一个纳什均衡产生相同的结局路径. 所以该博弈不能体现本章开始所讨论的思想，即合作的结局, 可以通过对偏离进行惩罚。证明: 在两个人都选择 C 的最后一个周期里，从 C 转 向 D 的偏离**不可能受到惩罚**一一即在以后每一个周期，结局都是 (D，D) 一因此在任何周期中没有一个人会最优地选择 C.    

有限周期, 最后一个周期T是明确早就知道的, 那么绝对占便宜的人肯定会耍花样, 有理由会转向D. 那么一直倒推.   就跟一次性的囚徒困境一样. 对均衡而言, 只能是选D .    这里讨论的是由 纳什均衡 得到的策略. 纳什均衡只是想自己不比别人亏, 不考虑总体收益最大. 



#### 14.5 Infinitely repeated *Prisoner's Dilemma*  无限重复囚徒困境

无限的博弈有这样的结局路径，其中对于每一个人和每一个周期 t，存在一个"玩家的行动是 C"的未来周期，所以通过选择 D 取代 C ，他可以惩罚另一个人在周期 t 的偏离。这个事实启示了，无限重复博弈可能是体现下述想法的一个合适模型: 可以通过"惩罚"策略 使合作得以维系. 

 大多数的相互作用既不会维持一个预定的有限周期数(一个明确的T), 也不会真的无限, 那怎么建模. 那最好就是不知道什么时候结束.  直觉提出，在许多经过很长时期才结束的相互作用里，在终止期没有到来之前，终止期本身对参与者的策略算计几乎不起作用。



#### 14.6  Strategies in an infinitely repeated Prisoner's Dilemma   无限重复囚徒困境中的策略

**grim trigger strategy** 冷酷触发策略
$$
s_{i}(\varnothing)=C \\ 
\ \\
s_{i}\left(a^{1}, \ldots, a^{t}\right)=\left\{\begin{array}{ll}
C & \text { if } a_{j}^{\tau}=C \text { for } \tau=1, \ldots, t \\
D & \text { otherwise }
\end{array}\right.
$$


该策略有两个 **states 状态** : 一个是 $\mathcal{C}$ ,   在该状态选 $C$ ; 另一个是 $\mathcal{D}$ , 选 $D$  . 

用图表示,  如果一个人选D, 则状态改变.

![image-20200513045525223](/img/2020-04-18-Game.assets/image-20200513045525223.png)

下面是个变体, 没有之前那么严厉, 只处罚3个周期

<img src="/img/2020-04-18-Game.assets/image-20200513045724173.png" alt="image-20200513045724173" style="zoom:50%;" />

下面一个变体,   tit-for-tat  针锋相对策略,  一个人在前一个周期做什么, 另外一个人也做什么

<img src="/img/2020-04-18-Game.assets/image-20200513045916224.png" alt="image-20200513045916224" style="zoom:50%;" />



#### 14.7 Some Nash equilibria of an infinitely repeated *Prisoner's Dilemma*  无限囚徒困境中的一些纳什均衡

14.7.1 Grim trigger strategies











### 15 重复博弈：一般性结果



### 16 讨价还价





### 17 Appendix: Mathematics 附录：数学

#### 17.3  Sets

##### **partition 划分**    

A partition of a set $A$ is a collection $$\left\{A_{1}, \ldots, A_{k}\right\}$$ of subsets of $A$ such that every member of $A$ is in exactly one of the sets $A_{j}$. 



设n个元素的集合可以划分为F(n,m)个不同的由m个非空子集组成的集合。  
考虑3个元素的集合，可划分为  

- 1个子集的集合：$$\{\{1，2，3\}\}$$  

- 2个子集的集合：$$\{\{1，2\}，\{3\}\}，\{\{1，3\}，\{2\}\}，\{\{2，3\}，\{1\}\}$$
- 3个子集的集合：$$\{\{1\}，\{2\}，\{3\}\}$$



####  17.4 Functions

affine 仿射函数  f (x) = ax + b

quadratic 二次函数 



#### 17.5 Profiles  组合

For example, players are Ernesto, action is $R,$ and Hilda,  $S$,  function $a$ defined by $a(\text { Ernesto })=R$ and $a(\text { Hilda })=S .$  可以将 $a$ 表示为 $\left(a_{\text {Ernesto }}, a_{\text {Hilda }}\right)=(R, S) $ , 称函数 $a$ 为一个**组合profile**.  

一个常用的组合, 与$\left(a_{1}, \ldots, a_{n}\right)$  不同,因为player $i$ 的动作是 $b_{i}$  , 可以记为$\left(b_{i}, a_{-i}\right)$ ; -i 表示除i以外.   
例如  (a1, a2, a3) = (T, L, M) and b2 = R, for example, then $(b_2, a_{−2}) = (T, R, M)$.





#### 17.8 Proofs

Lemma  引理

Proposition  命题

Corollary  推论






