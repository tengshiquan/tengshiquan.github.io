---
layout:     post
title:      Game Theory 笔记
subtitle:   Osborne的两本博弈论经典
date:       2020-04-01 12:00:00
author:     "tengshiquan"
header-img: "img/post-bg-dice.jpg"
catalog: true
tags:

    - AI
    - Game Theory

---






# An Introduction to Game Theory

比"A Course in Game Theory" 那本书数学上简单

总体上的区别,   博弈中, 不考虑马尔可夫性.  对具体问题都是具体建模,精确地求纳什均衡的解. 

历史是action的序列,    state的有特殊的含义. 



#### 总体结构

<img src="/img/2020-04-18-Game.assets/image-20200505013213150.png" alt="image-20200505013213150" style="zoom:50%;" />



### 1	引论

#### 1.1 何为博弈论？

#### 1.2 理性选择理论

#### 1.3 下一吸引点：相互作用的决策者



## Part I:  Games with Perfect Information 完全信息博弈

### 2	Nash Equilibrium 纳什均衡：理论  

#### 2.1 Strategic games 策略型博弈 

概念: *players*, *actions* , *preferences* ,  
action *profile*—the list of all the players’ actions   
*payoff functions* 收益函数

**DEFINITION 11.1** (*Strategic game with ordinal preferences*) A **strategic game** (with ordinal preferences) consists of

- a set of **players**  
- for each player, a set of **actions**
- for each player, **preferences** over the set of action profiles.



请记住，这些payoff只有**序数**意义 ***ordinal* significance**。例如，如果一个玩家对a、b和c这三个动作的payoff分别为1、2和10，我们唯一能得出的结论是，玩家更喜欢c而不是b，b更喜欢a；这些数字并不意味着玩家在c和b之间的偏好比他在a和b之间的偏好更强。

**模型中没有时间的概念。** 它的想法是，每个玩家选择自己的行动是一劳永逸的，而玩家选择自己的行动是 "同时"进行的，也就是说，当他选择行动的时候，没有一个玩家被告知其他玩家选择的行动。因此，策略游戏有时被称为 "同时行动游戏"。然而，一个行动可能涉及到的活动会随着时间的推移而延长，并可能考虑到无限多的突发事件。例如，一个行动可以规定，"如果X公司的股票跌到10美元以下，买入100股；否则，不要买入任何股票"。(因此，一个行动有时被称为 "**策略strategy**"。) 然而，模型中没有时间这一事实意味着，当把一个情况作为一个策略博弈来分析时，我们可以从可能出现的复杂问题(如果允许玩家随着事件的发展而改变他的计划)中抽离出来：我们假设行动是一劳永逸的。





#### 2.2 例：囚徒困境 the Prisoner’s Dilemma

最著名的策略博弈之一是 "囚徒困境" ;  收益矩阵

|        | 沉默 | *坦白* |
| :---: | :--: | :--: |
|  沉默  | 2,2  |  0,3   |
| *坦白* | 3,0  |  1,1   |

**囚徒困境主要适用于 合作是有益的, 但每个玩家都有投机取巧的动机.** 



##### 2.2.1 Working on a joint project 联合项目

你正在和朋友一起做一个联合项目。你们可以选择努力工作，也可以选择 "傻乐"。如果你的朋友努力工作，那么你更喜欢 "傻乎乎"（如果你也努力工作，项目的结果会更好，但对你来说，项目的价值增量并不值得额外的努力）。你更喜欢你们两个人都努力工作的结果，而不是你们两个人都傻乎乎的结果（在这种情况下，什么都没有完成），对你来说，最坏的结果是你努力工作，而你的朋友傻乎乎的结果（你讨厌被 "利用"）。如果你的朋友也有同样的偏好，那么你所面临的情况的游戏模型如图14.1所示，正如你所看到的，它与 "囚徒困境 "只是在行动的名称上有所不同. 



##### 2.2.2 Duopoly  双寡头垄断

在一个简单的二元垄断模型中，两家公司生产同样的产品。每家公司都希望获得尽可能高的利润。如果两家公司都选择高价，那么每家公司的利润为1000美元。如果一家公司选择高价，另一家公司选择低价，那么选择高价的公司没有顾客，亏损200美元，而选择低价的公司则赚取1200美元的利润（单位利润很低，但销量很高）。如果两家公司都选择Low，那么每家公司的利润为600美元。每个公司只关心自己的利润，所以我们可以用它所获得的利润来表示它的偏好，得出图14.2中的博弈。

|      |   High    |    Low    |
| :--: | :-------: | :-------: |
| High | 1000,1000 | -200,1200 |
| Low  | 1200,-200 |  600,600  |



##### 2.2.3 The arms race 军备竞赛

##### 2.2.4 Common property 公共财产



#### 2.3 例：欣赏巴赫音乐还是斯特拉文斯音乐？ BoS

这个例子中，玩家们一致认为合作比不合作好，但对最佳结果有不同意见。 例如两个政党制定政策.

|              | *Bach* | *Stravinsky* |
| :---: | :--: | :--: |
| *Bach*       | 2,1    | 0,0          |
| *Stravinsky* | 0,0    | 1,2          |



#### 2.4 例：抛掷硬币打赌  Matching Pennies

这个例子是 纯粹的冲突性博弈.   **strictly competitive 严格竞争**

|      | Head | Tail |
| :--: | :--: | :--: |
| Head | 1,-1 | -1,1 |
| Tail | -1,1 | 1,-1 |



#### 2.5 例：猎鹿  the Stag Hunt

一群猎人中的每个人都有两个选择：可以继续专心致志地去追捕一只雄鹿，也可以去抓一只野兔。如果所有的猎人都去追赶雄鹿，那么他们就会抓到雄鹿并平分；如果任何一个猎人把精力放在抓野兔上，那么雄鹿就会逃跑，而野兔就属于叛变的猎人一个人。每一个猎人都喜欢分得部分雄鹿，而不是一只野兔。

2个猎人的情况

|      |  鹿  | 兔子 |
| :--: | :--: | :--: |
|  鹿  | 2,2  | 0,1  |
| 兔子 | 1,0  | 1,1  |





#### 2.6 纳什均衡

A *Nash equilibrium* is an action profile $a^∗$ with the property that no player $i$ can do better by choosing an action different from $a^∗_i$ , given that every other player $j$ adheres to $a^∗_j$ .

在理想化的情况下，在任何给定博弈中的玩家都是从一组人群中随机抽取的，**纳什均衡对应于稳定状态*steady state***。无论何时博弈开始时，行动组合是相同的纳什均衡$a^∗$，那么没有任何玩家有理由选择与他的分量$a^∗$不同的行动.

换个说法，纳什均衡体现了一个稳定的 "社会规范 social norm"：如果其他人都遵守这个规范，没有人愿意偏离这个规范。

**DEFINITION 21.1** (**Nash equilibrium of strategic game with ordinal preferences**) The action profile $$a^{*}$$ in a strategic game with ordinal preferences is a Nash equilibrium if, for every player $$i$$ and every action $$a_{i}$$ of player $$i$$ ,    $$a^{*}$$ is at least as good according to player $$i$$ 's preferences as the action profile $$\left(a_{i}, a_{-i}^{*}\right)$$ in which player $$i$$ chooses $$a_{i}$$ while every other player $$j$$ chooses $$a_{j}^{*} .$$ Equivalently, for every player $$i$$, 
$$u_{i}\left(a^{*}\right) \geq u_{i}\left(a_{i}, a_{-i}^{*}\right)$$ for every action $$a_{i}$$ of player $$i$$ ,  where $$u_{i}$$ is a payoff function that represents player $$i$$ 's preferences.

**纳什均衡** :  $$u_{i}\left(a^{*}\right) \geq u_{i}\left(a_{i}, a_{-i}^{*}\right)$$

纳什均衡就是一个点(也可能是区域), 达到这个稳态后, 任何人自己私自偏离,都会有导致自己收益减少的情况. 

这个定义既不意味着一个策略博弈一定有纳什均衡，也不意味着它最多有一个纳什均衡。



#### 2.7 纳什均衡例题

##### 2.7.1 Prisoner’s Dilemma

|        | 沉默 | *坦白* |
| :----: | :--: | :----: |
|  沉默  | 2,2  |  0,3   |
| *坦白* | 3,0  |  1,1   |

(*Fink*, *Fink*) is the unique Nash equilibrium.

(告密，沉默) 不满，因为当玩家 1 选择"告密"时，玩家 2 选择"告密"的盈利超过选择"玩默"的盈利,  (沉默,沉默)每个人都有动机偏离.   

当一个人选择坦白, 追求自己的高收益的时候, 需要一个人沉默, 而另外一个也会选择该前提下自己的高收益, 这时会造成前一个人高收益落空.





##### 2.7.2 BoS

two Nash equilibria: (*Bach*, *Bach*) and (*Stravinsky*, *Stravinsky*) 



##### 2.7.3 Matching Pennies

该问题没有纳什均衡;  即每个玩家都用确定策略来玩,其中一个玩家如果输了,则改变其策略肯定能获利

##### 2.7.4 The Stag Hunt

two Nash equilibria: (*Stag*, *Stag*) and (*Hare*, *Hare*)

##### 2.7.6 A coordination game  协调博弈

|              |  *Bach*   | *Stravinsky* |
| :----------: | :-------: | :----------: |
|    *Bach*    | 2, 2 | 0,0 |
| *Stravinsky* |    0,0    |     1,1      |



##### 2.7.7 Provision of a public good

##### 2.7.8 Strict and nonstrict equilibria 严格均衡

在我们迄今所研究的所有纳什均衡的博弈中，玩家的偏离导致的结果比均衡结果更差。然而，纳什均衡的定义(21.1)只要求偏离的结果不比均衡结果好, 不一定需要更差. 而且，事实上，有些博弈中的平衡状态是，鉴于其他博弈者的行动，玩家在他的平衡行动和其他的行动之间无动于衷。

考虑图31.1中的博弈。这个博弈有一个独特的纳什均衡，即（T，L）。(对于其他每一对行动，其中一个玩家的行动最好是改变他的行动)。当玩家2选择了L，就像他在这个均衡中一样，玩家1选择T或B是同样快乐的；如果他偏离了B，那么他的情况并不比他在均衡中的情况更糟。我们说，纳什均衡（T，L）不是一个**严格均衡*strict equilibrium***。

|      |  L   |  M   |  R   |
| :--: | :--: | :--: | :--: |
|  T   | 1,1  | 1,0  | 0,1  |
|  B   | 1,0  | 0,1  | 1,0  |

对于一个一般博弈，如果每个玩家的均衡行动都比该玩家其他的行动好，那么这个均衡是严格的。



#### 2.8 best response function 最优反应函数,  最佳应对

##### 2.8.1 Definition

Precisely, we define the function $$B_{i}$$ by

$$
B_{i}\left(a_{-i}\right)=\left\{a_{i} \text { in } A_{i}: u_{i}\left(a_{i}, a_{-i}\right) \geq u_{i}\left(a_{i}^{\prime}, a_{-i}\right) \text { for all } a_{i}^{\prime} \text { in } A_{i}\right\}:
$$

any action in $$B_{i}\left(a_{-i}\right)$$ is at least as good for player $$i$$ as every other action of player $$i$$ when the other players' actions are given by $$a_{-i}$$. We call $$B_{i}$$ the **best response function** of player $$i$$ . 

该函数返回, 给定其他人一个动作的情况下, 玩家i能获得最大回报的那些动作. 显然该函数与其他人的动作相关.



##### 2.8.2 Using best response functions to define Nash equilibrium   用最优应对函数定义均衡

纳什均衡是一个行动组合，具有这样的属性：给定其他玩家的行动，没有一个玩家可以通过改变自己的行动来做得更好。使用刚才的术语，我们可以将纳什均衡定义为：**每个玩家的行动都是对其他玩家行动的最佳反应**。

占优策略. 

**PROPOSITION 34.1** The action profile a* is a **Nash equilibrium** of a strategic game with ordinal preferences if and only if every player's action is a **best response** to the other players' actions:  
$$
a_{i}^{*} \text{ is in }B_{i}\left(a_{-i}^{*}\right) \text{ for every player }i \tag{34.2}
$$

B这里指Best的集合.



若每个玩家都只有一个最优反应的情况 , 可以改写为:  for each player $i$ and each list $a_{-i}$ of the other players' actions, denote the single member of $$B_{i}\left(a_{-i}\right)$$ by $$b_{i}\left(a_{-i}\right)$$ (that is, $$B_{i}\left(a_{-i}\right)=\left\{b_{i}\left(a_{-i}\right)\right\}$$ ). Then (34.2) is equivalent to 
$$
 a_{i}^{*}=b_{i}\left(a_{-i}^{*}\right) \text{ for every player }i  \tag{34.3}
$$



##### 2.8.3 Using best response functions to find Nash equilibria  使用最优反应函数寻找纳什均衡

例题37.1（协同synergistic 关系）两个人参与了一种协同关系。如果两个人都对这种关系付出更多的努力，他们都会得到更好的回报。先固定玩家j的努力，玩家i的回报随着其自身的努力先增加，然后减少。具体来说，努力水平是一个非负数，玩家i的偏好 (for $i=1,2$ ) 由报酬函数$a_{i}\left(c+a_{j}-a_{i}\right)$表示，其中$a_i$是$i$的努力水平，$a_{j}$是另一个人的努力水平，$c>0$是一个常数。

下面建模: 

- Players The two individuals.
- Actions,  set of effort levels (非负数).
- Preferences,  Player $i^{\prime}$ s preferences are represented by the payoff function $a_{i}(c+  a_{j}-a_{i} )$,  for $i=1,2$ 



特别是，每个玩家都有无限多的动作，所以我们不能像以前那样用表格来解决. 

为了找到博弈的纳什均衡，我们可以构造和分析玩家的最佳反应函数。给定$a_{j}$，个体$i$的报酬率是$a_{i}$的二次函数，极值点 $b_{i}\left(a_{j}\right)=\frac{1}{2}\left(c+a_{j}\right)$ , 

 最佳响应函数如图38.1所示。

<img src="/img/2020-04-18-Game.assets/image-20200505205335276.png" alt="image-20200505205335276" style="zoom:33%;" />

两条线的交点就是纳什均衡. 





#### 2.9 Dominated actions 被支配行动, 劣行动

严劣, 弱劣

##### 2.9.1 Strict domination  严格支配

你把车开到一个红绿灯前。左边车道是自由的，而右边车道有一辆车可能在红灯变绿灯时右转，在这种情况下，它必须等待行人过马路。假设你想尽快前进，选择左侧车的动作 "严格支配 "了在选择右侧车道的动作。如果右车道上的车向右转，那么你最好在左车道上行驶，这样你的进步就不会受到阻碍；即使右车道上的车没有向右转，你也最好在左车道上行驶，而不是在对方后面。
在任何游戏中，如果一个玩家的动作是优越的，无论其他玩家怎么做，都会 "严格地支配 dominates"另一个动作。

**DEFINITION 43.1** (**Strict domination 严格支配**) In a strategic game with ordinal preferences, player $i^{\prime}$ 's action $a_{i}^{\prime \prime}$ strictly dominates her action $a_{i}^{\prime}$ if  $u_{i}\left(a_{i}^{\prime \prime}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions,  where $u_{i}$ is a payoff function that represents player $i$ 's preferences.

例如，在囚徒困境中，Fink的动作严格地支配着Quiet的动作：无论对手的动作如何，玩家选择Fink时的结果比选择Quiet时的结果更倾向于选择Fink的结果。另一方面，在BoS博弈中，两个动作都不能严格地支配另一个动作。如果对方选手选择巴赫，则巴赫比斯特拉文斯基好，但如果对方选手选择斯特拉文斯基，则比斯特拉文斯基差。

如果一个行动严格支配了行动$a_i$，我们说$a_i$是严格被支配行动。一个严格被支配的行动并不是对其他玩家的任何行动的最佳反应：无论其他玩家做什么，其他一些行动都是更好的。由于一个玩家的纳什均衡行动是对其他玩家的纳什均衡行动的最佳响应。*a strictly dominated action is not used in any Nash equilibrium.* 一个被支配行动不会用在任何纳什均衡中. 



##### 2.9.2 Weak domination 弱支配

当你在上一节开始的情况下接近红灯时，每条车道上都有一辆车。右边车道上的车可能是右转，也可能不是右转；如果是右转，可能会被过路的行人耽误。左边车道的车不能右转。在这种情况下，你在左车道拉起的车，虽然不是严格意义上的主宰，但你在右车道拉起的车 "微弱地支配了"。如果右车道的车不能右转，那么两个车道的车都是一样的好；如果是右转，那么左车道的车就比较好。

**DEFINITION 45.1** (Weak domination) In a strategic game with ordinal preferences, player $i^{\prime}$ s action $a_{i}^{\prime \prime}$ weakly dominates her action $a_{i}^{\prime}$ if $u_{i}\left(a_{i}^{\prime \prime}, a_{-i}\right) \geq u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions
and $u_{i}\left(a_{i}^{\prime \prime}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for some list $a_{-i}$ of the other players' actions. 

严格支配是大于, 弱支配是大于等于. 



#### 2.10 Equilibrium in a single population: symmetric games and symmetric equilibria 单一群体中的均衡：对称博弈和对称均衡

大意就是, 一个群体有统一的策略.  那么来自一个群体的玩家之间达成的平衡是什么样的. 

一个策略博弈的纳什均衡对应于多个种群成员之间相互作用的稳定状态，每个博弈中的每个玩家都有一个种群成员参与其中。有时，我们想建立一个模型，在这种情况下，单个同质种群的成员匿名参与到对称互动中。例如，考虑一下，行人在人行道上互相接近，或者汽车司机从不同方向同时到达十字路口。在每种情况下，每次相遇的成员都来自于同一人群：来自单一人群的行人相互相遇，而来自单一人群的汽车司机群体同时接近交叉路口。而在每种情况下，每个参与者的角色都是一样的。

两人博弈为"对称的"如果每个人有相同的行动集，以及每个人的收益仅依赖于他和对手的行动，不取决于他的角色. 

DEFINITION 49.3  (**Symmetric two-player strategic game with ordinal preferences 序数偏好的对称的两人策略塑博弈**) A two-player strategic game with ordinal preferences is **symmetric** if the players’ sets of actions are the same and the players’ preferences are represented by payoff functions $u_1$ and $u_2$ for which $u_1(a_1, a_2) = u_2(a_2, a_1)$ for every action pair $(a_1, a_2)$.

行动集相同, 且收益函数对称, 所以偏好也是相同的.  纳什均衡也是对称的. 

<img src="/img/2020-04-18-Game.assets/image-20200508043410979.png" alt="image-20200508043410979" style="zoom:50%;" />



DEFINITION 50.2 (**Symmetric Nash equilibrium 对称纳什均衡**)  即该均衡对博弈里的所有玩家都一样.

例子，考虑一个正在接近的行人的模型。在任意给定的遭遇中，每个参与者有两个可能的行动, 朝右或左, 当参与者都以同样的方向行走，结果好于以不同的方向行走 (在后一种情况，会发生相撞)

<img src="/img/2020-04-18-Game.assets/image-20200508043811278.png" alt="image-20200508043811278" style="zoom:33%;" />

对称博弈可以没有对称的纳什均衡。

<img src="/img/2020-04-18-Game.assets/image-20200508044038682.png" alt="image-20200508044038682" style="zoom:33%;" />







### 3 纳什均衡：例证

#### 3.1 古诺特寡头垄断模型

#### 3.2 伯川德寡头垄断模型

#### 3.3 竞选

#### 3.4 消耗战

#### 3.5 拍卖

#### 3.6 民事法



### 4 Mixed Strategy Equilibrium 混合策略均衡

大意, 之前一个策略就是确定的一个动作, 现在把一些动作混合在一起, 随机的抽取, 就叫混合策略. 理解为随机策略也可. 纯策略之所以会劣于随机策略, 是因为随机策略里面包含随机因素, 相当于部分的信息不对称, 对方不知道要出什么招, 只能以不变应万变, 所以会有优势. 



#### 4.1 引言

##### 4.1.1 Stochastic steady states  随机稳态

之前是理想化的稳态, 在这个稳态中，游戏中的每个玩家都有一个群体，每当游戏进行时，从每个群体中随机抽取一个玩家（见第2.6节）。在稳态下，每当玩家进行游戏时，每一个玩家的行为都是一样的，没有一个玩家希望改变自己的行为，因为他知道（根据他的经验）其他玩家的行为。在稳定状态下，每个玩家的 "行为"只是一个动作，而在每个群体中，所有玩家选择的动作都是一样的，在**稳定状态**下，每一次游戏的结果都是相同的纳什均衡。

更一般的稳态概念允许玩家的选择有变化，只要选择的模式保持不变。例如，在一个给定的群体中，不同的成员可能会选择不同的行动，每一个玩家在玩游戏时都会选择相同的行动。或者每个人在每次玩游戏的时候，都可能根据相同的、不变的分布，在概率上选择自己的行动。这两种更一般的稳态概念是等价的：第一种类型的稳态，其中代表玩家i的群体中选择行动a的部分p对应于第二种类型的稳态，其中代表玩家i的人口中的每一个成员都以概率p选择a。为了解释的方便，在本章的大部分内容中，我将这样的均衡解释为第二种稳态的模型，在这种稳态中，每个玩家都是以概率的方式选择自己的行动；这样的稳态被称为随机的（"涉及概率"）。



##### 4.1.2 Example: Matching Pennies

重要例子, 该博弈**没有纯策略纳什均衡**;  但有一个**随机*stochastic*的稳态**，即 每个玩家选择他的每一个动作的概率为1/2.  可以证明, 只要玩家选择1/2的概率, 则不论另外一个玩家怎么改变策略, 收益期望都是不变的.



##### 4.1.3 Generalizing the analysis: expected payoffs  期望收益

例, 彩票对应3个结果, P中大奖几率高, 偏好选P: three outcomes $a, b,$ and $c,$ and lottery $P$ yields $a$ with probability $p_{a}, b$ with probability $p_{b},$ and $c$ with probability $p_{c},$ whereas lottery $Q$ yields these three outcomes with probabilities $q_{a}, q_{b},$ and $q_{c} .$ Then the assumption is that for each player $i$ there are numbers $u_{i}(a), u_{i}(b),$ and $u_{i}(c)$ such that player $i$ prefers lottery $P$ to lottery $Q$ if and only if $p_{a} u_{i}(a)+p_{b} u_{i}(b)+p_{c} u_{i}(c)> q_{a} u_{i}(a)+q_{b} u_{i}(b)+q_{c} u_{i}(c) $.  

**vNM preferences**  对随机的情况, 偏好选结果的期望大的. 

**Bernoulli payoff function** , $p_{a} u_{i}(a)+p_{b} u_{i}(b)+p_{c} u_{i}(c)$  





#### 4.2 Strategic games in which players may randomize 有随机行为的策略型博弈

**DEFINITION 103.1**   A **strategic game** (with vNM preferences) consists of

- a set of **players**
- for each player, a set of **actions**
- for each player, **preferences** regarding lotteries over action profiles that may be represented by the expected value of a (“Bernoulli”) payoff function over action profiles.



#### 4.3 Mixed strategy Nash equilibrium 混合策略纳什均衡

##### 4.3.1 Mixed strategies 混合策略

**混合策略**就是在几个action上有概率的随机选择, 例如,猜拳, 每个1/3. 

混合策略可以将概率1分配给一个单一行动：通过允许玩家选择概率分布，允许其选择确定性行动。我们把这种混合策略称为**纯策略 pure strategy**。

##### 4.3.2 Equilibrium 均衡

定义 105.1(**具有 vNM 偏好的策略型博弈的混合策略纳什均衡** *Mixed strategy Nash equilibrium of strategic game with vNM preferences*)  如果 $$U_{i}\left(\alpha^{*}\right) \geq U_{i}\left(\alpha_{i}, \alpha_{-i}^{*}\right)$$ , 混合策略组合$$\alpha^*$$ 是一个纳什均衡

把之前的收益函数改成mixed strategy profile $$\alpha$$的 期望收益$$U_{i}(\alpha)$$即可. 



##### 4.3.3 Best response functions 最优反应函数

从混合策略均衡的定义来看，**如果且仅当每个玩家的混合策略都是对其他玩家的混合策略的最佳反应时，则混合策略组合$\alpha^{*}$ 就是混合策略的纳什均衡**.     
 $$\alpha^{*}$$ is a mixed strategy Nash equilibrium if and only if $$\alpha_{i}^{*}$$ is in $$B_{i}\left(\alpha_{-i}^{*}\right)$$ for every player $i$ 



##### 4.3.4 Best response functions in two-player two-action games 特殊情况的最优反应函数

混合策略pair $\left(\alpha_{1}, \alpha_{2}\right)$在四种可能的游戏结果上产生的概率分布如图

|        |  L(q)  |   R(1-q)   |
| :----: | :----: | :--------: |
|  T(p)  |   pq   |   p(1-q)   |
| B(1-p) | (1-p)q | (1-p)(1-q) |



玩家1的期望收益为:

$$
p q \cdot u_{1}(T, L)+p(1-q) \cdot u_{1}(T, R)+(1-p) q \cdot u_{1}(B, L)+(1-p)(1-q) \cdot u_{1}(B, R)
$$

改写为: 

$$
p\left[q \cdot u_{1}(T, L)+(1-q) \cdot u_{1}(T, R)\right]+(1-p)\left[q \cdot u_{1}(B, L)+(1-q) \cdot u_{1}(B, R)\right]
$$

第一个方括号是玩家1使用纯策略T, 玩家2使用混合策略$\alpha_{2}$时的预期回报,   第二个是玩家1使用纯策略B, 玩家2使用混合策略$\alpha_{2}$时的预期回报;  分别记为 $E_{1}\left(T, \alpha_{2}\right)$ and $E_{1}\left(B, \alpha_{2}\right) .$ 玩家1的期望收益改写为:   即在自己的动作上将期望拆分. 

$$
p E_{1}\left(T, \alpha_{2}\right)+(1-p) E_{1}\left(B, \alpha_{2}\right)
$$

给定玩家2的混合策略以后, 玩家1的期望收益就是线性函数.

<img src="/img/2020-04-18-Game.assets/image-20200505221618206.png" alt="image-20200505221618206" style="zoom: 50%;" />

**给定对方采用混合策略以后, 自己的收益函数是线性的, 而且最优的点在两端.  如果对方在均衡点上, 则自己没法通过单独改变混合策略来获益. 自己在均衡点上, 对方也没法单独改变策略来获益.  对方在均衡点上, 不让自己有机可乘; 自己在均衡点上, 不让对方有机可乘**

玩家1的线性预期回报的一个重要结论是，他对玩家2的混合策略有三种可能的最佳反应。

1. 玩家1唯一的最佳反应是纯策略T (if $E_{1}\left(T, \alpha_{2}\right)>E_{1}\left(B, \alpha_{2}\right)$) 

2. 玩家1唯一的最佳反应是纯策略B (if $E_{1}\left(B, \alpha_{2}\right)>E_{1}\left(T, \alpha_{2}\right)$)，在这种情况下，玩家1的预期回报率与图108.1中的p的函数关系线向下倾斜

3. 玩家1的所有混合策略都会产生相同的预期回报，因此都是最好的反应($E_{1}\left(T, \alpha_{2}\right)=E_{1}\left(B, \alpha_{2}\right)$)，在这种情况下，在图108.1的类比中，代表玩家1的预期回报率与p的函数的线是水平的

特别是， 混合策略$(p, 1-p)$ $0<p<1$永远不是唯一的最佳反应，要么它不是最佳反应，要么所有的混合策略都是最佳反应。



##### 4.3.5 Example: Matching Pennies 

4.1.2 已经证明了有唯一的混合策略纳什均衡.  现在用2.8.3节的方法.

设玩家1选head几率为p, 玩2选head几率为q.   
则玩家1选纯策略,head的预期收益为 q · 1 + (1 − q) · (−1) = 2q − 1, 选tail的预期收益为 q·(−1)+(1−q)·1 = 1−2q .  这时的预期收益完全由玩家2的q来决定.    
当知道了玩家2 的q之后, 玩家1的纯策略最佳反应函数为: 

$$
B_{1}(q)=\left\{\begin{array}{ll}
\{0\} & \text { if } q<\frac{1}{2} \\
\{p: 0 \leq p \leq 1\} & \text { if } q=\frac{1}{2} \\
\{1\} & \text { if } q>\frac{1}{2}
\end{array}\right.
$$


同理,如果玩家1采样p的概率, 玩家2的用纯策略, 则相应的最近反应函数也类似.

将这两个函数都画到下图里面, 唯一的交点就是 混合策略的纳什均衡.

<img src="/img/2020-04-18-Game.assets/image-20200508033716605.png" alt="image-20200508033716605" style="zoom:50%;" />



##### 4.3.6 Example: BoS

纯策略有两个纳什均衡.   对于这种, 2个人2个动作的, 对于混合策略, 因为别人走了随机, 所以只要别人不是在均衡点上, 自己这边肯定需要把策略偏向某个方向. 只有自己也在均衡点上, 就不用管对方怎么变, 自己都是期望最优了.



<img src="/img/2020-04-18-Game.assets/image-20200508034115026.png" alt="image-20200508034115026" style="zoom:33%;" />
$$
B_{1}(q)=\left\{\begin{array}{ll}
\{0\} & \text { if } q<\frac{1}{3} \\
\{p: 0 \leq p \leq 1\} & \text { if } q=\frac{1}{3} \\
\{1\} & \text { if } q>\frac{1}{3}
\end{array}\right.
$$

<img src="/img/2020-04-18-Game.assets/image-20200508034351923.png" alt="image-20200508034351923" style="zoom:50%;" />

黑点是纳什均衡, 中间的交点的黑点是混合策略的纳什均衡. 



##### 4.3.7 A useful characterization of mixed strategy Nash equilibrium 混合策略均衡的有用特征



目前为止，用来研究混合策略纳什均衡集合的方法涉及 构建最佳响应函数。其他的方法有时也是有用的。我现在提出一个混合策略均衡的特征，它为我们提供了一个简单的方法来检查一个混合策略组合是否是均衡，并且是寻找一个博弈的所有均衡的程序（在4.10节中描述）的基础。

关键是在第4.3.4节中对双人双动博弈的分析：玩家对**混合策略组合的预期回报是他对纯策略的预期回报的加权平均**，其中每个纯策略的权重是玩家的混合策略分配给该策略的概率。这个属性对于任何博弈（有任意数量的玩家）都适用。我们可以更精确地说明如下：

玩家对混合策略组合 $\alpha$ 的预期收益为, 其对所有形式为 $\left(a_{i}, \alpha_{-i}\right)$ 的混合策略(这里自己的部分是纯策略)的组合的预期收益的加权平均, 权重是  $\alpha_i(a_i)$ , 表示 $\alpha_{i}$ 分配给 $a_i$ 的概率. 

$$
U_{i}(\alpha)=\sum_{a_{i} \in A_{i}} \alpha_{i}\left(a_{i}\right) U_{i}\left(a_{i}, \alpha_{-i}\right)  \tag{113.1}
$$

其中,  $$A_{i}$$ 是玩家 $$i$$ 的纯策略动作集,  $$U_{i}\left(a_{i}, \alpha_{-i}\right)$$ 是玩家以概率1执行纯策略, 其他人 $$j$$ 使用混合策略$$\alpha_{j}$$ 的预期收益. 

该性质可以推出混合策略均衡的一个有用的特性:   $$\alpha^{*}$$ 为混合策略均衡,   $$E_{i}^{*}=U_{i}\left(\alpha^{*}\right)$$ 为该均衡策略的预期回报.  因为 $$\alpha^{*}$$ 为混合均衡, 则给定 $$\alpha_{-i^{\prime}}^{*}$$ 的情况下, 玩家i的所有策略(包含纯策略)的预期回报最多是 $$E_{i}^{*}$$.  由$$(113.1)$$, 可得, $$E_{i}^{*}$$  是 属于混合策略均衡的那些纯策略$$a^*_i$$ (即被分配了正概率)的预期回报的加权平均, 权重是分配给各个纯策略$$a^*_i$$的概率. 于是, 这些纯策略$$a^*_i$$的预期回报都等于$$E_{i}^{*}$$ .(如果那个纯策略的回报小了,则总体的加权平均值肯定要下降).   同时, 其他的那些不属于混合策略均衡的纯策略$$a_i$$的预期回报$$ \leq E_{i}^{*}$$ .   

反过来说,  找到那些纯策略 $$a_{i}^{*}$$的预期回报都是$$E_{i}^{*}$$的, 那么这些纯策略组合起来的混合策略就是纳什均衡. 

PROPOSITION 113.2  (**Characterization of mixed strategy Nash equilibrium of finite game 有限搏弈的混合策略纳什均衡的特性**)      
策略型博弈中, 混合策略组合 $$\alpha^*$$ 是纳什均衡,当且仅当,   对每个玩家$$i$$,  

- 给定对手策略$$\alpha_{-i}$$的情况下, $$\alpha^*$$ 分配正概率的每个行动的预期收益是相同的 $$ = E_{i}^{*}$$ , 说明其他人在均衡点, 自己怎么调都没用,不能额外获利
- 给定对手策略$$\alpha_{-i}$$的情况下, $$\alpha^*$$ 分配0概率的每个行动的预期收益 $$ \leq E_{i}^{*}$$ ,  劣的直接排除.

该结论的重要意义是, 它给出了混合策略纳什均衡的条件，即每个玩家的预期回报跟他的纯策略相关。对于有限多行动的博弈，可以很容易地检验混合策略组合是否是均衡。

例,  BoS ,  策略对 $\left(\left(\frac{2}{3}, \frac{1}{3}\right),\left(\frac{1}{3}, \frac{2}{3}\right)\right)$ 是混合策略均衡, 因为给定玩家2的策略 $\left(\frac{1}{3}, \frac{2}{3}\right)$, 玩家1的关于B和S的预期收益都是 $\frac{2}{3},$ 说明玩家2在均衡点上;  并且 给定玩家1的策略 $\left(\frac{2}{3}, \frac{1}{3}\right)$, 玩家2关于B和S的预期收益也都等于 $\frac{2}{3}$ , 说明玩家1在均衡点上. 



**很有用**  EXAMPLE 114.1 (检测一个策略组合是不是混合策略均衡) 

<img src="/img/2020-04-18-Game.assets/image-20200508172839897.png" alt="image-20200508172839897" style="zoom: 50%;" />

玩家1的策略$\left(\frac{3}{4}, 0, \frac{1}{4}\right)$,  玩家2的策略$\left(0, \frac{1}{3}, \frac{2}{3}\right)$ . 下面验证.  
对玩家1的收益预期为  
$T: \frac{1}{3} \cdot 3+\frac{2}{3} \cdot 1=\frac{5}{3}$  
$M: \frac{1}{3} \cdot 0+\frac{2}{3} \cdot 2=\frac{4}{3}$  
$B: \frac{1}{3} \cdot 5+\frac{2}{3} \cdot 0=\frac{5}{3}$  
所以玩家1满足定理113.2  
玩家2 , 纯策略的收益为$\frac{5}{2}\left(\frac{3}{4} \cdot 2+\frac{1}{4} \cdot 4=\frac{3}{4} \cdot 3+\frac{1}{4}  1=\frac{3}{4} \cdot 1+\frac{1}{4} \cdot 7=\frac{5}{2}\right),$ 所以也满足条件.

 

命题113.2的一个含义是，一个非退化的混合策略均衡（不是概率为1的纯策略均衡的那种混合）从来都不是**严格 strict 的纳什均衡**：every player whose mixed strategy assigns positive probability to more than one action is indifferent between her equilibrium mixed strategy and every action to which this mixed strategy assigns positive probability. 每个玩家对混合策略里面的选哪个动作无所谓, 因为其他人都在均衡点上. 



##### 4.3.8 Existence of equilibrium in finite games  有限博弈均衡的存在性

玩家有限多个行动的博弈都至少有一个混合策略纳什均衡。



#### 4.4 Dominated actions 劣行动

注意, 这里的比较, 都是 纯策略与混合策略的比较.   纯策略之间比没啥意思, 一眼就看出来了.

DEFINITION 117.1 (**Strict domination 严优**)  

注意, 前面是alhpa, 后面是a ;  严劣就是确定比别的东西差的.

混合策略组合 $\alpha_{i}$ **严优strictly dominates** 于 $a_{i}^{\prime}$ ,  if  $U_{i}\left(\alpha_{i}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions . 

即,玩家i的这个混合策略$\alpha_{i}$, 比任何其他的纯策略的回报都要好.



例子, 图117.1(其中只给出了玩家1的回报)  ,  行动T不**严劣strictly dominated**于M或者B,   即T 不弱于M或者B, 但T 弱于"1/2 选M ,1/2选B",  玩家2最好的应对是选R, 这时玩家1的期望回报是 3/2 , 大于1.

<img src="/img/2020-04-18-Game.assets/image-20200508022703992.png" alt="image-20200508022703992" style="zoom:33%;" />

**在任何混合策略纳什均衡中，严劣行动不被使用。** 一个纯的弱于一个组合,那肯定选组合.



#### 4.5 Pure equilibria when randomization is allowed 随机的纯策略均衡

证明:  对一般的博弈, 不允许玩家随机选择行动时的均衡，在允许玩家随机选择后仍然为均衡; 并且，允许玩家随机时存在的任何纯策略均衡，在不允许随机后也存在。



#### 4.6 例证：专家诊断



#### 4.7 Equilibrium in a single population 单一总体中的均衡

定义都与之前一样, 只不过加上了 vNM偏好.

<img src="/img/2020-04-18-Game.assets/image-20200508044620628.png" alt="image-20200508044620628" style="zoom:33%;" />

对路人接近问题, 除了纯策略的两个均衡, (Left, Left) and (Right, Right); 有个对称的混合策略均衡. 即 1/2选择左右. ?? 这个点是高点还是低点??

下例中, 没有纯策略对称均衡, 却有混合策略对称均衡.  还是1/2的几率.

<img src="/img/2020-04-18-Game.assets/image-20200508044816686.png" alt="image-20200508044816686" style="zoom:33%;" />



#### 4.8 例证：报案



#### 4.9 The formation of players’ beliefs 玩家信念的形成

在纳什均衡中，每个玩家在知道其他玩家的策略的情况下，选择一个能使其预期收益最大化的策略。到目前为止，我们还没有考虑过玩家是如何获得这些信息的。从非正式的角度来说，前面的分析的基本思想是，玩家们从他们的游戏经验中了解到了对方的策略。**epsilon greedy 采样 learn出来的**.  在理想化情况下，对于游戏中的每一个玩家，都对应一个群体, 其中大量的个体；在游戏的任何一局游戏中，每个群体中随机抽取一个参与者。在这种情况下，一个新的个体加入一个处于稳定状态的群体（即正在使用纳什均衡策略），他可以通过观察其他玩家在多次博弈中的行动来学习其他玩家的策略。只要玩家的更替率足够小，现有老玩家与新手（可能使用非均衡策略）的相遇就会足够少，以至于老玩家对稳态的信念不会受到干扰，因此，新玩家的问题只是学习其他玩家的行动。

下面的问题是, 如果博弈中的玩家都是缺乏经验的新手玩家, 那能达到纳什均衡么

##### 4.9.1 Eliminating dominated actions 剔除劣行动

排除法, 先去掉一些差动作, 减少搜索空间. 

第一个办法, 对某些博弈, 纯推理.

某些博弈中，可以期盼玩家通过对博弈的内在分析，合理选择他们的纳什均衡行动。在极端的情况下，每个玩家的最佳行动可能独立于其他玩家的行动，就像囚徒困境那样。在不太极端的情况下，一些玩家的最佳行动可能取决于其他玩家的行动，但其他玩家将选择的行动可能是明确的,  因为这些玩家都有严优于所有其他行动的行动.

<img src="/img/2020-04-18-Game.assets/image-20200508120053026.png" alt="image-20200508120053026" style="zoom:33%;" />

上例中, 玩家2的R 优于L, 所以玩家1可以推断自己应该选B, 也就是说, 新手玩家也可以导致这个唯一的纳什均衡.

延伸该思路, 

<img src="/img/2020-04-18-Game.assets/image-20200508141746314.png" alt="image-20200508141746314" style="zoom:33%;" />

上例中， 玩家1的T是严劣的， 所以玩家1可以推理出:玩家2能考虑到玩家1不会选T, 玩家2会选择R; 所以玩家1 会选择B.  即相信大家都是绝对理性的.



##### 4.9.2 Learning 学习 

重要!!

另一种方法是假设每个玩家在开始时对其他玩家的行为都有一个无法解释的 "先验 "信念，然后根据他收到的信息改变这些信念--"学习"。在这里，我简单地讨论了两个理论，即同一组参与者重复地玩一个游戏，每个参与者都会根据自己对其他人的行为的观察，改变自己对其他人的策略的信念。

**Best response dynamics 动态最优反应** :  其实就**多次游戏迭代,会收敛到纳什均衡**;  一个特别简单的理论假设，在第一个时期之后的每个时期，每个玩家都相信其他玩家会选择他们在**前一个时期**选择的行动。在第一个时期，每个玩家对其他玩家的行动选择一个任意的决定性信念，选择一个最佳反应。在随后的每一个时期，每个玩家都会选择一个最佳反应来回应上一时期其他玩家的行动。这个过程被称为最佳反应动态。一个从一个时期到另一个时期保持不变的行动组合就是一个**纯策略纳什均衡**。此外，在纯纳什均衡中，每个玩家的行动是他对其他玩家的行动的唯一最佳反应，这就是一个纯纳什均衡的行动组合，从一个时期到另一个时期保持不变。

在一些博弈中，不管玩家的初始信念如何，最优反应动态产生的行动组合序列收敛于一个纯策略纳什均衡。  
另外有一些博弈，存在一些初始信念，之后产生的行动组合序列**并不收敛**。例如，在BoS（例16.2）中，如果玩家1最初相信玩家2会选择斯特拉文斯基，而玩家2最初相信玩家1会选择巴赫，那么玩家的选择将在（巴赫、斯特拉文斯基、巴赫）和（斯特拉文斯基、巴赫）这两个动作对之间无限期地交替进行。这个例子突出了玩家在模式中的推理能力的有限性。即没有考虑到对方的行动总是对自己之前的行动作出最好的反应的这种可能性。

还有个前提: 每个玩家都相信其他每个玩家都在使用纯策略. 

**Fictitious play 假想博弈** : **统计概率,作为其混合策略**. 假设玩家在形成对对手策略的信念时，会考虑**之前所有时期的行动**。他们把这些行动看作是混合策略的实现。考虑一个双人博弈。每个玩家开始时都对对方的行动有一个任意的概率信念。在游戏的第一局中，他选择了一个对这个信念的最佳反应，并观察对方的行动，比如说行动A。然后，他将自己的信念改变为将概率1分配给A；在第二个时期，他选择一个对这个信念的最佳反应，并观察对方的行动，比如说B。 然后，他把自己的信念改成给A和B都分配了1/2概率，并选择了一个最佳的应对措施。 他每个时期都会继续改变自己的信念；在任何时期，他都认为对手使用的是混合策略，在这种策略中，每个动作的概率与频率成正比。

在匹配硬币, 这个过程运作如下。假设玩家1 从"玩家 2 的行动将是反面"的信念出发，玩家2 从"玩家1的行动将是正面"的信念开始。然后，两个玩家在周期 1 都选择了"反面"。于是, 两个玩家在周期2中都相信对方选了反面, 因此玩家1选择反面, 玩家2选择正面; 到周期3, 玩家1认为:玩家2选正反的几率是1/2, 玩家2认为: 玩家1肯定选反面; 于是,正反面都是玩家1关于其信念的最优反应, 玩家2 唯一的最优反应是正面; 然后一直继续下去...

像 "匹配便士 "这样的双人博弈，玩家的利益是直接对立的，在任何双人游戏中，每个玩家都有两个行动，这个过程从任何初始信念开始都**收敛到混合策略纳什均衡**。也就是说，在足够多的时间段后，每个玩家选择行动的频率接近于混合策略在纳什均衡中的频率。对于其他博弈来说，有一些初始信念，其过程并不收敛。(即使最简单的例子太复杂了，无法简单介绍)。



#### 4.10 Extension: Finding all mixed strategy Nash equilibria   延伸: 求混合策略纳什均衡

对于有两个行动的两人博弈，我们可以 通过构**建最优反应函数**，求得所有的混合策略纳什均衡。在更复杂的博弈中，这个方法一般不实用。

下面求博弈中全部混合策略纳什均衡的方法由命题 113.2 中的均衡特征推导出来。

- 对每个玩家$i$, 从其行动集 $A_i$ 中选择一个子集$S_i$
- 核实是否存在一个混合策略组合$\alpha$ ，使得
  - 每个策略 $\alpha_i$ 分配正概率的行动集是 $S_i$ 
  - $\alpha$ 满足命题113.2 中的条件。
- 对玩家行动集中的每一个子集组合，重复地分析。 



这个方法工作量蛮大的..

例子, 下图, 每个玩家的动作集有三个非空子集(1,2,(1,2)); 因此存在9个 玩家1玩家2的行动对.  对每一对($S_1,S_2$) , 核实是否存在一堆混合策略($\alpha_1, \alpha_2$) , 使得每个$\alpha_i$ 仅对$S_i$的行动分配正概率, 并且满足113.2.

<img src="/img/2020-04-18-Game.assets/image-20200508181252013.png" alt="image-20200508181252013" style="zoom:33%;" />

- 考虑四对子集，其中每个玩家的子集由一个动作组成，就等于检查是否是纯策略均衡。(对每个玩家来说，自动满足命题113.2中的第一个条件，因为每个子集中只有一个动作)。
- 考虑玩家1的子集 $\{T, B\}$和玩家2的子集 $\{L\}$ : 对于玩家1来说，第113.2条中的第二个条件是自动满足的，因为玩家1没有任何行动的概率为0，而对于玩家2来说，第一个条件是自动满足的，因为他只给一个行动分配了正概率。因此，如果要有一个混合策略均衡，其中玩家1使用T的概率是p , 我们需要$u_{11}=u_{21}$ , 因为玩家1的两个动作的期望回报必须一样. 并且, $p v_{11}+(1-p) v_{21} \geq p v_{12}+(1-p) v_{22}$, 即考虑到玩家1的混合策略，L至少要和R一样好。 如果$u_{11} \neq u_{21}$ , 或者 不存在满足不等式的p, 那么就不存在这种类型的均衡. 其他三组子集也同理.
- 考虑$\{T, B\}$ 和 $\{L, R\}$ . 我们需要找到一对混合策略，并满足命题113.2中的第一个条件（第二个条件是自动满足的，因为两个玩家都给他们的行为赋予正概率）。也就是说，我们需要找到概率p和q(如果有的话), 使得  $q u_{11}+(1-q) u_{12}=q u_{21}+(1-q) u_{22} \quad$ and $\quad p v_{11}+(1-p) v_{21}=p v_{12}+(1-p) v_{22}$

例如，在 BoS 中，检查其中每个子集由单一行动组成的子集对时，发现了两个纯策略均衡; 检查其中一个子集只含有单一行动而另 个子集由两个行动组成的子集对时，发现没有均衡;  剩下的情况, 求得混合策略均衡。



#### 4.11 延伸：每个玩家的行动具有连续统势时的博弈

#### 4.12 附录：以期望盈利体现优先选择



### 5 Extensive games with perfect information: Theory 完全信息展开型博弈：理论

策略型博弈没有决策的序列结构。当把这个模型应用到决策者 会有序行动的情况时，我们假定每一个决策者"一劳永逸"地选择了他的行动计划, 随着事件的展开，他不能修改计划。相反，展开型博弈模型清晰地描述了决策的序列结构，随着事件的展开，每个决策者可以自由地改变自己的决策。



#### 5.2 Extensive games with perfect information 完全信息展开型博弈

##### 5.2.1 Definition

之前只需 玩家集与偏好;  现在需要说明 玩家的动作次序,  和在每个时刻每个玩家可能采取的行动。为了做到这一点，需要详细说明所有可能发生的行动序列的集合，以及在每个序列中每个时刻采取该动作的玩家.  我们称每个可能的动作序列sequence of actions为**终点历史terminal history**.  在 terminal history的每个时刻指出是哪个玩家的函数叫 **player function**.    terminal history 就是包含结束的从头到尾的历史.

一般地说，假设（C，D）和（C，E）是终点历史，玩家函数将玩家1分配给游戏开始时，玩家2分配给历史C时刻之后，那么玩家1在游戏开始时选择了C后，玩家2可以使用的两个动作是D和E。一个游戏的终点历史记录被指定为一组序列。但不是每一个序列集都是合法的终点历史集。例如，如果(C，D)是终点历史，那么指定C为终点历史是不对的：事实上，(C，D)是终点历史意味着，在游戏开始时选择了C之后，有的玩家可能会选择D，这样，C的动作就不会结束游戏。更一般地说，作为终点历史的**真子历史 proper subhistory**的序列本身不能成为终点历史。这个限制是我们唯一需要对一个序列集施加的限制，以便这个序列集可以被解释为终点历史的集合。

为了精确地陈述这个限制，定义行动的一个有限序列$\left(a^{1}, a^{2}, \ldots, a^{k}\right)$ 的"**子历史 subhistories**"是 空, $\varnothing$ (表示博弈的开局) , 和 所有形式为 $\left(a^{1}, a^{2}, \ldots, a^{m}\right)$ $1 \leq m \leq k$ ; 同理也可以定义无限序列的. 

不等于整个序列的子历史 称为**真 子历史 proper subhistory** ; 一个行动序列，它是某个终点历史的子历史，简单地称作 "**历史 history**"。 

**子历史都是包含开头的 ; 真子历史,  含头不含尾** , 



DEFINITION 153.1 (**Extensive game with perfect information**) An extensive game with perfect information consists of   **完全信息的展开型博弈** 的要素

- a set of **players**
- a set of sequences (**terminal histories**) with the property that no sequence is a proper subhistory of any other sequence  终点历史集合;  因为是终点历史, 所以肯定不是其他的真子历史
- a function (**player function**) that assigns a player to every sequence that is a proper subhistory of some terminal history ;  即P(真子历史) = 该时刻玩家;  
- for each player, **preferences** over the set of terminal histories.  关于终点历史集合的偏好

就策略型博弈来说，我们可以通过给出一个描述偏好的收益函数来确定玩家的偏好;  某些情况下，结果与每个终点历史相连，玩家的偏好自然地定义在这些结果上，而不是直接地定义在终点历史上。



EXAMPLE 153.2 (Entry game 进入博弈)  建模

- **Players** The challenger and the incumbent. 挑战者和在位者。
- **Terminal histories** $(\text {In, Acquiesce}),(\text {In, Fight}),$ and Out.  
- **Player function** $P(\varnothing)=$ Challenger and $P(\operatorname{In})=$ Incumbent.
- **Preferences**   挑战者的偏好: $u_{1}$ ,  $u_{1}(\text { In, Acquiesce})=2, u_{1}(\text { Out })=1,$ $u_{1}(\operatorname{In}, \text { Fight})=0$  
  在位者的偏好 $u_{2}$ ,   $u_{2}(\text { Out })=2, u_{2}(\text { In, Acquiesce})=1,$ $u_{2}(\operatorname{In}, \text { Fight})=0$

这个博弈可以用一个图表示:  最上层的小圆圈,表示开始时历史是空. 下面的节点都是黑点.

<img src="/img/2020-04-18-Game.assets/image-20200506165524265.png" alt="image-20200506165524265" style="zoom:33%;" />

可以由终点历史集以及玩家函数推断出 玩家在某个时刻的可选动作集. 

$$
A(h) = \{a: (h, a) \text{ is a history } \}
$$

如上例, 历史有 $\varnothing, \operatorname{In},$ Out, $(\text { In, Acquiesce})$ and $(I n, \text { Fight})$ ;   
可选动作集:   $A(\varnothing)=\{I n, O u t\},$ $A(I n)=\{\text {Acquiesce}, \text { Fight}\}$



##### 5.2.2 Solutions

之前的进入博弈，"挑战者将进入和随后在位者将默许"似乎是很清楚的。挑战者可以这样推理, 如果自己进入，那么在位者将会默许，因为这样做的话对于在位者来说比斗争要好些。考虑到在位者将会以这种方式应对进入，挑战者进入会使自己处境更好。

论证的思路称为**反向归纳法 (backward induction)**。每当玩家必须行动时，对于他的每一个可能的行动，他推断玩家(包括他自己)随后会理性采取的行动，并且选择一个行动以产生他最喜欢的终点历史。虽然反向归纳法可以适用于上例中的博弈，但是它不能适用于每一个 完全信息展开型博弈. 

<img src="/img/2020-04-18-Game.assets/image-20200506175326829.png" alt="image-20200506175326829" style="zoom:33%;" />

对这个变体, 如果挑战者进入，在位者不在乎默许还是斗争。反向归纳法没有告诉挑战者，在这种情况下在位者将采取什么行动，于是留下来一个未解的问题:挑战者应选择什么行动. 具有无限长历史的博弈提出了关于反向归纳法的另一个难题:没有一个终点可作为归纳的出发点。完全信息展开型博弈的一个推广-- 允许玩家同时行动还提出了另一个问题:当玩家同时行动时，我们一般不能直接推断每个玩家的最优行动。 现在是回合制.

另一种定义均衡的方法是从纳什均衡的概念出发。试图对可以在稳定状态下持续的行为模式进行建模。由此得出的均衡概念适用于所有具有完全信息的扩展博弈。首先讨论的是稳态方法。稳定状态方法的结果和反向归纳法一样. 



#### 5.3 Strategies and outcomes  策略和结果

##### 5.3.1 Strategies 策略

展开型博弈的**关键概念是策略**。玩家的策略表明了对于每一个历史(在这个历史之后轮到他行动)玩家所选择的行动。

DEFINITION 157.1 (**Strategy**) A strategy of player i in an **extensive game with perfect information** is a function that assigns to each history h after which it is player i’s turn to move (i.e. P(h) = i, where P is the player function) an action in A(h) (the set of actions available after h).

下图是个例子. 表格是玩家2的所有可能策略. 

<img src="/img/2020-04-18-Game.assets/image-20200506185714297.png" alt="image-20200506185714297" style="zoom: 33%;" />



在一些博弈中，某些玩家的策略不仅仅是行动计划。

定义157.1要求任何玩家i的策略在每一个历史之后都指定了一个动作，即使对于 执行该策略过程中没有发生的历史也一样。

<img src="/img/2020-04-18-Game.assets/image-20200507002112934.png" alt="image-20200507002112934" style="zoom: 33%;" />



##### 5.3.2 Outcomes  结果

strategy profile 决定了 terminal history (不考虑随机).  记策略组合strategy profile为 $s$ ,  player function为 $P$.  起始玩家 $P(\varnothing)$ , 其 strategy 记为 $s_{P}(\varnothing),$ 选择 action $s_{P(\varnothing)}(\varnothing)$ , 记为 $a^{1}$. 如果历史history $a^{1}$ 不是 terminal, 后继玩家 $P\left(a^{1}\right)$ 行动, 策略为 $s_{P\left(a^{1}\right)}$,  action $s_{P\left(a^{1}\right)}\left(a^{1}\right)$, 记为 $a^{2}$.  若 $\left(a^{1}, a^{2}\right)$ 不是终点, 则继续..直到terminal. 我们将 terminal history 称为 $s$ 的**outcome 结果**, 记为 $O(s)$ 

例如158.1, outcome of the strategy pair $(D G, E)$ is the terminal history $D,$ and the outcome of $(C H, E)$ is the terminal history $(C, E, H)$

注意, 策略组合 $s$ 的结果$O(s)$ 仅仅依赖于玩家的行动计划, 而不是他们的全部策略. 即不需要知道那些不包含在当前历史中的策略相关部分。为了确定$O(s)$，我们不需要参考任何玩家的策略中指定他在被该策略排除的历史之后的行动的任何组成部分。 



#### 5.4 纳什均衡

对于策略博弈，纳什均衡是对玩家在**稳定状态steady state**下的行为建模。也就是说，我们寻找的行为模式是，如果每个玩家都知道其他玩家的行为，那么他没有理由改变自己的行为。对展开型博弈, 首先定义了一个纳什均衡：考虑到其他玩家的策略，没有任何一个玩家希望偏离这个策略组合。这个定义是对战略博弈中的纳什均衡的改编（21.1）。

DEFINITION 159.2  (**Nash equilibrium of extensive game with perfect information**) The strategy profile $$s^∗$$ in an extensive game with perfect information is a **Nash equilibrium** if, for every player $$i$$ and every strategy $$r_{i}$$ of player $$i$$, the terminal history $$O\left(s^{*}\right)$$ generated by $$s^{*}$$ is at least as good according to player $$i^{\prime}$$ s preferences as the terminal history $$O\left(r_{i}, s_{-i}^{*}\right)$$ generated by the strategy profile $$\left(r_{i}, s_{-i}^{*}\right)$$ in which player $$i$$ chooses $$r_{i}$$ while every other player $$j$$ chooses $$s_{j}^{*} .$$ Equivalently, for each player $$i$$
$$u_{i}\left(O\left(s^{*}\right)\right) \geq u_{i}\left(O\left(r_{i}, s_{-i}^{*}\right)\right)$$ for every strategy $$r_{i}$$ of player $$i$$ ; where $$u_{i}$$ is a payoff function that represents player $$i$$ 's preferences and $$O$$ is the outcome function of the game. 

**完全信息展开型博弈的纳什均衡** : 

若 $$u_{i}\left(O\left(s^{*}\right)\right) \geq u_{i}\left(O\left(r_{i}, s_{-i}^{*}\right)\right)$$  	对每个玩家$i$的每个策略$r_i$都成立 , 则策略组合 $$s^∗$$ 是一个纳什均衡. 



例 160.1 (Nash equilibria of the entry game) **进入博弈的纳什均衡**.  有两个纳什均衡, (In, Acquiesce) and (Out, Fight).   
第一个可以由backward induction求得.    
第二个均衡，挑战者总是选择"在外"。给定在位者进入后选择斗争的策略，"在外"是最优的策略。 给定挑战者选择"在外"策略，在位者选择"斗争"策略是最优的; 在位者选择"默许" 或"斗争"对于他的收益是无差异的。于是，没有一个玩家可以在给定其他玩家策略的情况下，通过选择不同的策略而增加自己的收益。 所以第二个均衡点成立.  其实这个点改成1,3更好理解.

<img src="/img/2020-04-18-Game.assets/image-20200507014031558.png" alt="image-20200507014031558" style="zoom: 33%;" />

纳什均衡(Out, Fight) 在策略型形式中不会出现。挑战者如何知道如果他进入的话，在位者将选择"斗争"呢?  这样解释策略型博弈是 :每当挑战者参与博弈时，即使他选择"在外"也会观察在位者的行动。   
相对的，这样解释展开型: 总是选择"Out"的挑战者绝不会观察到在位者的行动，因为在位者不会行动。  
在策略型博弈中"在给定其他玩家策略时，每个玩家的策略是最优的"。这个纳什均衡条件的基本原理是，在稳定状态中，每个玩家参与博弈的**经验**导致他关于其他玩家行动的**信念**是正确的.这个道理不适用于(展开型)进入博弈的纳什均衡点 (Out, Fight) ，因为总是选择"在外"的挑战者绝不会观察到在历史"进入"之后的在位者的行动。所以就**学习不到这个经验**.

通过考虑一个带有稍稍扰动的稳定状态，我们就可以避免解释展开型博弈纳什均衡中的这个困难，在极少数情况下，会采取非均衡的行动(也许犯错误，或者是蓄意的实验) ，而这些扰动使得每个玩家最终可以观察到每一个历史后的其他玩家的行动。鉴于这样的扰动，每个玩家最终都会学习到其他玩家的整个策略。 **相当于探索,并学习.** 

但是，如果将纳什均衡 (Out, Fight)解释为这种带扰动的稳定状态，又会遇到另一个问题。在那些(极端)场合，当挑战者进入时，在位者随后的"斗争"行为, 则博弈的余下部分并不是稳定状态: 如果挑战者进入，在位者默许比起斗争来会使自己的境况更好一些。也就是说，纳什均衡 (Out, Fight)并不对应于展开型博弈**稳健 (robust)的稳定状态**。

注意，展开型博弈体现了这样的假设,  在博弈开始时，在位者不事先表态"如果进入的话就斗争", 则他想选什么就选什么应对。如果在位者事先宣称"如果进入则斗争", 那么分析就会不同。这样的"宣言"将导致挑战者停留在外，这是一个在位者所希望的结果。没有在位者做出"许诺"的可能性，我们可以想象在位者在博弈开始时就宣告其打算斗争;但是这样的威胁是不可信的，因为在挑战者进入之后，在任者仅有的动机是默许。  这个倒是现实中挺常见的情况.



#### 5.5 Subgame perfect equilibrium 子博弈完美均衡

非常重要!!!!   这里有bellman公式的思想了.  也是因果律, 不管之前发生了什么, 我只要从现在开始利益最大化.

##### 5.5.1 Definition

纳什均衡概念忽视了展开型博弈的有序结构，其策略为在博弈开始之前一劳永逸地做出选择。结果是，前一节所提到的，纳什均衡对应的稳定状态可能不稳健。

现在，定义模拟稳键的稳定状态的均衡概念 equilibrium that models a robust steady state。这个概念要求在给定其他人的策略情况下，每个人的策略不仅在博弈开始时，而且在每一个历史时刻都是最优的。

先定义**子游戏 subgame** :  对于任意非终点历史$h$，跟随在$h$后的子博弈(subgame)是发生$h$之后留存下来的博弈部分。 即某时刻之后剩下的全部.

DEFINITION 162.1(**Subgame**)​  Let $\Gamma$ be an extensive game with perfect information, with player function $P .$ For any nonterminal history $h$ of $\Gamma,$ the **subgame** $\Gamma(h)$ following the history $h$ is the following extensive game.

- **Players**  The players in $\Gamma$ 
- **Terminal histories**  The set of all sequences $h^{\prime}$ of actions such that $\left(h, h^{\prime}\right)$ is a terminal history of $\Gamma$

- **Player function** The player $P\left(h, h^{\prime}\right)$ is assigned to each proper subhistory $h^{\prime}$ of a terminal history.

- **Preferences**  Each player prefers $h^{\prime}$ to $h^{\prime \prime}$ if and only if she prefers $\left(h, h^{\prime}\right)$ to $\left(h, h^{\prime \prime}\right)$ in $\Gamma$

注意, 空历史 $\varnothing$ 的后面的子博弈是整个博弈自身. 其他的每个子博弈都称为真子博弈. 由于对每一个非终点历史都存在一个子博弈，所以子博弈个数等于非终点历史的个数。

下面每个人不光应对整个博弈, 而是要先应对各个子博弈. 

**子博弈完美均衡**,   策略组合$$s^*$$, **在任何的子博弈中, 都是纳什均衡**.	A **subgame perfect equilibrium** is a strategy profile  $$s^*$$  with the property that in no subgame can any player $i$ do better by choosing a strategy different from $$s^*_i$$ , given that every other player j adheres to  $$s^*_j$$.

Nash equilibrium (Out, Fight) of the entry game (Example 152.1) 就不是一个 完美均衡.  因为在历史"进入"之后的子博弈中，策略"斗争"对在位者并不是最优的, 在这个子博弈中，在位者选择"默许"比选择"斗争"会使自己的处境 更好一些。 (In, Acquiesce) 则是一个完美子博弈均衡.

DEFINITION 164.1 (**Subgame perfect equilibrium 子博弈完美均衡**)  
$$
u_{i}\left(O_{h}\left(s^{*}\right)\right) \geq u_{i}\left(O_{h}\left(r_{i}, s_{-i}^{*}\right)\right) \text { for every strategy } r_{i} \text { of player } i
$$


##### 5.5.2 Subgame perfect equilibrium and Nash equilibrium 子博弈完美均衡和纳什均衡

在子博弈完美均衡中，每个人的策略是最优的。特别地，其在空历史之后是最优的. 

**每个子博弈完美均衡是纳什均衡。**

**子博弈完美衡是在每个子博弈中导致纳什均衡的策略组合。**



##### 5.5.4 Interpretation 解释

**子博弈完美均衡**对应于一个稍有扰动的稳定状态，其中， 所有人在很少的极端情况下采取非均衡行动，这样，经过长期的经验积累，每个人对于其他人的整个策略形成正确的信念，知道其他人在每个子博弈中将如何动作。给定了这些倍念，没有一个人会在博弈开始或任何历史之后希望偏离自己的策略。

子博弈完美均衡的这个解释，如同纳什均衡解释为稳定状态一样，不要求知道其他人的偏好，也不要求先考虑其他人的理性。它需要将策略解释为一个计划，这个计划是包含探索性的.  理解为 epsilon-greedy 即可.



#### 5.6 Finding subgame perfect equilibria of finite horizon games: backward induction 求有限范畴博弈的子博弈完美均衡：反向归纳法

可以通过求纳什均衡来求得一些问题的子博弈完美均衡，并检查这些均衡中的每一个是否为子博弈完美。 

定义"子博弈的长度"为子博弈中最长的历史长度。后退自纳法操作如下: 通过寻找长度为 1 的子博弈("最后的"子博弈) 中玩家的最佳行动开始。然后，把这些行动看作为给定的;  再找长度为 2 的子博弈中首先行动的玩家的最佳行动。继续直到博弈的起始阶段.   有点类似minimax

例子: 

<img src="/img/2020-04-18-Game.assets/image-20200507045804072.png" alt="image-20200507045804072" style="zoom:50%;" />

另外一个例子:

<img src="/img/2020-04-18-Game.assets/image-20200507050304696.png" alt="image-20200507050304696" style="zoom:50%;" />

(C, FHK), (C, FIK), (C, GHK), (D, GHK), (E, GHK), and (D, GIK).



### 6 完全信息展开型博弈：例







### 7 完全信息展开型博弈：延伸与讨论

#### 7.1 Allowing for simultaneous moves  同时行动

##### 7.1.1 Definition

完全信息的展开型博弈(定义 153.1)模型，假设在每一系列事件后，**单个决策者在已知每个决策者以前行动的情况下采取行动**。现在，我们描述一个更为复杂的模型，它允许我们去研究在某些事件系列后，一组决策者的成员"同时"选择他们的行动。每个成员知道每个决策者以前的行动，但是不知道该组中其他成员同时发生的行动。

例如这样的情况, 即玩家1选择C或D，然后玩家2和3同时采取行动，各自选择E或F。那么 (C, (E, E))是一个 terminal history. 在一般模型中，玩家函数为每个非终端历史分配了一组玩家。在刚才描述的例子中，这组玩家包括初始历史的玩家1，以及历史C的玩家2和3。



DEFINITION 202.1 **完全信息且同时行动的展开型博弈** An extensive game with perfect information and simultaneous moves consists of

- a set of **players** 一样
- a set of sequences (**terminal histories**) with the property that no sequence is a proper subhistory of any other sequence 一样
- a function (the **player function**) that assigns a **set of players** to every sequence that is a proper subhistory of some terminal history   映射到多个玩家
- for each **proper subhistory** h of each terminal history and each player i that is a member of the set of players assigned to h by the player function, a set $A_i(h)$ (the set of **actions available** to player i after the history h)    在t时刻能行动玩家的所有可用动作集
- for each player, **preferences** over the set of terminal histories  一样



例子, BoS变体.  首先，人1决定是留在家里看书还是参加音乐会。如果他读了一本书，游戏就结束了。如果他决定参加一场音乐会，那么，就像在BoS中一样，他和人2在不知道对方的选择的情况下，自主选择是去欣赏巴赫还是斯特拉文斯基的听觉享受。

<img src="/img/2020-04-18-Game.assets/image-20200507114542432.png" alt="image-20200507114542432" style="zoom: 33%;" />





##### 7.1.2 Strategies and Nash equilibrium

完全信息同时行动的展开型博弈的纳什均衡 定义与 没有同时行动的博弈中的定义(Definition 159.2)一样

EXAMPLE 204.1 (Nash equilibria of a variant of BoS) In the game in Example 203.1 

three pure Nash equilibria: ((Concert, B), B), ((Book, B), S), and ((Book, S), S).

记住，玩家的策略比行动计划多

<img src="/img/2020-04-18-Game.assets/image-20200507115050848.png" alt="image-20200507115050848" style="zoom: 33%;" />



##### 7.1.3 Subgame perfect equilibrium 子博弈均衡

为了求有限的具有完全信息和同时行动的展开型博弈的子博弈完美均衡集，我们可以像以前那样，使用后向归纳法。

EXAMPLE206.1(BoS 变体的纳什均衡) 考虑图204.1中的游戏。逆向归纳的过程如下。

- Concert 后, 有两个纯策略均衡 (S, S) and (B, B) 
- 如果Concert之后的子博弈的结果是 (S, S), 那玩家1在开始时的最优选择是 Book
- 如果Concert之后的子博弈的结果是 (B, B), 那玩家1在开始时的最优选择是 Concert

所以结论是, 有两个子博弈完美均衡subgame perfect equilibria: ((Book, S), S) and ((Concert, B), B).

We conclude that the game has two subgame perfect equilibria: ((Book, S), S) and ((Concert, B), B).







### 8 Coalitional Games and the Core  联合博弈及其核心

#### 8.1 Coalitional games 联合博弈

我们把每一组玩家称为**联盟coalition**，把所有玩家的联盟称为**大联盟grand coalition**。



DEFINITION 235.1 (**Coalitional game 联合博弈**) A coalitional game consists of

- a set of **players**
- for each **coalition**, a set of **actions**
- for each player, **preferences** over the set of all actions of all **coalitions** of which she is a member. 每个玩家, 在所有(其作为成员)的联盟里所有动作集上的偏好. 

常用 $N$ 表示大联盟, 以$S$表示任意一个联盟。可以通过一个描述偏好的收益函数，确定玩家的偏好。

在下面几个例子中，每个联盟控制着某种数量的物品，这些物品可以在其成员之间分配。在这样一个博弈中，联盟S的每一个行动都是S的成员之间对S所控制的物品的分配，我把它称为**S分配**的物品 **S-allocation**。我把N次分配简单地称为**分配 allocation**。

对于每一个人来说，大联盟可能达到的结果比较好(>=)。我的称这样的博弈 为"有凝聚力的cohesive"。



EXAMPLE 236.2 (**Two-player unanimity game 两人一致博弈**)  两个人一起生产一个单位(比如1公斤)的产品，他们以自己希望的任何方式分享。没有一个人可以独自生产任何产品。每个人仅关心自己获得的产品量，并且希望多多益善.

- **Players**  The two people (players 1 and 2).
- **Actions**  每个人单独行动, 但没有产出. 两个人的联合行动集 {1, 2} 是所有非负数集合($x_1, x_2$), 且$x_1 + x_2 = 1 $ 
- **Preferences**  每个人的偏好由其得到的产量来表示.

玩家集的可能划分是$$\{\{1, 2\}\}$$，由两个玩家的单一联合组成，以及$$\{\{1\},\{2\}\}$$，其中每个玩家单独行动。后者只有一种行动组合可供其使用，其产出为0。因此，这个游戏是有凝聚力的。

 

EXAMPLE 237.1 (**Landowner and workers 地主和工人**) 当使用是k个工人时，地主的庄园产量为 f(k+1)的食物，其中f是递增融数，且f(0)=0。工人的总数是m;  地主和每个劳动者只关心自己的产量多少，宁多勿少。

- **Players**  landowner and the m workers
- **Actions**  一个完全由工人组成的联盟只有一个行动，其中没有成员收到任何产量的产品。一个由地主和k个工人组成的联盟$S$的行动集合是关于产量$f(k+1)$ 的所有$S$分配的集合。
- **Preferences**  每个人的偏好由其得到的产量来表示.

这个游戏是有凝聚力的，因为大联盟的产出比其他任何一个联盟的产出都要多，而且，对于所有玩家的任何一个划分的集合，只有一个联盟有产出。



EXAMPLE237.2 (**Three-player majority game 三人多数博弈**)   三个人有 1 单位产品的分配权。组成的任何多数的联盟可以支配该产品的分配。每个人只关心他得到的量。

- **Players**   三个人
- **Actions**   由一个玩家组成的每个联盟都有一个动作，这个动作对玩家没有输出。每个由两个或三个玩家组成的联盟S的行动集就是分配一个单位产品的S分配集。
- **Preferences**  每个人的偏好由其获得量来表示.

这个游戏是有凝聚力的，因为每一个划分的玩家集最多包含一个多数联盟，而这样的联盟的每一个动作，都有一个大联盟的动作，每个玩家的产出至少是一样多的。



在这些例子中，每个联盟S的行动集就是S所能获得的产量的S分配集，每个玩家的偏好用他所获得的产量来表示。因此，我们用一个数字来概括每个联盟的行动集，这个数字等于该联盟所能获得的总产量，可以把这个数字解释为可能在联盟成员之间分配的总 "报酬"。这就是**可转移的收益transferable payoff**。



DEFINITION 236.1 ( **Cohesive coalitional game 有凝聚力的联合博弈**)   



#### 8.2 The core 核

DEFINITION 239.1 (**Core**) The core of a coalitional game is the set of actions $a_N$ of the grand coalition N such that no coalition has an action that all its members prefer to  $a_N$ .

最好的联盟行为集就是核. 





## Part II:  Games with Imperfect Information  不完全信息博弈

### 9 贝叶斯博弈

#### 9.1 Introduction

**信息不完全的策略型博弈 - 贝叶斯博弈**

纳什均衡有一条基本的假设，每个人对其他人的行动持有正确的信念。为此，玩家必须了解他正在参与的博弈;特别是要了解其他人的偏好。在许多情况下, 玩家并不完全了解对手的特征, 比如，讨价还价者可能不太清楚其他人对谈判物品的估价，企业可能不知道对方的成本函数等等。有时候，玩家可能很了解对手的特点，但可能不知道这些对手对自己的特点了解的程度。本章将介绍"贝叶斯博弈" , 它推广了策略型博弈，将帮助我们去分析如下的情况，每个玩家不完全了解与他的行为选择有关的环境。

#### 9.2 Motivational examples 启发性例子

EXAMPLE 271.1 (**Variant of BoS with imperfect information 不完全信息的 BoS 变体**) 

玩家1 不能肯定玩家 2 是否愿意一起外出，还是想躲开自己，而玩家 2 和以前例子一样，知道玩家 1 的偏好. 具体地讲，假设玩家 1认为玩家 2愿意与自己外出的可能性有1/2，躲开自己的可能性有1/2(这种判断可能是玩家 1 的经验).  即使我们只对纯策略均衡感兴趣，但由于涉及概率，分析这种情况需要知道玩家关于随机结局的偏好;表格中的数字代表玩家的贝努利收益。



![image-20200507163912064](/img/2020-04-18-Game.assets/image-20200507163912064.png)

我们可以认为存在两种**状态states** , 一个是上图左边对应的伯努利收益, 一个是右边. 玩家2知道自己的状态, 玩家1不知道, 只能每个状态给1/2的几率.

以 1 的角度，玩家 2 有两种可能的"**类型types**"，一种类型的偏好由上图的左表给出，另一种类型的在右边。 1 不知道 2 的类型，所以为了理性地选择自己的行动，必须对每种类型的行动形成一个信念。鉴于这些信念和他对每种类型的可能性的信念，他可以计算出他对每一个动作的预期回报。例如, 玩家1 觉得如果对方今天是讨厌自己的类型,会选B, 如果今天对方是喜欢自己的类型,会选S, 则自己选B的话, 对方1/2选S, 1/2选B, 所以预期收益为1/2 * 2+1/2 * 0 = 1. 自己选S, 预期收益为 1/2. 计算各种组合, 则得到下表.  其中每一列是两种类型的玩家2的行动组合, 其中第一项是想一起的, 第二项是想回避的.



<img src="/img/2020-04-18-Game.assets/image-20200507164759512.png" alt="image-20200507164759512" style="zoom:50%;" />

对于这种情况，我们定义纯策略纳什均衡为包含三个行动的行动组，其 中一个行动是人 1 的，还有两个行动分别是 2 的两个类型的，具有如下性质:

- 给定两个类型的玩家 2 的行动(以及玩家 1 关于状态的信念) , 玩家 1 的行动是最优的。
- 给定玩家 1 的行动，每一个类型的玩家 2 的行动是最优的。

也就是说，把玩家 2 的两个类型视作两个单独的玩家，并且将这种情况作为 3人策略型博弈进行分析。

我们断言，(B, (B, S))是一个纳什均衡



#### 9.3 General definitions  一般定义

##### 9.3.1 Bayesian games  贝叶斯博弈

DEFINITION 277.1  A Bayesian game consists of

- a set of **players** 
- a set of **states**

and for each player

- a set of **actions**
- a set of **signals** that she may receive and a **signal function** that associates a signal with each state
- for each signal that she may receive, a **belief** about the states consistent with the signal (a probability distribution over the set of states with which the signal is associated)
- a **Bernoulli payoff function** over pairs (a, ω), where a is an **action profile** and ω is a **state**, the expected value of which represents the player’s **preferences among lotteries** over the set of such pairs.



对 例 271.1 建模 

- **Players** The pair of people.
- **States** The set of states is $\{\text {meet, avoid}\}$
- **Actions** The set of actions of each player is $\{B, S\}$
- **Signals** Player 1 may receive a single signal, say $z$ ; her **signal function** $\tau_{1}$ satisfies $\tau_{1}(\text {meet})=\tau_{1}(\text {avoid})=z$ .两个状态的值一样,无法区分;  Player 2 receives one of two signals, say $m$ and $v$ ; her signal function $\tau_{2}$ satisfies $\tau_{2}(\text { meet})=m$ and $\tau_{2}(\text {avoid})=v$
- **Beliefs**  Player 1 assigns probability $\frac{1}{2}$ to each state after receiving the signal $z$ Player 2 assigns probability 1 to the state meet after receiving the signal $m$ and probability 1 to the state avoid after receiving the signal $v$
- **Payoffs**  The payoffs $u_{i}(a, \text { meet})$ of each player $i$ for all possible action pairs are given in the left panel of Figure 272.1 , and the payoffs $u_{i}(a, \text { avoid })$ are given in the right panel.



##### 9.3.2 Nash equilibrium

In a general game, denote the probability assigned by the belief of type $t_{i}$ of player $i$ to state $\omega$ by $\operatorname{Pr}\left(\omega \vert t_{i}\right) .$ 在某个状态的概率. Denote the action taken by each type $t_{j}$ of each player $j$ by $a\left(j, t_{j}\right) $.某状态下的动作.  Player $j$ 's signal in state $\omega$ is $\tau_{j}(\omega),$ so her action in state $\omega$ is $a\left(j, \tau_{j}(\omega)\right) .$ For each state $\omega,$ denote by $\hat{a}(\omega)$ the action profile in which each player $j$ chooses the action $a\left(j, \tau_{j}(\omega)\right) .$ Then the expected payoff of type $t_{i}$ of player $i$ when she chooses the action $a_{i}$ is  玩家i选择a的期望收益

$$
\sum_{\omega \in \Omega} \operatorname{Pr}\left(\omega | t_{i}\right) u_{i}\left(\left(a_{i}, \hat{a}_{-i}(\omega)\right), \omega\right)
$$

$\Omega$  set of states ,  $$\left(a_{i}, \hat{a}_{-i}(\omega)\right)$$ action profile,  every other player $j$ chooses $$\hat{a}_{j}(\omega) $$  


DEFINITION 280.1 A **Nash equilibrium of a Bayesian game** is a Nash equilibrium of the strategic game (with vNM preferences) defined as follows.

- **Players** The set of all pairs $\left(i, t_{i}\right)$ where $i$ is a player in the Bayesian game and $t_{i}$ is one of the signals that $i$ may receive. 
- **Actions** The set of actions of each player $\left(i, t_{i}\right)$ is the set of actions of player $i$ in the Bayesian game.
- **Preferences** The Bernoulli payoff function of each player $\left(i, t_{i}\right)$ is given by (279.1)   收益函数是上式. 

就是之前的加上了Bernoulli期望. 



#### 9.7 Illustration: auctions 拍卖



### 10 Extensive Games with Imperfect Information 不完全信息展开型博弈

本章只找到中文版



**dynamic Bayesian games** = **dynamic/extensive games of incomplete information**

当每个人选择行动时，可能不知道其他人以前的行动。



#### 10.1   Extensive games with imperfect information  不完全信息展开型博弈

为描述不完全信息展开型博弈， 相比完全信息博弈 , 必须添加一条:每一个玩家关于在他行动的每一时刻的历史信息的说明。以 $H_i$ 表示历史的集合，玩家 i 在这之后采取行动。通过将$H_i$划分(分隔)为若干**信息集 information set**的集成来确定玩家 i 的信息。这种集成称为玩家 i 的信息划分。玩家 i 在作出决策时，知道所发生的信息集，但不知道在该信息集中发生的是哪个历史。

**信息集之间可以区分, 信息集内部无法区分!!**



Definition: An **information set (信息集)** of a player is a collection of **decision nodes** (or **histories**) satisfying the following two conditions:

1. the player has the move at every node in the information set
2. when the play of the game reaches a node in the information set, the player with the move does not know which node in the information set has been reached, unless the information set is a singleton (单点, containing only one decision node).



例如，假设玩家 i 在历史 $C, D$ 和 $E$ , 即 $[H_i=\{C, D, E\}]$ 之后行动 。 

- 如果历史 C 发生过，那么他知道 C 已经发生，而如果D 或者 E 发生过，那么他只知道 D 或E 中有一个发生, 但不能明确知道是哪一个。于是玩家 $i$ 的**信息划分**由两个**信息集**组成: $\{C\}$ 和 $\{D, E\}$ 。
- 若他对哪个历史发生过全都不知道，那么他的信息划分由单一的信息集组成，即$\{C, D, E\}$.  
- 如果他正确地知道历史,那么他的信息划分就由三个信息集 $\{C\}$, $\{D\}$, $\{E\}$  组成

如前所述,将在历史 $h$ 之后行动的玩家的可使用行动集合记作 $A(h)$ 。只有当 $A(h)=A\left(h^{\prime}\right)$ 时 $,$ 我们认为两个历史 $h$ 和 $h^{\prime}$ 在同一个信息集中。为什么呢？在任何历史之后行动的玩家必须知道在该历史之后他可使用的行动集，因此如果 h 和 h'在同一个信息集中,并且 $A(h) \neq$ $A\left(h^{\prime}\right),$ 那么在这个信息集上采取行动的玩家可以通过观案他可使用的行动来推断在这两个历史中发生了哪一个历史。 如果包含 $h$ 和 $h^{\prime}$ 的信息集是 $I_{i}$ ,那么记 $A(h)$ 和 $A\left(h^{\prime}\right)$ 的共同部分为 $A\left(I_{i}\right)$ ; 也就是说，$A\left(I_{i}\right)$是玩家 i 在他的信息集 $I_{i}$ 上可供选择的行动集。 

许多不完全信息展开型博弈含有随机的行动， 考虑到随机行动的出现，结局outcome就是在terminal历史集合上的随机结果,因此每个玩家的偏好必定在这些随机结局上确定。 

定义 10.1(展开型博弈) （具有不完全信息和随机行动的）展开型博弈包含:

- **玩家**集合
- (终点**历史**的)序列集
- **玩家函数** : 它将玩家或“机会 chance"分配给某些终点历史的真子历史的每一个序列; 如果是chance, 则chance 随机选择动作. 
- 对于玩家函数分配给“机会chance”的每个历史,有一个**函数**对这个历史之后的可**选择行动**分配一个**概率分布**。它具有如下性质:每一个这样的概率分布独立于每一个其他的分布 。
- 对于每个玩家，由玩家函数分配给这个玩家有关历史集合的划分(玩家的信息划分)，使得对于在划分的任何给定成员中的每一个历史， 可使用的**行动集** $A(h)$是一样的
- 对于每个玩家，有终点历史的随机结局集合上的**偏好** 



先考虑最简单的imperfect展开型博弈可以建模为imperfect 策略型博弈的情况，其中每个玩家行动一次，并且没有一个玩家在行动时知道任何其他人的行动. 

例,  将BoS建模为imperfect 展开型博弈. 玩家相继选择各自的行动,但第二个行动者不知道第一个人的选择.

- 玩家:  1, 2
- terminal history:   (B，B)、(B，S)、(S，B) , (S，S)
- 玩家函数:  $P(\varnothing) = 1, P(S) = P(B) = 2$ 
- 机会行动:  无
- 信息划分:  玩家1的信息划分只包含 $\varnothing$ ;  玩家2的信息划分包含单一的信息集 $$\{B, S\}$$
- 偏好   

博弈如图所示，在每个终点历史下方的数字是伯努利收益，其期望值描述了玩家关于随机结局的偏好。连接 B S 的**虚线**表示这两个历史处于玩家2 的**同一个信息集中**。

<img src="/img/2020-04-18-Game.assets/image-20200509192550735.png" alt="image-20200509192550735" style="zoom: 50%;" />



重要例子, 理解chance  (一个纸牌游戏) : 两个玩家各bet 1 美元开始游戏。然后玩家1发到一张牌，这张牌有同等概率为"王牌"与"小牌", 玩家2 看不到这张牌。玩家1可以"摊牌"，或"追加bet"。如果他选择前者就就向玩家 2 展示他的牌。 如果大王, 玩家1赢钱, 如果小牌,玩家2赢钱, 玩家2过程中没有动作就结束.    如果玩家1追加赌注, 再押1美元, 玩家2可以放弃或者跟注. 如果放弃, 玩家1赢钱; 若跟进, 也再押1美元, 然后玩家1必须摊牌. 

如图, 玩家1有两个信息集,  王牌, 小牌;  玩家2 有两个信息集,  (王牌, 追加) , (小牌, 追加) ; 这个信息集 反映了玩家 2 不能看到手牌这一事实。注意，对玩家2, 在信息集内每一个历史的行动集是相同的。

<img src="/img/2020-04-18-Game.assets/image-20200509194128767.png" alt="image-20200509194128767" style="zoom:50%;" />

在这些例子中，其中一个玩家拥有包含不止一个历史的信息集。每个玩家的每个信息集包含单个历史的博弈等价于其有完全信息的展开理博弈。

例,  进入博弈的变种 , 挑战者有三种选择: 在外面，准备好了再进入，无准备地进入。准备是昂贵的，但减少了斗争的损失。 不管进入者准备与否，在位者宁愿默许而不想斗争。在位者观察到挑战者是否进入，但现察不到进入者准备与否。 建模如下图.  挑战者的信息集由空集组成，在位者的信患集由"准备" 和"无准备"这两个历史组成. 这里少了Out后的结果

<img src="/img/2020-04-18-Game.assets/image-20200509234603670.png" alt="image-20200509234603670" style="zoom:50%;" />



#### 10.2	Strategies  策略

策略确定了每当轮到玩家行动时所来取的行动. 

定义 10.6 (展开型博弈的策略) 在展开型博弈中，玩家 i 的一个(纯)策略是这样的一个函数，它对玩家 i 的每一个信息集 $I_i$ 分配一个$A(I_i)$   (玩家 i 在信息集 $I_i$ 中可选择的行动集〉中的行动。

上面例子中,  BoS中, 每个玩家有两个策略, B和S ;   纸牌, 玩家1 有两个信息集 大牌,小牌, 每个信息集上有两个行动, 加注,摊牌 , 因此有4个策略 ((大)加注, (小)加注), ((大)加注, (小)摊牌), ((大)摊牌, (小)加注),((大)摊牌,(小)摊牌); 玩家2有2个策略: 跟进, 放弃



如果允许混合策略. 

定义 10.8 (展开型博弈的混合策略) 在展开型博弈中，玩家的混合策略是在纯策略上的一个概率分布。

所以, 混合策略包含了概率为1的纯策略.



#### 10.3	Nash equilibrium   纳什均衡

定义 10.9 (**展开型博弈的纳什均衡**) 展开型博弈的混合策略组合$$\alpha^*$$ 如果满足下述条件，则称为**(混合策略)纳什均衡**: 对于每一个玩家 $i$ 和 玩家$i$的每一个混合策略$\alpha_i$,  玩家i关于$$\alpha^*$$的期望收益至少与$$(\alpha_i, \alpha_{-i}^*)$$的期望收益一样大。

求展开型博弈纳什均衡的一个方法是构造博弈的策略型形式，并且将它作为一个策略型博弈来分析.

例题 10.10(BoS 作为展开型博弈)   博弈有两个纯纳什均衡(B,B)和(S,S),  以及一个混合均衡，玩家1 以 $\frac{2}{3}$ 采用 $B$, 玩家 2 以 $\frac{1}{3}$ 采用 $B$  .  这个例子, 玩家 2 在采取行动时,不知道玩家 1 所选择的行动。 玩家 2 信息的空缺体现在他的信息集中,它包含了历史 B 和历史 S 这两个部分.  但是, 即使玩家 2 不知道玩家 1 的行动，他的**博弈经验**也会告诉他**预期的历史**(或关于历史的概率分布)。关键在于，玩家的信息划分反映了他在博弈时对另一个玩家行动的观察所得出的信息; 他的博弈经验使他产生有关其他玩家的稳定状态行动的更多信患。

例题 10.11(纸牌游戏)   10.3的例子, 策略形式如下图. 0和博弈.

<img src="/img/2020-04-18-Game.assets/image-20200510044458414.png" alt="image-20200510044458414" style="zoom:50%;" />

该例没有纯策略的均衡, 因为各个点都会跑向其他地方.  玩家1的策略(摊牌，摊牌) **严劣**于 1/2(加注,加注), 1/2(加注,摊牌) 这一混合策略. 因此, 在任何纳什均衡中, 玩家1不会选择该纯策略.   玩家1的策略(摊牌,加注) 对于玩家 2 分配正概率给“跟进”的任何混合策略不是一个最优反应,  所以, 考虑到没有纯策略的均衡，在所有的纳什均衡中，玩家1一定在(加注，加注)和(加注，摊牌)之间随机选择。令p为玩家1选择(加,加)的概率, q为玩家2 选放弃的概率. 因为达到均衡以后,  玩家1的每个动作的预期收益都是一样; 玩家2也同样. 所以有 $q=\frac{1}{2}(1-q)$ 和 $-p=-\frac{1}{2}(1-p)$  ,   求得 $p=q=\frac{1}{3}$ .



例 10.14 (承诺与可观察性) 两个人各有两个动作，X 和 Y。他们关于四个行动对的收益如下:

<img src="/img/2020-04-18-Game.assets/image-20200510060534355.png" alt="image-20200510060534355" style="zoom: 67%;" />

首先, 假设他们同时选择行动。模拟该情况的策略型博弈有唯一的均衡,   Y, Y。(注意,对于玩家 1 来说, X 严劣于 Y) 

现在, 假设玩家先后选择行动，玩家 1 最先选择, 玩家 2 在 选择自己的行动之前观察到玩家 1 的行动。将这种情况建模而成的完全信息展开型博弈有单一的子博弈完美均衡，X, X。在这个均衡中,玩家 1 的收益好于他在同时行动博弈的均衡中的。

最后，假设玩家 1 最先行动，不过他的行动没有被玩家 2 完全观察到。如果玩家 1 选择了 X，玩家 2 可能认为他选择的是 Y,或者情况正 好相反。我们可以将这种情况建模为不完全信息展开型博卒,其中玩家 1 的行动后面跟随一个**随机行动**，它选择可被玩家 2 观察到的**信号**。玩家 2 观察到的是信号而不是玩家 1 的行动。假定信号为正确的概率关于两个行动是一样的，且小于 1。将此概率记作 1 - $\varepsilon$ 。(于是,如果玩家 1 选择 $X$, 那么信号为 $X$ 的概率是 $1-\varepsilon$,信号为 $Y$ 的概率是 $\varepsilon$ ; 对Y也一样 ) 。假设 $0 \leqslant \varepsilon<\frac{1}{4}$  

这个展开型博弈和它的策略型形式，以及它的纳什均衡都显示在图10.6中。玩家2的策略,$IJ$,表示玩家2看到了信号X之后,选择$I$, 看到信号Y之后,选择$J$;      因为玩家2没法看到玩家1的情况, 其extensive策略只能以这种方式表现.

特别地，我们看到,对所有满足 0 $\leqslant \varepsilon<\frac{1}{4}$ 的 $\varepsilon,$  有一个纯策略纳什均衡 ( $Y, Y Y)$ 

> 即,玩家2如果看不到玩家1的行动, 那么跟一起行动其实差不多.

![image-20200510142529882](/img/2020-04-18-Game.assets/image-20200510142529882.png)



概括地说，玩家 1 先行动以及他的行动完全可被观察的博弈有唯一的子博弈完美均衡，X, X.   玩家1的行动可观察, 但存在误差的博弈有一个纯策略纳什均衡，其结局是不管误差有多小,两个人都选Y.

因此，如在完全信息博弈的子博弈完美均衡中所显示的作为，先动者通过承诺获益的优势，在第二行动的玩家对先动者行动的观察即使有一点点不完全，情况的博弈中的纯策略纳什均衡里完全丧失殆尽???。为什么呢?  
假定玩家1 和 2 都选择Y，并且考虑玩家1 转向 X 的含义。在完全信息博弈中，玩家 2"观察到 X"与均衡是不相容的: 他会将这种情况解释为发生了偏差。对此，他通过选择 X 做出最优反应，使得玩家 1 的这个"偏差" 是值得的。在不完全信息博弈中，玩家 2"观察到X"与均衡是相容的: 他将这种情况解释为一个错误的信号(无论这样的信号多么不可能) ，并继续选择 Y，使得玩家 1 的偏离不利于玩家 1 自己. 

我们看到，在所有的完全信息展开博弈中，纳什均衡概念是不够的，我们提出了子博弈完美均衡的概念去处理问题。我们怎样把子博弈完美均衡的思想延伸到更广泛的 具有(可能)不完全信息的展开型博弈中去呢?



例题10.15(进入博弈) 

<img src="/img/2020-04-18-Game.assets/image-20200510205907796.png" alt="image-20200510205907796" style="zoom:50%;" />

博弈有两个纯策略纳什均衡， (无准备，默许) 和(在外，斗争) ,还一个混合策略纳什均衡，其中，挑战者采用纯策略 在外，而在位者给 默许 的概率至多为1/2 . 

如在第五章中研究的具有完全信息的进入博弈的版本中，纳什均衡(在外，斗争〉似乎是不合理的。倘若事实上挑战者进入，在位者的最优反应是"默许"。在具有完 全信息的博弈中，我们通过定义子博弈完美均衡概念剔除了这种均衡，因为 子博弈完美均衡要求，对于轮到玩家行动的每个历史，在给定其他玩家 的策略时，玩家的策略是最佳的，而不管当  玩家坚持他们的策略时这个 历史是否发生。 

这个思想关于不完全信息博弈的自然推广，要求每个玩家在其每个信息集上的策略是最优的。

在其他博弈中，这个思想的贯彻不是直接的，因为在信息集上行动的最优性可能取决于已经发生的历史。

下面一个变体，其中在位 喜欢斗争甚于 默许一个无准备的进入者. 

<img src="/img/2020-04-18-Game.assets/image-20200510224622459.png" alt="image-20200510224622459" style="zoom:50%;" />





#### 10.4	Beliefs and sequential equilibrium    信念和连续均衡

策略型博弈的纳什均衡可以用两个条件来刻画:  每个玩家在给定他 关于其他玩家的倍念时选择的最优行动，和每个玩家的信念都是正确的。现在对展开型博弈定义的均衡概念体现了问样的两个要求，并且像完全信息展开型搏弈的子搏弈完美均衡概念一样，强调在玩家必须选择行动的每一点，它们都成立。在精确定义策略型博弈的纳什均衡时，我们不必将玩家的信念与他们的策略分开来考虑，因为"**信念是正确的**"这个要求完全确定了它们:**每个玩家关于其他玩家策略的信念简单地等于那个策略**。对于展开型博弈，正如我们在图 10. 8 中的博弈中已经看到的那样，玩家策略不能完全确定他们的信念。因此，导致我们对策略组合和信念集合组成的"组合"来定义均衡概念。

##### 10.4.1 信念

两种叫法.

A **belief system (认知系统)** in an extensive game is a function that assigns to each information set of each player a probability distribution over the histories (or decision nodes) in that information set.

定义 10.16 展开型博弈中的**信念体系 belief system**是一个函数，它给每个信息集分配一个在那个信息集上的历史的模率分布。

就是, 玩家无法区分的一个信息集, 那么, 自己认为的, 这个信息集里面每个历史的概率.

例如，考虑例题 10.5 中的进入博弈。有两个信患集:一个包含 空历史，另一个包含"准备"和"无准备"这两个历史。因此，博弈的信念体系由 一对概率分布组成:一个分配概率 1 到空历史(挑战者在博弈起始时的信念) , 另一个分配概率到历史"准备"和"无准备"(挑战者进入之后，在位者的信念)。



##### 10.4.2 策略

对一个信息集分配一个该信息集中可使用行动的概率分布。称这样的映射为"行为策略"  (***behavioral* strategy**) 。

A **behavioral strategy (行为策略)** of player i in an extensive game is a function that assigns to each of i’s information set (denoted as $I_i$) a probability distribution over the set of actions to player i at that information set (denoted as $A(I_i)$), with the property that each probability distribution is independent of every other distribution.

定义 10. 17(展开型博弈中的行为策略) 展开型博弈中玩家 i 的行为策略是一个函数，为玩家 i 的每一个信息集$I_i$ 分配一个 $A(I_i)$中行动上的概率分布，具有"每个概率分布与其他每个分布独立"的性质。

每个概率分布分配概率 1 至单一行动的行为策略与纯策略等价 ; 在研究的所有博弈中，混合策略与行为策略是等价的.

**Difference** between **behavioral strategy** and **mixed strategy**: a mixed strategy refers to a probability distribution over pure strategies, whereas a behavioral strategy refers to the collection of probability distributions over the actions at the information sets.



##### 10.4.3 均衡

An **assessment (评估)** in an extensive game is a pair consisting of (1) a profile of (behavioral) strategies and (2) a belief system.

定义 [**评估 (Assessment)**] 展开型博弈中的"评估"是由行为策略组合和信念体系组成的"对"

如果 评估 满足下述两个条件, 那么它是一个均衡:

1. **Sequential rationality (连续理性; 序贯理性)**: each player’s strategy is optimal whenever she has to move, given her beliefs and the other players’ strategies.  
   - The strategy has to be optimal in every information set, regardless of whether that information set is reached if the players follow their strategies.
2. **Consistency of beliefs with strategies(信念与策略一致)**: each player’s belief is consistent with the strategy profile. 每个玩家的信念与策略组合是一致的。
   - Each player’s belief must be correct in equilibrium.



下图中的例子,  假设玩家1 的策略,  开始时选取 E，在历史 (C，F)之后选择 $J$ ; 玩家2关于玩家1的信念玩家1会2/3选C, 1/3选D; 连续理性要求:给定由玩家1的策略所确定的后续行为，即使当玩家1遵循自己的策略时玩家2的信息集达不到，但是玩家2在这个信息集上的策略应当是最优的.   给定了玩家 2 的信念,在从玩家2的信息集出发的博弈部分,关于策略 $F$ 的期望盈利是 $\frac{2}{3} \cdot 0+\frac{1}{3} \cdot 1=\frac{1}{3}$ , 关于策略$G$ 的期望盈利是 $\frac{2}{3} \cdot 1+\frac{1}{3} \cdot 0=\frac{2}{3}$ 。 因此,连续理性要求她选择 $G$ . 在给定 2 的策略下, 连续理性也要求 1 在他的两个信息集上的策略是最优的。1 在历史(C,F)之后的最优行动是 $J$ ; 如 2 的策略是 G , 那么 1 在开始时的最优行动是 $D$ 和 $E$  ; 于是,给定了 2 的策略 G,  1 有两个最优策略一 $DJ$ 和 $E J$



<img src="/img/2020-04-18-Game.assets/image-20200511014917272.png" alt="image-20200511014917272" style="zoom: 33%;" />



记, **behavioral strategy profile** as $\beta$ and a **belief system** as $\mu$ , $I_i$ 为玩家i的一个信息集. 若$I_i$中每个历史发生的概率就是 $\mu_i$ , 并且随后玩家坚持策略 $\beta$, 那么得到的terminal 历史上的一个概率分布, 记为 $O_{l_i}(\beta, \mu)$ ;   

玩家的信念与策略一致的要求是新的。其思想是，在一个稳定状态中，每个玩家的**信念必须是正确的: 玩家认为任何历史发生的概率必定 等于 当玩家坚持她们的策略时这个历史真实发生的概率**。 如果玩家遵循策略，那么在达到的信息集中，这一思想是显然的; 但是，在玩家遵循策略而没有能够达到的信息集上，这一思想就不那么清楚了。 

**基于统计一致的信念**; 下面精确地阐述一致(相容)要求，**把信念体系仅限制在如果每个玩家坚持自己的策略将以正概率达到的信息集上**。明确地讲，由在这样的信息集上行动的玩家的信念指派给该信息集中每个历史$$h^*$$的概率， 应该等于在到达信息集的条件下按照策略使$$h^*$$发生的概率。
$$
\frac{P\left(h^{*} \text { according to } \beta\right)}{\sum_{h \in I_{i}} P(h \text { according to } \beta)}  \tag{10.19}
$$
再考虑上图的博弈,  如果玩家1的策略在开始时选行动 E，则根据一致性要求, 对 2 的信念没有限制，can hold any belief at her information set. 因为根本没走到,没应对不用管.  
然而，如 1 在开始时的 概率p 选C ,  q选D, 1-p-q 选E;  那么 $Pr(C  \text { according to } \beta)=p$,  $Pr(D) = q$ , 那么根据上面公式,  玩家2的信念则为 : p/(p+q) 到C,  q/(p+q) 到D. 



例题 10.20(BoS 中的一致信念) 例10.2, 对于1 的每一个策略, 2 的信息集以概率 1 达到。在这个博弈中,一致性(或相容性)要求 2 的信念总是正确的。对于所有同时行动的任何博弈,这个结论都成立。

例题 10.21(纸牌游戏中的相容性信念)  例10.3, 如果玩家 1 不管自己的牌是“王牌”还是“小牌”,她的策略都是选取“摊牌”,  那么相容性条件不限制玩家 2 的信念,因为玩家 2 的信息集达不到。 如果 1 的牌是“王牌”,选“加注”的概率记作 $p_{H},$ 如果玩家 1 的牌 是“小王”, 选择“加注”的概率记为 $p_{L}$ 。那么,$Pr (按照 \beta 发生(王牌, 加注))= \frac{1}{2} p_{H}, \operatorname{Pr}(\text { 按照 } \beta \text { 发生(小王,追加堵注) })=\frac{1}{2} p_{L}$ 。因此,玩家 2 的信念指派概率 $p_{H} /\left(p_{H}+p_{L}\right)$ 到历史 $H$ ,  指派概率 $p_{L} /\left(p_{H}+p_{L}\right)$ 到历史 $L$ .



<img src="/img/2020-04-18-Game.assets/image-20200511014917272.png" alt="image-20200511014917272" style="zoom: 33%;" />

例题 10.22(进入博弈的相容性信念) 记 $p_{R}, p_{U}$ 和 $p_{O}$ 为挑战者指派到“准备”、"无准备”和“在外”的概率。  
如果 $p_{O}=1,$ 相容性条件不限制在位者的信念。  
否则, 条件要求指派概率 $p_{R} /\left(p_{R}+p_{U}\right)$ 到“准备”,指派概率 $p_{U} /\left(p_{R}+p_{U}\right)$ 到“无准备”。



定义 : an **assessment 评估** $(\beta, \mu)$ is a **weak sequential equilibrium 弱连续均衡** if it satisfies the following two conditions:

1. **Sequential rationality 连续理性**: for each player $i$ and each information set $l_{i}$ of player $i,$ her expected payoff to the probability distribution $O_{l_i}(\beta, \mu)$ over terminal histories generated by her belief $\mu_{i}$ and $l_{i}$ and the behavior prescribed subsequently by the strategy profile $\beta$ is at least as large as her expected payoff to the probability distribution $O_{l_i}\left(\left(\gamma_{i}, \beta_{-i}\right), \mu\right)$ generated by her belief $\mu_{i}$ at $l_{i}$ and the behavior prescribed subsequently by the strategy profile $\left(\gamma_{i}, \beta_{-i}\right),$ for each of her behavioral strategies $\gamma_{i}$    
   对每个人, 在该评估下, 预期收益是最好的.>理性
2. **Weak consistency of beliefs with strategies 弱信念与策略一致性** : for every information set $I_i$ reached with positive probability given the strategy profile $β$, the probability assigned by the belief system to each history $$h^*$$ in $I_i$ is given by (10.19).  
   即信念是基于概率统计的.



<img src="/img/2020-04-18-Game.assets/image-20200511014917272.png" alt="image-20200511014917272" style="zoom: 33%;" />

该例, 体现了弱连续均衡.  

1. 给定 2 的策略 G，1 的策略 EJ 是序贯理性的;  给定图上玩家2的信念以及玩家1的策略 EJ, 玩家2的策略G是 连续理性的.  进而, 玩家2的信念与策略组合(EJ,G) 一致. 因此,该博弈有一个弱连续均衡, 其中策略是(EJ,G), 信念是上图的(或者其他使得能选G的信念). 
2. 对(DJ,G) ,  对玩家2的G, 玩1是连续理性的; 给定玩2的信念与玩1的策略, 玩2 策略是连续理性; 但玩2信念与策略组合不一致.   唯一一致的信念是概率1到D, 使得玩2的F是最优.

在完全信息的展开型博弈中，只有一个信念体系是可能的: 每一个玩家在每个信息集上相信"单一适合的历史以概率 1 发生"。

**在完全信息的展开型博弈中，任意弱连续均衡的策略组合就是子博弈完美均衡。**

**任何弱连续均衡的策略组合是纳什均衡。**



#### 10.5	Signaling games   信号博弈

**Signaling game**: 有些玩家对影响到每个人的变量都是知情的，而其他玩家则不知道。知情的玩家（"发送者sender"）先采取行动，而不知情的玩家（"接收者receiver"）在观察到知情玩家的行动后采取行动。知情玩家的行动可能会给他们的信息（例如，他们的类型）发出 "信号signal"。 

这样的情况可以建模为展开型博弈，其中发送者有若干个可能的"类型"，每一个类型对应于她知道的变数的一个值。她观察到的值，也就是她的类型，由随机的方式确定。接收者观察不到发送者的类型，可是能看到发送者所采取的行动，然后接收者自己再采取行动。



例10.27(进入作为信号博奔)  挑战者 呈现"强"的概率等于p，而呈现"弱"的概率为 1-p ;挑战者知道自己的类型，可是在位者并不知道。挑战者要么"准备"，要么保持"无准备"状态。(没有 "外面"的选择。) 在位者观察到挑战者是否准备就绪，但观察不到她的类型 . 

<img src="/img/2020-04-18-Game.assets/image-20200511120127099.png" alt="image-20200511120127099" style="zoom:50%;" />

<img src="/img/2020-04-18-Game.assets/image-20200511120206589.png" alt="image-20200511120206589" style="zoom:50%;" />

现在求这个博弈的纯弱序贯均衡。  



概括来说，博弈有两类弱序贯均衡。 倘若挑战者强，她就选择"准备"，而如果挑战者是弱的, 就选择"无准备"。在位者相信，有准备的挑战者是强的，而无准备的为弱的，并且默许有准备的挑战者, 对无准备的挑战者斗争。



这个例子描述了可能存在于信号博弈中的两类纯策略均衡: 











#### 10.6	Illustration: conspicuous expenditure as a signal of quality   

#### 10.7	Illustration: education as a signal of ability   

#### 10.8	Illustration: strategic information transmission   

#### 10.9	Illustration: agenda control with imperfect information   







## Part III: Variants and Extensions  变体和推广

### 11 Strictly Competitive Games and Maxminimization 严格竞争博弈和最大最小化

**minimax: 悲观保守**  非常重要的方法.



纳什均衡, 其思想是，每个玩家通过自己与各种对手的博弈经验，知道游戏中其他玩家会采取的行动，并根据这些知识选择自己的行动。
在本章和下一章中，我们从不同的角度来研究博弈的可能结果。我们考虑每个博弈者对其他博弈者的行动所形成的信念，不是从他的经验出发，而是从他对博弈的分析出发，来考虑其意义。
这一章重点讨论的是严格意义上的二人游戏，在这种游戏中，玩家的利益是截然相反的。在这种博弈中，一个简单的决策程序导致每个玩家选择一个纳什均衡行动。



#### 11.1  Maxminimization  最大最小化

你**第一次**面临博弈;**对于你的对手**将采取什么行动**没有任何信念**。你应该怎样选择你的行动呢?给你一个非常**保守的方案** :对于你的每一个行 动，当其他玩家的行动变化时，找出对你来说是最差的结局，然后在这些最差的结局中找出一个最好的，相应的行动就是你的选择。这种方法称为 "**最大最小化maxminimization**"法。

DEFINITION 336.1  A **maxminimizing mixed strategy** for player $i$ in a strategic game (with vNM payoffs) is a mixed strategy $\alpha_{i}^{*}$ that solves the problem

$$
\max_{\alpha_{i}} \min_{\alpha_{-i}} U_{i}\left(\alpha_{i}, \alpha_{-i}\right)
$$

where $U_{i}$ is player $i$ 's vNM payoff function.

一句话，玩家$i$的最大最小化策略是, 无论他做什么，其他玩家都会以最小化他的预期回报的方式行动, 在这样**悲观的假设下**, 去最大化了自己的回报. 



另一个角度看到minimax.  如果一个混合策略保证玩家i 的回报保障是$$\bar{u}_{i}$$ , 那么不管其他玩家采样什么策略, 即:
$$u_{i}\left(\alpha_{i}, \alpha_{-i}\right) \geq \bar{u}_{i}$$ for every list $$\alpha_{-i}$$ of the other players' mixed strategies. 

minimax策略能够最大限度地保证玩家的回报: 如果 $\alpha_{i}^{*}$ 是minimax策略, 则有
$$\min _{\alpha_{-i}} u_{i}\left(\alpha_{i}^{*}, \alpha_{-i}\right) \geq \min _{\alpha_{-i}} u_{i}\left(\alpha_{i}, \alpha_{-i}\right)$$ for every mixed strategy $\alpha_{i}$ of player $i$

**就是说, minimax是所有策略里面,  玩家能得到最好的回报保障.**



EXAMPLE 337.1  maxminimizers的例子. 

<img src="/img/2020-04-18-Game.assets/image-20200508011853619.png" alt="image-20200508011853619" style="zoom:33%;" />

显然, 如果策略限制玩家1要么选择T,要么选择B, 最坏的情况, 收益保障是-1.  然后, 玩家1在T和B中随机化, 收益可能更好一点. 比如1/2选T, 1/2选B, 则玩家2固定选择L,玩家1的预期收益是1/2, 玩家2选择R,玩家1的预期收益是0;   令$p$ 为玩家1选择T的概率.  下图中两条线分别表示玩家2选择L,R时候,玩家1的随着p的改变的收益. 黑色的倒V线表示玩家1所能获得的被玩家2针对下的收益保障,即 $\min_{\alpha_2}u_1(\alpha_1,\alpha_2)$  , 而玩家1需要max这个保障, 所以选择p=2/5. 

<img src="/img/2020-04-18-Game.assets/image-20200508012459016.png" alt="image-20200508012459016" style="zoom: 33%;" />



#### 11.2  Maxminimization and Nash equilibrium  最大最小化与纳什均衡

下面讨论纳什均衡与minimax策略之间的关系.  重要结论

**LEMMA 338.1**  **对策略博弈, 任何纳什均衡策略的收益都大于等于minimax策略的收益**.  *The payoff of each player in any Nash equilibrium of a strategic game is at least equal to her maxminimized payoff*. 
Proof.  Let $$\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right)$$ be a Nash equilibrium. Consider player 1. First note that by the definition of a Nash equilibrium, 
$$U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right) \geq U_{1}\left(\alpha_{1}, \alpha_{2}^{*}\right)$$ 	for every mixed strategy $$\alpha_{1}$$ of player 1
so that
$$U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right) \geq \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)$$ 	for every mixed strategy $$\alpha_{1}$$ of player 1
since the inequality holds for every mixed strategy $$\alpha_{1}$$ of player 1,  we conclude that
$$
U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right) \geq \max _{\alpha_{1}} \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)
$$



#### 11.3 Strictly competitive games 严格竞争博弈

在许多博弈中，玩家没有充分的理由去相信其他人将采取使其收益最小化的行动。可是在玩家的利益完全对立的两人博弈中，这个假设是合理的 . 

DEFINITION 339.1 (**序数偏好的严格竞争策略型博弈 Strictly competitive strategic game with ordinal preferences**)  一个策略型博弈是严格竞争的, 如果有两个玩家, 并且有
$$
u_{1}\left(a_{1}, a_{2}\right) \geqslant u_{1}\left(b_{1}, b_{2}\right) \quad \text { 当且仅当 } \quad u_{2}\left(b_{1}, b_{2}\right) \geqslant u_{2}\left(a_{1}, a_{2}\right)
$$
其中 $\left(a_{1}, a_{2}\right)$ 和 $\left(b_{1}, b_{2}\right)$ 是一对行动;  主要就是这两个人的收益函数是方向相反的.

注意，如果 $u_{1}$ 是描述严格竟争博弈中玩家1偏好的收益函数,那么收益函数$-u_1$ 则描述了玩家2 的偏好。也就是说，在任何严格竟争博弈中,**存在**玩家的收益函数$u_1$ 和 $u_2$,  使得对于任意的行动组合 $\left(a_{1}, a_{2}\right)$ 成立 $u_{1}\left(a_{1}, a_{2}\right)+u_{2}\left(a_{1}, a_{2}\right)=0$ 。出于这个原因, 严格竞争博弈有时叫作"**零和 zerosum**" 博弈。 零和博弈是严格竞争博弈在收益函数为0时的特殊情况. 因为收益函数是序数偏好, 其实 (-1,2) 这种的也是严格竞争的. 但肯定可以设计出sum为0的收益函数.

囚徒困境,BOS都不是严格竞争;  匹配硬币是的. 

下例,  也是严格竞争, 纯策略的时候.  玩家1喜欢(B, R) > (T, L) > (B, L) > (T, R) , 玩家2正好相反. 但考虑混合策略,则不是严格竞争.

<img src="/img/2020-04-18-Game.assets/image-20200509020106893.png" alt="image-20200509020106893" style="zoom:50%;" />



DEFINITION 339.2 (**vNM 偏好的严格竞争策略型博弈 Strictly competitive strategic game with vNM preferences**) 一个具有 vNM 偏好的策略型博弈是严格竞争的，如果它有两个玩家,并且 

$$
U_{1}\left(\alpha_{1}, \alpha_{2}\right) \geqslant U_{1}\left(\beta_{1}, \beta_{2}\right) \quad \text { 当且仅当 } \quad U_{2}\left(\beta_{1}, \beta_{z}\right) \geqslant U_{2}\left(\alpha_{1}, \alpha_{2}\right)
$$

这里，( $\alpha_{1}, \alpha_{2}$ ) 和 $\left(\beta_{1}, \beta_{2}\right)$ 是一对混合策略 ;并且对于 $i=1,2$,  $U_{i}$ 是描述玩家 $i$ 关于随机结局偏好的期望收益函数。

如同具有有序数偏好的博弈那样，在具有 vNM 偏好的严格竞争博弈中， 存在具有如下性质的描述玩家偏好的收益函数:对于每个行动组合，玩家的收益之和等于 0。即，如果$u_1$是伯努利收益函数，它的期望值描述了玩家1关于随机结局的偏好，那么$-u_1$ 就是其期望值描述了玩家2偏好 的伯努利收益函数。

当混合策略时为严格竟争的任何博弈，在限于纯策略时 显然也是严格竞争的,但是反之不成立。例如,考虑图339.1中的博奕，现在将方框内的数字解释为伯努利盈利。玩家1对于如下两种结果感觉没有差别 : 一种是结局 ( $T, L$ ); 另一种是“( $T, R$ ) 以概率 $\frac{3}{5}$ 发生和$(B, R)$以概率$\frac{2}{5}$ "的随机结局, 因为$\frac{3}{5} \cdot 0+\frac{2}{5} \cdot 5=2$,  可是玩家2 对于这两个结局感觉有差异[他关于(T,L)的盈利是 1，而相应于那个随机结局，他的期望盈利是 $\left.\frac{3}{5} \cdot 5+\frac{2}{5} \cdot 0=3\right]$



##### 11.4	Maxminimization and Nash equilibrium in strictly competitive games  严格竞争博弈中的最大最小化与纳什均衡

在任何博弈中，纳什均衡盈利 >= 最大最小化盈利

下面证明，在具有混合策略纳什均衡的严格竞争博弈中，这两个盈利是相同的。事实上有:

在具有混合策略纳什均衡的严格竞争博弈中，一对混合策略组合是混合策略纳什均衡，当且仅当每个玩家的策略是最大最小化解。



PROPOSITION 341.1 (**严格竟争博弈中的纳什均衡策略和最大最小化解**) 考虑具有 vNM 偏好的严格竟争策略型博亲。令$U_1$ 为描述玩家1偏好的期望收益函数,令$U_{2}=-U_{1}$ ,$U_{2}$ 描述玩家2的偏好  
a. 如果 $$ (\alpha_{1}^*, \alpha_{2}^*)$$是混合策略纳什均衡,  那么  $$\alpha_{1}^*$$是玩家1的最大最小化解 , $$\alpha_{2}^*$$是玩家2的最大最小化解, 并且:
$$
\max _{\alpha_{1}} \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)=\min _{\alpha_{2}} \max _{\alpha_{1}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)=U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right)
$$

b. 如果$$\max _{\alpha_{1}} \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)=\min _{\alpha_{2}} \max _{\alpha_{1}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)$$ , [特别地,如果博弈有一个混合策略纳什均衡,那么 a 条件满足(见 a 部分)], $$\alpha_{1}^*$$ 是玩家1的最大最小化解, $$\alpha_{2}^*$$ 是玩家2的最大最小化解,  那么($$\alpha_{1}^{*}, \alpha_{2}^{*}$$)是混合策略纳什 均衡。



**首先**，结果的a部分意味着在严格竞争博弈中，每个人的混合策略纳什均衡**收益是唯一**的。

COROLLARY  342.1  严格竞争博弈中的每个混合策略纳什均衡产生相同的期望盈利组合。 Every Nash equilibrium of a strictly competitive game yields the same pair of payoffs.

如同我们已经着到的，在非严格竞争博弈中，不是所有的纳什均衡都必然产生相同的收益组合(例,考虑 BoS)



**其次**，假设 $\left(\alpha_{1}, \alpha_{2}\right)$  和 $\left(\alpha_{1}^{\prime}, \alpha_{2}^{\prime}\right)$ 都是严格竞争博弈中的混合策略纳什均衡。 那么由命题341.1 中的a部分可知，策略$\alpha_{1}$ 和$ \alpha_{1}^{\prime}$ 是玩家1 的最大最小化解，$\alpha_{2}$ 和$ \alpha_{2}^{\prime}$ 是玩家2 的最大最小化解。然而由 b部分的结果可知，$\left(\alpha_{1}, \alpha_{2}^{\prime}\right)$和$\left(\alpha_{1}^{\prime}, \alpha_{2}\right)$ 都是博弈的混合策略纳什均衡。也就是说，我扪有下述结果。

如果玩家1有两个套路, 则每个都适用.

COROLLARY 342.2  严格竞争博弈中的混合策略纳什均衡是可以**互换**的: 如果  $\left(\alpha_{1}, \alpha_{2}\right)$ 和$\left(\alpha_{1}^{\prime}, \alpha_{2}^{\prime}\right)$  是混合策略纳什均衡，那么$\left(\alpha_{1}, \alpha_{2}^{\prime}\right)$和$\left(\alpha_{1}^{\prime}, \alpha_{2}\right)$ 也是博弈的混合策略纳什均衡。

博弈 BoS 显示，非严格竞争博弈的纳什均衡不一定可以互换。



**第三**，记严格竞争博弈中玩家 1 的均衡盈利为$$U_1^*$$ ,  命题 341.1 中的 a 部分意味着，玩家1的任何纳什均衡策略确保其盈利至少为$$U_1^*$$，玩家 2 的任何纳什均衡策略确保其收益至少是 $$-U_1^*$$ 。第二个含义是，玩家 2 的任何纳什均衡策略保证玩家1的收益至多为$$U_1^*$$ .

COROLLARY 343.1  在严格竞争博弈中，玩家1的任何纳什均衡策略可以保证他的收益至少是其均衡收益; 玩家2的任何纳什均衡策略可以保证玩家1的收益至多是其均衡收益。 

**均衡收益0和**.





### 12 Rationalizability 理性化



### 13  Evolutionary equilibrium  演化均衡

用博弈论来研究生物演化.

本章中我们描述了基于策略盟博弈的模型。玩家是进化中生物总体 的成员(人类、动物、植物、细菌......) ，彼此相互影响。每个玩家的行动集 由生物体通过变化获得的行为模式组成，它的盈利度量了它的生物学适应性或繁衍能力〈健康后代的期望个数〉。







### 14  Repeated games: The Prisoner’s Dilemma 重复博弈: 囚徒困境



#### 14.1 The main idea 

之前的博弈对应一次性关系;  重复博弈对应 长期关系. 

理论的主要思想是，玩家可能会因为 "惩罚"的"威胁": 降低自己的长期回报, 而不敢利用自己的短期优势.   要开始考虑长期利益以及什么时候跑路.    



给定一个基本博弈G (静态博弈或动态博弈)，重复进行T次G，并且在每次重复G时博弈方都
能观察到之前博弈的结果，这样的博弈过程称为“G的T次重复博弈”,记为G(T)。而G则称为G(T)的“原博弈, G(T)中的每次重复称为G(T)的一个“**阶段**”。





例如，假设两个人重复地"玩"囚徒困境, 

<img src="/img/2020-04-18-Game.assets/image-20200509035308686.png" alt="image-20200509035308686" style="zoom:33%;" />

这个策略型博弈有唯一的纳什均衡，其中，每个玩家选择 D;  现在我们来考虑重复博弈中的下述策略，被称为**"冷酷触发策略" *(the* *grim trigger strategy)*** *:*

- 只要另一个玩家选择 C，就一直选择 C 
- 如果在任何周期中，另一个玩家选择 D，那么在以后的每一个周都选择 D。

这个策略从双方合作开始，并且继绩合作下去，直至对方背叛;  对手的一次背叛触发了无情的背叛，我们可以把这解释为对对手的报复性"惩罚" . 如果对手采用这种策略，他应该怎样反应呢? 如果 他在每一个周期选择 C，那么结果是(C, C) ，他在每一周期的盈利为 2。倘若他在某个周期转向 D，那么他在那个周期得到盈利 3(短期的获利) ，并且在以后每一个周期得到盈利1(长期的损失)。只要他赋予未来盈利的值比起他赋予当前盈利的值不会太小，那么对于他来说，盈利系列 (3，1，1，...)比起盈利系列 (2，2，2，...)要糟糕些，因此，他在每一个周期选择 C 比在某个周期转而选择 D ，情况要好得多。

然而，这个"策略对"不是重复博弈中唯一的纳什均衡。另外一个纳什均衡是在每个历史之后每个玩家都选择 D的"策略对":  如果一个玩家采取这个策略，那么另一个玩家只能选D. 



这个分析提出了许多问题:

- 为了重复囚徒困境有每个周期的结局都是 (C，C) 的纳什均衡，确切地，玩家必须有多大耐心?  对未来的预期
- 其他什么结局是由纳什均衡产生的? 
- 在第五章中，展开型博弈的纳什均衡直觉上并不总是吸引人，因为在发生偏离的历史之后，他们指令的行动可能不是最优的。 子博弈完美均衡要求在每个可能的历史之后的策略是最优的，不仅是那些玩家坚持自己的策略而达到的历史，因此这个概念更加吸引 人。每个玩家都使用冷酷触发策略的"策略对"是子博弈完美均衡 吗?也就是说，每个玩家会最优地惩罚其他玩家的偏离吗?如果不会，博弈有支持称心合意结局的子博弈完柴均衡吗?
- 冷酷触发策略规定了相当严厉的报复。是否存在"玩家的策略惩罚偏离不太严厉"的纳什均衡或子博弈完美均衡?
- 论证如何适用于非囚徒困境的博弈?



#### 14.2 Preferences 偏好

##### 14.2.1 Discounting  折扣

对未来预期的数学表达方式.  **discounted sum**  折扣和,**贴现**和;   
有局限性, 偏好不一定是这样的,但能体现重视当下的偏好特征.
$$
u_{i}\left(a^{1}\right)+\delta u_{i}\left(a^{2}\right)+\delta^{2} u_{i}\left(a^{3}\right)+\cdots+\delta^{T-1} u_{i}\left(a^{T}\right)=\sum_{t=1}^{T} \delta^{t-1} u_{i}\left(a^{t}\right)
$$

假设是玩家关于盈利序列$\left(w^{1}, w^{2}, \cdots\right)$的偏好由这些盈利的"贴现和" $\sum_{t=1}^{\infty} \delta^{t-1} w^{t}$ 进行描述,这里 $0<\delta<1$ 。对于任何给定的序列 $\left(w^{1}, w^{2}, \cdots\right)$ 是否存在一个 c 值使得玩家认为收益序列和常数序列 $(c, c, \cdots)$ 之间是**等价**的.  记 $\left(w^{1}, w^{2}, \cdots\right)$  的和为V,  $(c, c, \cdots)$ 的和是$c /(1-\delta)$ , 因此,若 $c=(1-\delta) V$,那么玩家认为这两个序列之间不存在差异。所以被称为**贴现平均值discounted average**. 

准确的说, 贴现平均值为 $(1-\delta) \sum_{i=1}^{\infty} \delta^{i-1} w^{\prime}$ 。 注意,对于任何位于 0 与 1 之间的贴现因子 $\delta$以及任何数 c，常数盈利序列$(c,c,\cdots)$的贴现平均值 $(1-\delta)(c+\delta c+ \delta^2 c+ \dots) =c$。



##### 14.2.2 Equivalent payoff functions 等价收益函数

考虑在不受时间影响的**确定性**结局上的偏好时，我们发现许多收益函数描述了同一个偏好。尤其是，假如 $u$ 是描述决定性结局上的偏好的收益函数，那么  $u$ 的任意递增函数也描述了该偏好. 

当考虑不受时间影响的随机结局的偏好时，发现收益函数的等价性更具有局限性, 如果 $u$ 是一个的伯努利收益函数，它的期望值描述了关于随机结局的偏好，那么每一个期望值描述了他的偏好的其他盈利函数是 $u$ 的递增线性函数 .  (4. 12. 2) 下面证明.

对重复博弈 , 收益是序列的, 考虑等价函数.  如果两个结果序列 $\left(x^{1}, x^{2}, \ldots\right)$ and $\left(y^{1}, y^{2}, \ldots\right)$ 是等价的, 有
$$
\sum_{t=0}^{\infty} \delta^{t-1} u\left(x^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1} u\left(y^{t}\right)
$$
令 $v$  为一个 increasing affine function of $u: v(x)=\alpha+\beta u(x)$ with $\beta>0$ ,  即线性正相关.
$$
\sum_{t=0}^{\infty} \delta^{t-1} v\left(x^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1}\left[\alpha+\beta u\left(x^{t}\right)\right]=\sum_{t=0}^{\infty} \delta^{t-1} \alpha+\beta \sum_{t=0}^{\infty} \delta^{t-1} u\left(x^{t}\right)
$$

$$
\sum_{t=0}^{\infty} \delta^{t-1} v\left(y^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1}\left[\alpha+\beta u\left(y^{t}\right)\right]=\sum_{t=0}^{\infty} \delta^{t-1} \alpha+\beta \sum_{t=0}^{\infty} \delta^{t-1} u\left(y^{t}\right)
$$

则有, 
$$
\sum_{t=0}^{\infty} \delta^{t-1} v\left(x^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1} v\left(y^{t}\right)
$$


LEMMA 393.1 (**折扣收益函数的等效性Equivalence of payoff functions under discounting**) The discounted sum of payoffs with the **payoff function u** and discount factor δ represents the **same preferences** over streams of payoffs as the discounted sum of payoffs with the **payoff function v** and discount factor δ if and only if there exist α and β > 0 such that u(x) = α + βv(x) for all x.



这个结果的意义在于，对重复博弈的策略型博弈中,  即使结果是deterministic，收益也不再是简单的序数。  例如, 囚徒困境, 将下图中收益表 (0, 3),(0, 3) 换成 (0, 5), (0, 5) , 基于这个得到一个新的囚徒重复博弈, 则这两个重复博弈的玩家偏好是不一样的.   比如，当折扣因子接近于1时，在第一种情况下，每个玩家喜欢结局序列((C, C), (C, C)) 超过((D, C), (C, D))  , 在第二种情况下则不是这样。

<img src="/img/2020-04-18-Game.assets/image-20200509035308686.png" alt="image-20200509035308686" style="zoom:33%;" />



所以, 下面都要用收益函数来定义策略型博弈, 而不是偏好. 



#### 14.3 Infinitely repeated games 无限重复博弈

将一次性的strategic博弈的重复博弈,  看成perfect信息的extensive博弈. 

DEFINITION 394.1   	G , a strategic game.  **The infinitely repeated game** of $G$ for the discount factor $\delta$ is the **extensive game** with **perfect information** and **simultaneous moves** in which
- the set of players is $N$
- the set of terminal histories is the set of **infinite** sequences $\left(a^{1}, a^{2}, \ldots\right)$ of action profiles in $G$
- the player function assigns the set of all players to every proper subhistory of every terminal history
- the set of actions available to player $i$ after any history is $A_{i}$
- each player $i$ evaluates each terminal history $\left(a^{1}, a^{2}, \ldots\right)$ according to its discounted average $(1-\delta) \sum_{t=1}^{\infty} \delta^{t-1} u_{i}\left(a^{t}\right)$



把上面的无限改为T, 则为T周期重复博弈 ;

terminal history 也被 称为 结局路径. 



#### 14.4 Finitely repeated *Prisoner's Dilemma* 有限重复囚徒困境

<img src="/img/2020-04-18-Game.assets/image-20200509035308686.png" alt="image-20200509035308686" style="zoom:33%;" />

考虑囚徒困境的T周期重复博弈。假设对于每一个可能的历史，一个玩家的策略是在每一个周期选D, 那么其他人肯定也选D. 因为其他人选C更差.  因此，(D,D) 的"策略对" 是T 周期的纳什均衡。

每一个纳什均衡产生相同的结局路径. 所以该博弈不能体现本章开始所讨论的思想，即合作的结局, 可以通过对偏离进行惩罚。证明: 在两个人都选择 C 的最后一个周期里，从 C 转 向 D 的偏离**不可能受到惩罚**一一即在以后每一个周期，结局都是 (D，D) 一因此在任何周期中没有一个人会最优地选择 C.    

有限周期, 最后一个周期T是明确早就知道的, 那么绝对占便宜的人肯定会耍花样, 有理由会转向D. 那么一直倒推.   就跟一次性的囚徒困境一样. 对均衡而言, 只能是选D .    这里讨论的是由 纳什均衡 得到的策略. 纳什均衡只是想自己不比别人亏, 不考虑总体收益最大. 



#### 14.5 Infinitely repeated *Prisoner's Dilemma*  无限重复囚徒困境

无限的博弈有这样的结局路径，其中对于每一个人和每一个周期 t，存在一个"玩家的行动是 C"的未来周期，所以通过选择 D 取代 C ，她可以惩罚另一个人在周期 t 的偏离。这个事实启示了，无限重复博弈可能是体现下述想法的一个合适模型: 可以通过"惩罚"策略 使合作得以维系. 

 大多数的相互作用既不会维持一个预定的有限周期数(一个明确的T), 也不会真的无限, 那怎么建模. 那最好就是不知道什么时候结束.  直觉提出，在许多经过很长时期才结束的相互作用里，在终止期没有到来之前，终止期本身对参与者的策略算计几乎不起作用。



#### 14.6  Strategies in an infinitely repeated Prisoner's Dilemma   无限重复囚徒困境中的策略

**grim trigger strategy** 冷酷触发策略
$$
s_{i}(\varnothing)=C \\ 
\ \\
s_{i}\left(a^{1}, \ldots, a^{t}\right)=\left\{\begin{array}{ll}
C & \text { if } a_{j}^{\tau}=C \text { for } \tau=1, \ldots, t \\
D & \text { otherwise }
\end{array}\right.
$$


该策略有两个 **states 状态** : 一个是 $\mathcal{C}$ ,   在该状态选 $C$ ; 另一个是 $\mathcal{D}$ , 选 $D$  . 

用图表示,  如果一个人选D, 则状态改变.

![image-20200513045525223](/img/2020-04-18-Game.assets/image-20200513045525223.png)

下面是个变体, 没有之前那么严厉, 只处罚3个周期

<img src="/img/2020-04-18-Game.assets/image-20200513045724173.png" alt="image-20200513045724173" style="zoom:50%;" />

下面一个变体,   tit-for-tat  针锋相对策略,  一个人在前一个周期做什么, 另外一个人也做什么

<img src="/img/2020-04-18-Game.assets/image-20200513045916224.png" alt="image-20200513045916224" style="zoom:50%;" />



#### 14.7 Some Nash equilibria of an infinitely repeated *Prisoner's Dilemma*  无限囚徒困境中的一些纳什均衡

14.7.1 Grim trigger strategies











### 15 重复博弈：一般性结果



### 16 讨价还价





### 17 Appendix: Mathematics 附录：数学

#### 17.3  Sets

##### **partition 划分**    

A partition of a set $A$ is a collection $$\left\{A_{1}, \ldots, A_{k}\right\}$$ of subsets of $A$ such that every member of $A$ is in exactly one of the sets $A_{j}$. 



设n个元素的集合可以划分为F(n,m)个不同的由m个非空子集组成的集合。  
考虑3个元素的集合，可划分为  

- 1个子集的集合：$$\{\{1，2，3\}\}$$  

- 2个子集的集合：$$\{\{1，2\}，\{3\}\}，\{\{1，3\}，\{2\}\}，\{\{2，3\}，\{1\}\}$$
- 3个子集的集合：$$\{\{1\}，\{2\}，\{3\}\}$$



####  17.4 Functions

affine 仿射函数  f (x) = ax + b

quadratic 二次函数 



#### 17.5 Profiles  组合

For example, players are Ernesto, action is $R,$ and Hilda,  $S$,  function $a$ defined by $a(\text { Ernesto })=R$ and $a(\text { Hilda })=S .$  可以将 $a$ 表示为 $\left(a_{\text {Ernesto }}, a_{\text {Hilda }}\right)=(R, S) $ , 称函数 $a$ 为一个**组合profile**.  

一个常用的组合, 与$\left(a_{1}, \ldots, a_{n}\right)$  不同,因为player $i$ 的动作是 $b_{i}$  , 可以记为$\left(b_{i}, a_{-i}\right)$ ; -i 表示除i以外.   
例如  (a1, a2, a3) = (T, L, M) and b2 = R, for example, then $(b_2, a_{−2}) = (T, R, M)$.





#### 17.8 Proofs

Lemma  引理

Proposition  命题

Corollary  推论











# A Course in Game Theory

1994 , Martin J. Osborne

一些笔记, 待整理

公式太多, 体系比较全.



### 总体结构

<img src="/img/2020-04-18-Game.assets/image-20200501182914681.png" alt="image-20200501182914681" style="zoom:50%;" />



## Introduction

#### 1.1	Game Theory 博弈论

博弈论的基本假设 : 假设对手是理性的 rational



#### 1.2	Games and Solutions

##### Noncooperative and Cooperative Games   合作, 非合作博弈



##### Strategic Games and Extensive Games  策略博弈和扩展博弈

策略博弈是这样一种情形的模型:每个参与人一劳永逸地选择一次行动计划plan, 并且所有参与人的决策是同时做出的(也就是说,在选择行动计划时每个参与人并不知道其他参与人的行动计划)。与此相反，扩展博弈模型则规定了事件的可能顺序:每个参与人不仅可以在博弈开始时考虑自己的行动计划,并且每当他必须做出决定时，也可以考虑自己的行动计划。



##### Games with Perfect and Imperfect Information  完全与不完全信息博弈

完全信息就是对其他人的行动都了解;  不完全信息就是不清楚其他人的行动. 



#### 1.3	Game Theory and the Theory of Competitive Equilibrium  博弈论与竞争均衡理论

为了近一步弄清博弈论的本质,现在将它与经济学中的**竟争均衡理论**作比较。博弈论要考虑决策主体在做出决策前企图获得其他参与人的**行为信息**,而竞争理论给出的假定是:每个参与人只对某些环境参数感兴趣(例如价格),即使这些参数是被全体参与人的行为所决定的。
我们通过考虑下面一种情形来说明这两个理论的差异:在该情形中,每个参与人的某种行动(如钓鱼)的水准依赖于污染的程度,反过来污染程度又依赖于全体参与人的活动。若用竞争理论分析,我们便会去寻找一个与全体参与人行动相一致的污染程度,此时每个参与人都认为这个程度是给定的;若用博弈理论分析,我们则要求每个参与人的行动均为**最优optimal**,此时所有参与人一起造成的污染预期是给定的。



#### 1.4	Rational Behavior 理性行为

我们研究模型时, **假设**每个决策主体都是“**理性的 rational**”, 即决策主体知道他的所做的选择, 对未知的因素形成预期,具有明确的**偏好preferences**, 并在经过一定的优化过程后 特意地选择他的行动。

在不存在**不确定性uncertainty**的情况下，以下因素构成了**理性选择模型model of rational choice**：

- set $A$ of **actions** 行为集
- set $C$ of possible **consequences**  上述行为的可能**结果集合**
- **consequence function** $g: A \rightarrow C$   ;  **结果函数** ,  每个action对于一个consequence;   **reward**
- **preference relation** (a complete transitive reflexive binary relation 完全的,可传递的, 自反的 二元关系) $\succsim$ on the set $C$      ;  结果集合上的  **偏好关系**;   就是策略本身
- **utility function**   $U: C \rightarrow \mathbb{R}$ ,  有时用 **效用函数** 来表示偏好.   用奖励的函数表示策略  
  效用函数定义了一个偏好关系:   $x \succsim y$ 当且仅当 $U(x) \geq U(y)$   
  给定一个集合$B \subseteq A$ ,  在某特別情形下是可行feasible的, 一个理性的决策者选择一个可行的最优行动 $$a^*$$ (  $$a^* \in B$$  ) , 当对所有$a \in B$ 满足  $g\left(a^*\right) \succsim g(a)$ .    
  或者说, 他解决了问题 $\max _{a \in B} U(g(a))$ .   
  值的注意的是, 使用这个决策模型需要假设每个决策主体在不同的集合$B$上使用同一个偏好关系. 



下面讨论包含不确定性的决策建模. 

为了对不确定性下的决策进行建模，几乎所有的博弈论都使用了冯-诺依曼(1944)和萨维奇(1972)的理论。  
也就是说，如果结果函数是随机的，并且对决策者来说是已知的（即对每一个$a \in A$ ，结果 $g(a)$ 是 $C$上的随机（概率分布）），那么决策者就被假定为, 他的行动 为了最大化 **von Neumann-Morgenstern 效用函数**的期望 而去行动.     
如果行动与结果间的随机映射关系未给定，那么决策者的行为就被假定为他按照自己心中（主观的）概率分布去行动。在这种情况下，决策者的行为就好像他心中有一个 "**状态空间state space**" $\Omega$ ，一个$\Omega$上的概率测度，一个函数 $g: A \times \Omega \rightarrow C$，和一个效用函数$u: C \rightarrow \mathbb{R}$ ;  他被假设为按照概率测度来选择行动 $a$，使$u(g(a, \omega))$ 的期望值最大化。



#### 1.5	The Steady State and Deductive Interpretations 稳态 和 推论

对于策略博弈和扩展博弈的解 有两种相互冲突的解释。**稳态steady state**(或如Binmore(1987/88)所称的**演化evolutive**)解释与经济学中的标准解释密切相关。博弈论和其他科学一样，处理的是规律性问题。正如卡纳普（1966年，第3页）所写的那样，"我们在日常生活中进行的观察以及科学的更系统化的观察都揭示了世界上的某些重复性或规律性......科学的规律不过是尽可能精确地表达这些规律性的陈述。" 稳态解释将一个博弈视为一个模型，旨在解释在相似情况下观察到的一些规律。每个参与者都凭借从长期的经验中获得的知识, 从而 "知道 "均衡并测试其行为的最优性。相形之下，**推论deductive**（或者说，Binmore所说的**演绎式eductive**）解释，将一个游戏孤立地看成是一个 "一次性的 "事件，并试图推断出理性对结果的限制；它假设每个博弈者仅从理性原则推断出其他博弈者的行为方式。我们试图避免博弈论中经常出现的两种解释之间的混淆。



#### 1.6	Bounded Rationality 有限理性

当在现实中谈论博弈的时候，会注意个体之间的能力的不对称。这些在生活中非常关键的差异，在目前的博弈论中是缺失的。
为了说明这一事实，考虑国际象棋。棋手们可能在对合法棋步的认识和分析能力上存在差异。然而，当用博弈论对国际象棋进行建模时，假设棋手对游戏规则的知识是完美的，分析能力是理想的。我们在第2章和第6章中证明的结果（定理22.2和99.2）意味着，对于 "理性 "的棋手来说，国际象棋是一个 平庸博弈：存在一种可以用来 "解决 "这个游戏的算法。这个算法定义了一对策略，每一个棋手都有一对策略，它导致了一个 "平衡 "的结果，具有这样的属性，即一个遵循他的策略的棋手可以肯定，无论对方使用什么策略，结果至少和平衡结果一样好。这种策略的存在表明，国际象棋是没有意思的，因为它只有一种可能的结果。尽管如此，国际象棋仍然是一个非常受欢迎和有趣的游戏。它的均衡结果还有待计算；目前还无法用算法来计算。比如说，即使有一天白棋被证明有一个获胜的策略，人类也不可能执行这个策略。因此，虽然抽象的国际象棋模型可以让我们推导出一个重要的事实，但同时它也忽略了决定实际下棋结果的最重要的因素：棋手的 "能力"。
对不同的棋手在能力和对局势的认知上的不对称性进行建模，是未来研究的一个引人入胜的挑战，而 "**有限理性**"的模型已经开始解决这个问题。



#### 1.7	Terminology and Notation  术语 标记

本书使用 deductive reasoning 演绎推理. 

函数$f$ 是 **凹函数 concave** :  if $f\left(\alpha x+(1-\alpha) x^{\prime}\right) \geq \alpha f(x)+(1-\alpha) f\left(x^{\prime}\right)$ for all $x \in \mathbb{R}$ , all $x^{\prime} \in \mathbb{R},$ and all $\alpha \in[0,1]$  ;  
$\arg \max _{x \in X} f(x)$ 表示函数 $f: X \rightarrow \mathbb{R}$ 的最大值集合;   
对任何 $Y \subseteq X$ , 用 $f(Y)$ 表示集合 $\{f(x): x \in Y\}$  

$N$ :  玩家集合.   

- 将某个变量的值的集合(每个玩家都对应一个)作为一个**组合profile** : $$x = \left(x_{i}\right)_{i \in N}$$  
- 为了简单, 如果明确有$i \in N$,  组合简单记为 $\left(x_{i}\right) $ .   
- $x_{-i}$表示除玩家$i$以外的所有人的组合.   
- 给定列表 $$x_{-i} = \left(x_{j}\right)_{j \in N \backslash\{i\}}$$  和元素  $$x_{i}$$ , 可以用 $$\left(x_{-i}, x_{i}\right)$$ 表示组合 $$\left(x_{i}\right)_{i \in N}$$  
- 若对每个 $i \in N$ ,  $X_{i}$ 是一个集合, 则可以用 $X_{-i}$ 表示集合 $\times_{j \in N \backslash\{i\}} X_{j}$

对于集合$A$ 上的**二元关系 binary relation** $\succsim$ :  

- if $a \succsim b$ or $b \succsim a$ for every $a \in A$ and $b \in A$ , 则是 **完备的complete**
- if $a \succsim a$ for every $a \in A$ , 则是 **自反的reflexive** 
- if $a \succsim c$ whenever $a \succsim b$ and $b \succsim c$ ,  则是 **传递的transitive**

偏好关系是 complete reflexive transitive 的二元关系.  

- if $a \succsim b$ , not $b \succsim a$ , 记为 $a \succ b$ 
- if $a \succsim b$  and $b \succsim a$ ,  记为 $a \sim b$

集合$A$ 上的偏好关系  $\succsim$  是**连续的continuous** :  if $a \succsim b$ whenever there are sequences $$\left(a^{k}\right)_{k}$$ and $$\left(b^{k}\right)_{k}$$  in $A$ that converge to $a$ and $b$ respectively for which $$a^{k} \succsim b^{k}$$ for all $k$  .   
A preference relation $\succsim$ on $$\mathbb{R}^{n}$$ is **quasi-concave 拟凹的** if for every $b \in \mathbb{R}^{n}$ the set $$\left\{a \in \mathbb{R}^{n}: a \succsim b\right\}$$ is convex; it is **strictly quasi-concave 严格拟凹的** if every such set is strictly convex.



$|X|$ : 集合元素的个数.       
$X$ 的**分割partition** 是$X$的 **非连通子集disjoint subsets** 的一个集合. 非连通子集的和为 $X$   
Let $N$ be a finite set and let $X \subseteq \mathbb{R}^{N}$ be a set. Then $x \in X$ is **帕累托有效 Pareto efficient** if there is no $y \in X$ for which $y_{i}>x_{i}$ for all $i \in N ; x \in X$ is **strongly Pareto efficient** if there is no $y \in X$ for which $y_{i} \geq x_{i}$ for all $i \in N$ and $y_{i}>x_{i}$ for some $i \in N$. 

一个有限(或可数)集合$X$ 上的 **概率测度probability measure** $\mu$  是一个可加函数.  associates a nonnegative real number with every subset of $X$  (that is, $\mu(B \cup C)=\mu(B)+\mu(C)$   whenever  $B$  and  $C$ are disjoint) and satisfies $\mu(X)=1 .$ 



## Strategic Games 策略博弈

在这一部分中，研究一种被称为策略博弈的策略互动模型，或者用冯-诺依曼的术语来说，是一种 "**通常形式的博弈 game in normal form**"。这个模型为每个玩家指定了一组可能的行动集合，并在可能的行动集合上的偏好顺序。



### 2	Nash Equilibrium 纳什均衡

纳什均衡是博弈论中最基本的概念之一



#### 2.1	Strategic Games 策略博弈

##### 2.1.1	Definition

策略博弈是一种相互作用的决策模型，在这个模型中，每个决策者都会仅仅选择一次自己的行动计划，而且这些选择是同时进行的。 即一次性给出策略就完事了.

我们称一个行动组合$a= (a_j)_{j\in N}$为结果(outcome),并用$A$表示结果集合$\times_{j \in N} A_{j}$ 

这里要求将每个参与人$i$的偏好定义在$A$ 而不是$A_i$上,这是将策略博弈从决策向题中区分出来的特征所在,即每个
参与人不仅要考虑自己的行动,还要考虑其他参与人采取的行动。



DEFINITION 11.1 A strategic game consists of
- a finite set $N$ (the set of players)
- for each player $i \in N$ a nonempty set $A_{i}$ (the set of actions available to player $i)$ 
- for each player $i \in N$ a preference relation $\succsim_{i}$ on $A=\times_{j \in N} A_{j}$ (the preference relation of player $i$ ).

If the set $A_{i}$ of actions of every player $i$ is finite then the game is **finite有限的**.



这个模型过于抽象, 在具体问题上必须更加具体化才能得到好的结果. 

在某些情况下，行为者的**偏好preferences** 最自然地不是根据**行动组合action profiles**而是根据其**结果consequences**来定义。例如，在建立寡头垄断的模型时，我们可以把参与者的集合看成是一组公司，把每家公司的行动集合看成是价格集合；但我们可能希望建立模型的假设是，每家公司只关心自己的利润，而不关心产生该利润的价格组合。  
为此,  引入**结果函数** :   $g: A \rightarrow C $ 以及  **结果consequences集合**$C$ 上的偏好关系组合 $$\left(\succsim_{i}^{*}\right)$$ ;   
那么策略博弈中, 每个玩家的偏好关系可以定义为:  $$a \succsim_{i} b$$ if and only if $$g(a) \succsim_{i}^{*} g(b)$$ 

有时，我们希望对一种情形建模，即行动组合的结果受到外来的一个**随机变量**的影响, 而玩家们事先并不了解随机变量是怎么实现的. 一个动作曲线的后果会受到一个外生随机变量的影响，而这个外生随机变量在玩家采取行动之前是不知道的。   
也可以通过策略博弈来建模.  引入**概率空间 probability space** $\Omega$ , 随机结果函数: $g: A \times \Omega \rightarrow C$ , 该函数的输出,   $g(a, \omega)$ 是结果consequence .   一个行动组合相当于造成了结果集合$C$ 上的一个**随机lottery**. 对每个玩家的偏好关系$$\succsim_{i}^{*}$$, 必须在所有随机的集合上具体指定.  玩家 $i$ 的偏好关系并定义为:  $$a \succsim_{i} b$$ if and only if the lottery over $C$ induced by $g(a, \cdot)$ is at least as good according to $$\succsim_{i}^{*}$$ as the lottery induced by $g(b, \cdot)$ .



在广泛的情况下，策略博弈中玩家$i$的偏好关系$\succsim_{i}$可以用一个**报酬函数(效用函数)payoff function** $u_{i}: A \rightarrow \mathbb{R}$  来表示。只要 $a \succsim_{i}$ b , 就有 $u_{i}(a) \geq u_{i}(b)$  .  通常我们**通过报酬函数来表示玩家的偏好关系**。在这种情况下，我们用  $\left\langle N,\left(A_{i}\right),\left(u_{i}\right)\right\rangle$ 而不是 $\left\langle N,\left(A_{i}\right),\left(\succsim_{i}\right)\right\rangle$ .   用策略结果来表示策略. 





<img src="/img/2020-04-18-Game.assets/image-20200503002729772.png" alt="image-20200503002729772" style="zoom:50%;" />

两个玩家 玩家1,玩家2的有限策略博弈可以用图13.1中的表格来方便地描述。一个玩家的行动用行来表示，另一个玩家的行动用列来表示。 表格里面的两个数分别是两个玩家的payoff 报酬.  具体见下面例子.



##### 2.1.2	Comments on Interpretation 关于如何解释

策略博弈的一种常见解释是，它是一个**事件只发生一次**的模型；每个玩家都知道博弈的细节和所有玩家都是 "理性的"，玩家同时独立地选择自己的行动。在这种解释下，每个人在选择自己的行动时，并不知道其他人做的选择；没有任何信息（除了模型的基本元素）可以作为对其他玩家行为的预期的基础。

本书采用了另一种解释，即玩家可以根据过去的博弈获取的信息形成对其他人的行为的预期。当一个game被连续玩了很多次, 每次play之间没有联系, 才可以用 策略博弈来建模.  即, 一个人玩了很多次，必须只关注他的瞬时回报，而忽略了他当前的行为对其他玩家未来行为的影响。因此，在这种解释中，只有在互动的发生之间缺乏跨时空的策略联系的情况下，才适合将一个情境建模为策略博弈。(第8章讨论的重复博弈模型涉及的是一系列的策略互动，在这些互动中确实存在着这种时间上的联系)。   即不考虑当前行为会被其他人记住学习.





#### 2.2	Nash Equilibrium

博弈论中最常用的解的概念是纳什均衡。这个概念抓住了策略博弈中的**稳态 steady state**，在这个状态下，每个博弈者都对其他博弈者的行为抱有正确的预期，并理性地采取行动。它并不试图研究达到稳定状态的过程。

DEFINITION 14.1 A Nash equilibrium of a strategic game $$\left\langle N,\left(A_{i}\right)   \left(\succsim_{i}\right)\right\rangle$$ is a **profile** $$a^{*} \in A$$ of actions with the property that for every player $i \in N$ we have

$$
\left(a_{-i}^{*}, a_{i}^{*}\right) \succsim_{i}\left(a_{-i}^{*}, a_{i}\right) \text { for all } a_{i} \in A_{i}
$$

因此，若 $$a^{*}$$是纳什均衡，必须是没有一个玩家$i$的行动产生的结果比他选择$a^∗_i$时产生的结果更好，当其他玩家$j$选择了他的均衡行动$a^∗_j$。简而言之，考虑到其他玩家的行动，没有一个玩家可以偏离纳什均衡来获利。

下面是对定义的重新表述。对于任何  $a_{-i} \in A_{-i}$ 定义 $B_{i}\left(a_{-i}\right)$ 为玩家 $i$ 在给定 $a_{-i}$ 条件下的最优行动集合:

$$
B_{i}\left(a_{-i}\right)=\left\{a_{i} \in A_{i}:\left(a_{-i}, a_{i}\right) \succsim_{i}\left(a_{-i}, a_{i}^{\prime}\right) \text { for all } a_{i}^{\prime} \in A_{i}\right\}
$$

称集合值函数 $B_{i}$ 为玩家$i$ 的 **最佳响应函数best-response function** .   
则纳什均衡作为一个行动组合满足 $$a^{*}$$ : 

$$
a_{i}^{*} \in B_{i}\left(a_{-i}^{*}\right) \text { for all } i \in N
$$

该定义的另一种表述方式指出了一种寻找纳什均衡的方法(不一定有效):  首先计算出每个玩家的最佳响应函数, 然后再寻找一个行动组合  $$a^{*}$$ 使得 $$a_{i}^{*} \in B_{i}\left(a_{-i}^{*}\right)$$ for all $i \in N$   
若函数 $B_{i}$ 是单值的singleton-valued, 则第二步就是求解有 $|N|$ 个未知 $\left(a_{i}^{*}\right)_{i \in N}$ 的 $|N|$ 个方程. 







#### 2.3	Examples

先看一些经典例子.  都是只有两个参与者, 两个动作



##### Example 15.3 Bach or Stravinsky? (BoS)

两个人想一起出去听一场巴赫或斯特拉文斯基的音乐会。他们最关心的是一起出去玩，但一个人更喜欢巴赫，另一个人更喜欢斯特拉文斯基。 payoff function 报酬函数 表示为: 

<img src="/img/2020-04-18-Game.assets/image-20200502173936136.png" alt="image-20200502173936136" style="zoom:50%;" />

BoS模拟的是一个玩家希望协调他们的行为，但又有利益冲突的情况。这个博弈有两个纳什均衡，分别是（巴赫，巴赫）和（斯特拉文斯基，巴赫）。(巴赫，巴赫)和(斯特拉文斯基，斯特拉文斯基)。也就是说，有两个稳定状态：一个是两个玩家总是选择巴赫，一个是两个玩家总是选择斯特拉文斯基。



##### Example 16.1  A coordination game 合作博弈

就像在BoS中，两个人希望一起出去玩，但在这种情况下，他们就更理想的演唱会达成一致。图16.2给出了一个符合这种情况的博弈。
和BoS一样，这个博弈也有两个纳什均衡。(Mozart，Mozart)和(Mahler，Mahler)。与BoS不同的是，博弈者对达到其中一个均衡状态有共同的利益，即(Mozart,Mozart)；然而，纳什均衡的概念并不排除有一个稳定状态(Mahler,Mahler)，在这个稳定状态果较差。

<img src="/img/2020-04-18-Game.assets/image-20200502195324831.png" alt="image-20200502195324831" style="zoom: 33%;" />

##### Example 16.2 (The Prisoner’s Dilemma)   囚徒困境

两名犯罪嫌疑人被分别关进不同的牢房。如果他们都认罪，每人将被判处三年监禁。如果他们中只有一人认罪，他将被释放，并作为证人对另一人不利，后者将被判处四年徒刑。如果两人都不认罪，都会被认定为轻罪，都会被判处一年有期徒刑。选择一个方便的payoff 报酬表示偏好，我们得到了图17.1中的博弈。
在这个博弈中，合作是有收益的--对博弈者来说，最好的结果是双方都不认罪--但每个博弈者都有成为 "自由人 "的动机。无论一个玩家做什么，另一个玩家都会选择 "坦白 "而不是 "不坦白"，所以这个博弈有一个独特的纳什均衡（坦白，坦白）。

<img src="/img/2020-04-18-Game.assets/image-20200502195756402.png" alt="image-20200502195756402" style="zoom: 33%;" />



##### Example 16.3 (Hawk–Dove)  老鹰鸽子

两种动物在争夺一些猎物。各自可以像鸽子一样，也可以像鹰一样。对每一种动物来说，最好的结果是它的行为像鹰，而另一种动物的行为像鸽子；最坏的结果是两种动物的行为都像鹰。这个博弈有两个纳什均衡，（鸽子，鹰）和（鹰，鸽子），分别对应着两个不同的约定。

<img src="/img/2020-04-18-Game.assets/image-20200502200640483.png" alt="image-20200502200640483" style="zoom: 33%;" />

##### Example 17.1 (Matching Pennies)  猜硬币

两个人各自选择正面或反面。如果选择不同，第1人付给第2人一元钱；如果选择相同，第2人付给第1人一元钱。每个人只关心自己得到的钱的多少。一个模拟这种情况的博弈如图17.3所示。这样的游戏，在这种游戏中，参与者的利益是截然相反的，这种游戏被称为 "严格竞争 strictly competitive"。**这个博弈没有纳什均衡**。

<img src="/img/2020-04-18-Game.assets/image-20200502201222686.png" alt="image-20200502201222686" style="zoom: 33%;" />

策略博弈的概念包含了比前五个例子中描述的情况要复杂得多的情况。以下是已被广泛研究过的三个博弈的代表：拍卖、时间博弈和位置博弈。

##### Example 18.1 (An auction)  拍卖

n个人盲拍(sealed-bid) auction, 同时出价, 标的物被给予出价最高的买家中id最低的那位.  这n个人集合$$\{1,2,\dots, n \}$$ ,  每个人对标的物的估值为$v_i$ , 且有  $v_1>v_2>\dots>v_n>0$ . 

在**第一价格first price 拍卖**中，获胜者的付款是他的出价。

习题18.2 将第一价格拍卖作为一个策略博弈，并分析其纳什均衡。特别是，表明在所有均衡状态下，玩家1获得了目标。

在**第二价格 second price**拍卖中，获胜者的付款是由没有获胜的选手提交的最高价（这样，如果只有一个选手提交最高价，那么支付的价格就是第二高价）。

练习18.3 证明在第二价格拍卖中，任何玩家i的出价vi是一个弱主导行为：玩家i出价vi时的报酬至少和出价其他值时的报酬一样高，而不考虑其他玩家的行为。证明尽管如此，仍有（"低效"）均衡状态，其中赢家不是玩家1。



##### Example 18.4 (A war of attrition) 消耗战

两个玩家在一个物体上发生了争夺，对玩家i来说，物体的价值是vi > 0。时间被建模为一个连续的变量，从0开始到无穷。每个玩家选择何时让步给另一个玩家；如果第一个让步的玩家在时间t的时候让步，那么另一个玩家在那个时候获得该物体。如果两个玩家同时让步，则物品被平分，玩家i得到的回报为vi/2。时间是有价值的：在第一个让步之前，每个玩家每损失一个单位时间的回报。

练习18.5 把这种情况表述为一个策略博弈，并表明在所有纳什均衡状态下，其中一方立即认输。



##### Example 18.6 (A location game) 位置游戏

每一个人都会选择是否成为政治候选人，如果是的话，则选择哪个位置。
有一个公民的连续体，每个人都有一个最喜欢的位置；位置的分布由[0，1]上的密度函数f给出，对于所有x∈[0，1]，f（x）>0。一个候选人如果位置比任何其他候选人的位置更接近一个公民, 则可以赢取该公民的选票；如果有k个候选人选择了相同的位置，那么每个人都能得到该位置选票的1/k。在竞争中，得票最多的候选人为获胜者。每个人宁愿成为唯一的胜出者，也不愿意与第一名并列，宁愿与第一名并列，也不愿意出局，宁愿不参加比赛，也不愿意输掉比赛。

习题19.1 将此情境设为策略博弈，找到当n=2时的纳什均衡集，并证明当n=3时不存在纳什均衡。



#### 2.4	Existence of a Nash Equilibrium 纳什均衡的存在性

不是每个strategic game 都有 Nash equilibrium. 



Proposition 20.3 The strategic game $$\left\langle N,\left(A_{i}\right),\left(\succsim_{i}\right)\right\rangle$$ has a Nash equilibrium if for all $i \in N$ 

- the set $$A_{i}$$ of actions of player i is a nonempty compact convex subset of a Euclidian space

and the preference relation $$\succsim_{i}$$ is

- continuous
- quasi-concave on $$A_{i}$$



注意，这个结果保证一个策略博弈在满足一定条件下至少有一个纳什均衡；正如我们所看到的，一个博弈可以有一个以上的均衡。(我们没有讨论一个博弈有唯一的纳什均衡的条件)。还注意到定理20.3并不适用于任何一个博弈中的玩家有无限多行动的博弈，因为这样的博弈违反了每个玩家的行动集是凸的条件。



#### 2.5	Strictly Competitive Games 严格竞争博弈, 零和博弈



### 3	Mixed, Correlated, and Evolutionary Equilibrium 混合,相关与演进均衡

#### 3.1 Mixed Strategy Nash Equilibrium  混合策略纳什均衡

##### 3.1.1 Definitions

混合策略纳什均衡的概念是为了模拟一个稳定状态的博弈，在这个博弈中，参与者的选择不是确定性的，而是受概率规则调节。 

之前将策略博弈定义为三元组$\langle N,  \left(A_{i}\right),\left(\succsim_{i}\right) \rangle$ ,  每个人i的偏好关系 $\succsim_{i}$被定义在行动组集合$A=\times_{i \in N} A_{i}$上. 本章允许玩家的选择是非确定性的, 需要增加在不确定性上的偏好.  遵从现代博弈论的习惯, 假定偏好关系满足assumptions of von Neumann and Morgenstern, 所以偏好可以表示为$u_{i}: A \rightarrow \mathbb{R}$ 函数的期望值.   本章关于策略相互作用的模型是 $\left\langle N,\left(A_{i}\right),\left(u_{i}\right)\right\rangle$ .

 令 $G=\left\langle N,\left(A_{i}\right),\left(u_{i}\right)\right\rangle$ 是一个 **strategic game**. 我们用 $\Delta\left(A_{i}\right)$ 表示 $A_{i}$ 上的概率分布集合,  $\Delta\left(A_{i}\right)$ 的一个元素为 玩家$i$的一个 **混合策略mixed strategy** ; 假定每个玩家的混合策略是独立随机化的independent randomizations. 为明确起见, 我们称 $A_{i}$ 的一个元素为**纯策略pure strategy**. 对有限集$X$ and $\delta \in \Delta(X)$ , 用$\delta(x)$ 表示 $\delta$ 赋予 $x \in X$ 的概率, 将 $\delta$ 的**支撑集support** 定义为 $x \in X$ 的集合, 其中 $\delta(x)>0 .$ 混合策略的一个组合 $$\left(\alpha_{j}\right)_{j \in N}$$ 产生了 $A$ 上的一个概率分布; 例如, 如果每个 $A_{j}$ 是有限集, 则在独立随机化条件下, 行动组合 $a=\left(a_{j}\right)_{j \in N}$ 的概率是 $$\Pi_{j \in N} \alpha_{j}\left(a_{j}\right)$$,  所以玩家 $i$对 $$\left(\alpha_{j}\right)_{j \in N}$$的估值为$$\sum_{a \in A}\left(\Pi_{j \in N} \alpha_{j}\left(a_{j}\right)\right) u_{i}(a)$$ . 



**DEFINITION 32.1** The **mixed extension** of the strategic game $$\langle N,\left(A_{i}\right) 
\left(u_{i}\right) \rangle$$ is the strategic game $\left\langle N,\left(\Delta\left(A_{i}\right)\right),\left(U_{i}\right)\right\rangle$ in which $\Delta\left(A_{i}\right)$ is the set of probability distributions over $A_{i},$ and $U_{i}: \times_{j \in N} \Delta\left(A_{j}\right) \rightarrow \mathbb{R}$ assigns to each $\alpha \in \times_{j \in N} \Delta\left(A_{j}\right)$ the expected value under $u_{i}$ of the lottery over $A$ that is induced by $\alpha$ (so that  $U_{i}(\alpha)=\sum_{a \in A}\left(\Pi_{j \in N} \alpha_{j}\left(a_{j}\right)\right) u_{i}(a)$ if $A$ is finite).

Note that each function $U_{i}$ is multilinear. That is, for any mixed strategy profile $\alpha,$ any mixed strategies $\beta_{i}$ and $\gamma_{i}$ of player $i,$ and any number $\lambda \in[0,1],$ we have $U_{i}\left(\alpha_{-i}, \lambda \beta_{i}+(1-\lambda) \gamma_{i}\right)=\lambda U_{i}\left(\alpha_{-i}, \beta_{i}\right)+ (1-\lambda) U_{i}\left(\alpha_{-i}, \gamma_{i}\right) $. Note also that when each $A_{i}$ is finite we have 
$$
U_{i}(\alpha)=\sum_{a_{i} \in A_{i}} \alpha_{i}\left(a_{i}\right) U_{i}\left(\alpha_{-i}, e\left(a_{i}\right)\right)
$$
for any mixed strategy profile $\alpha$, where $e\left(a_{i}\right)$ is the degenerate mixed strategy of player $i$ that attaches probability one to $a_{i} \in A_{i}$. 

**DEFINITION 32.3** A **mixed strategy Nash equilibrium of a strategic game** is a Nash equilibrium of its mixed extension.

Suppose that $$\alpha^{*} \in \times_{j \in N} \Delta\left(A_{j}\right)$$ is a mixed strategy Nash equilibrium of $$G=\left\langle N,\left(A_{i}\right),\left(u_{i}\right)\right\rangle$$ in which each player $$i$$ 's mixed strategy $$\alpha_{i}^{*}$$ is degenerate in the sense that it assigns probability one to a single member - say $$a_{i}^{*}-$$ of $$A_{i} .$$ Then, since $$A_{i}$$ can be identified with a subset of $$\Delta\left(A_{i}\right),$$ the action profile $$a^{*}$$ is a Nash equilibrium of $$G .$$ Conversely, suppose that $$a^{*}$$ is a Nash equilibrium of $$G .$$ Then by the linearity of $$U_{i}$$ in $$\alpha_{i}$$ no probability distribution over actions in $$A_{i}$$ yields player $$i$$ a payoff higher than that generated by $$e\left(a_{i}^{*}\right),$$ and thus the profile $$\left(e\left(a_{i}^{*}\right)\right)$$ is a mixed strategy Nash equilibrium of $$G$$ .

我们刚刚论证了一个策略博弈的纳什均衡集是其混合策略纳什均衡集的子集。在第二章中我们看到，有些博弈的纳什均衡集是空的。也有混合策略纳什均衡集合为空的博弈。然而，每个博弈中的每个玩家都有有限多行动的博弈至少有一个混合策略纳什均衡。

**Proposition 33.1** Every finite strategic game has a mixed strategy Nash equilibrium.



##### 3.1.2 	Examples

**EXAMPLE 34.1(BoS)**   与第二章的例子一样, 不过这里从混合策略均衡的角度, 解释为von Neumann-Morgenstern(VNM) utilities. 



As we noted previously this game has two (pure) Nash equilibria, $(B, B)$ and $(S, S),$ where $B=B a c h$ and $S=$Stravinsky. Suppose that $\left(\alpha_{1}, \alpha_{2}\right)$ is a mixed strategy Nash equilibrium. If $\alpha_{1}(B)$ is zero or one, we obtain the two pure Nash equilibria. If $0<\alpha_{1}(B)<1$ then, given $\alpha_{2}$ by Lemma 33.2 player 1 's actions $B$ and $S$ must yield the same payoff, so that we must have $2 \alpha_{2}(B)=\alpha_{2}(S)$ and thus $\alpha_{2}(B)=\frac{1}{3} .$ since $0<$ $\alpha_{2}(B)<1$ it follows from the same result that player 2 's actions $B$ and
$S$ must yield the same payoff, so that $\alpha_{1}(B)=2 \alpha_{1}(S),$ or $\alpha_{1}(B)=\frac{2}{3}$ Thus the only nondegenerate mixed strategy Nash equilibrium of the game is $\left(\left(\frac{2}{3}, \frac{1}{3}\right),\left(\frac{1}{3}, \frac{2}{3}\right)\right)$
It is illuminating to construct the players' best response functions in the mixed extension of this game. If $0 \leq \alpha_{2}(B)<\frac{1}{3}$ then player 1 's






R. Thus our basic model of strategic interaction in this chapter is a triple $\left\langle N,\left(A_{i}\right),\left(u_{i}\right)\right\rangle$ that differs from a strategic game as we previously defined it in that $u_{i}: A \rightarrow \mathbb{R}$ for each $i \in N$ is a function whose expected value represents player $i$ 's preferences over the set of lotteries on $A$. Nevertheless, we refer to the model simply as a strategic game.







## Extensive Games with Perfect Information 完全信息扩展博弈

**扩展extensive**博弈明确描述了 玩家在战略情况下遇到的决策问题的顺序结构。该模型使我们能够研究每个玩家不仅在博弈开始时可以考虑他的行动计划，而且在他必须做出决策的任何时间点也可以考虑他的行动计划。



### 6	Extensive Games with Perfect Information 完全信息扩展博弈

#### 6.1	Extensive Games with Perfect Information

##### 6.1.1	Definition

**扩展博弈**是对战略情境中玩家所遇到的决策问题的**顺序结构**的详细描述。在这样的博弈中，如果每个博弈者在做出任何决策时，**都能完美地了解到之前发生的所有事件**，那么在这样的博弈中就有完美的信息。为了简单起见，我们最初将注意力限制在没有两个玩家同时做出决策的博弈中，并且所有相关的行动都是由玩家做出的（没有随机性介入）。我们在第6.3节中取消了这两个限制）。

**Definition 89.1** An **extensive game with perfect information 完全信息扩展博弈** has the following components.

- A finite set $$N($$ the set of **players**)   **参与者集合**
- A set $$H$$ of **sequences** (finite or infinite) that satisfies the following three properties.  **动作序列集合**
  - The empty sequence $$\varnothing$$ is a member of $$H$$  **空**
  - If $$\left(a^{k}\right)_{k=1, \ldots, K} \in H$$ (where $$K$$ may be infinite) and $$L<K$$ then $$\left(a^{k}\right)_{k=1, \ldots, L} \in H$$  **前序**
  - If an infinite sequence $$\left(a^{k}\right)_{k=1}^{\infty}$$ satisfies $$\left(a^{k}\right)_{k=1, \ldots, L} \in H$$ for every positive integer $$L$$ then $$\left(a^{k}\right)_{k=1}^{\infty} \in H$$     **无限长度**   
    (Each member of $$H$$ is a **history 动作历史**; each component of a history is an **action** taken by a player.)  A history $$\left(a^{k}\right)_{k=1, \ldots, K} \in H$$ is **terminal** if it is infinite or if there is no $$a^{K+1}$$ such that  $$\left(a^{k}\right)_{k=1, \ldots, K+1} \in H$$ .  The **set of terminal histories** is denoted $$Z$$ .
- A function $$P$$ that assigns to each nonterminal history (each member of $$H \backslash Z$$ ) a member of $$N$$ .($$P$$  is the **player function**, $$P(h)$$ being the player who takes an action after the history $$h$$.)  **玩家函数**
- For each player $$i \in N$$ a preference relation $$\succsim_{i}$$ on $$Z$$ (the **preference relation** of player $$i$$ )  **偏好关系**

当不要确定玩家偏好的时候, 用三元组表示. Sometimes it is convenient to specify the structure of an extensive game without specifying the players' preferences. We refer to a triple 三元组 $$\langle N, H, P\rangle$$ whose components satisfy the first three conditions in the definition as an **extensive game form with perfect information**.

若历史有限, 则成为博弈**有限**. If the set $$H$$ of possible histories is finite then the game is **finite**. If the longest history is finite then the game has a **finite horizon**. Let $$h$$ be a history of length $$k ;$$ we denote by $$(h, a)$$ the history of length $$k+1$$ consisting of $$h$$ followed by $$a$$

After any nonterminal history $$h$$ player $$P(h)$$ chooses an action from the set   **可用动作集合**

$$
A(h)=\{a:(h, a) \in H\}
$$

初始状态.  The empty history is the **starting point** of the game; we sometimes refer to it as the **initial history**. At this point player $$P(\varnothing)$$ chooses a member of $$A(\varnothing) .$$ For each possible choice $$a^{0}$$ from this set player $$P\left(a^{0}\right)$$ subsequently chooses a member of the set $$A\left(a^{0}\right) ;$$ this choice determines the next player to move, and so on.  







## EXTENSIVE GAMES WITH IMPERFECT INFORMATION

### 11.1	Extensive Games with Imperfect Information



#### 11.1.2	Definitions

下面的定义是对具有完美信息的扩展博弈（89.1）的推广，允许玩家在采取行动时**对过去的事件并不完全地了解**。它还允许外部的不确定性：有些行为可能是由 "**偶然性 chance** "决定的（见6.3.1节）。它并不包含我们在第6.3节中讨论过的另一个扩展博弈的定义，即在这个定义中，不止一个人可以在任何历史事件之后行动（见例202.1之后的讨论）。

**DEFINITION 200.1**  An **extensive game** has the following components.

- A finite set $$N($$ the set of **players**)   参与者集合
- A set $$H$$ of **sequences** (finite or infinite) that satisfies the following three properties.  动作序列集合
  - The empty sequence $$\varnothing$$ is a member of $$H$$
  - If $$\left(a^{k}\right)_{k=1, \ldots, K} \in H$$ (where $$K$$ may be infinite) and $$L<K$$ then $$\left(a^{k}\right)_{k=1, \ldots, L} \in H$$
  - If an infinite sequence $$\left(a^{k}\right)_{k=1}^{\infty}$$ satisfies $$\left(a^{k}\right)_{k=1, \ldots, L} \in H$$ for every positive integer $$L$$ then $$\left(a^{k}\right)_{k=1}^{\infty} \in H$$    
    (Each member of $$H$$ is a **history**; each component of a history is an **action** taken by a player.) A history $$\left(a^{k}\right)_{k=1, \ldots, K} \in H$$ is terminal if it is infinite or if there is no $$a^{K+1}$$ such that  $$\left(a^{k}\right)_{k=1, \ldots, K+1} \in H$$ .  The set of actions available after the nonterminal history $$h$$ is denoted $$A(h)=\{a:(h, a) \in H\}$$ and the set of terminal histories is denoted $$Z$$ . 
- A function $$P$$ that assigns to each nonterminal history (each member of $$H \backslash Z)$$ a member of $$N \cup\{c\} $$.($$P$$   is the **player function**,  $$P(h)$$ being the player who takes an action after the history $$h .$$ If $$P(h)=c$$ then **chance** determines the action taken after the history $$h .)$$
- 可以理解为强化学习里面$\pi$ 策略函数:  A function $$f_{c}$$ that associates with every history $$h$$ for which $$P(h)=c$$ a **probability measure** $$f_{c}(\cdot \vert h)$$ on $$A(h),$$ where each such probability measure is independent of every other such measure. $$(f_{c}(a \vert h)$$ is the probability that $a$ occurs after the history  $h$ )   
- For each player $$i \in N$$ a partition $$\mathcal{I}_{i}$$ of $$\{h \in H: P(h)=i\}$$ with the property that $$A(h)=A\left(h^{\prime}\right)$$ whenever $$h$$ and $$h^{\prime}$$ are in the same member of the partition 即对玩家来说不可分辨. For $$I_{i} \in \mathcal{I}_{i}$$ we denote by $$A\left(I_{i}\right)$$ the set $$A(h)$$ and by $$P\left(I_{i}\right)$$ the player $$P(h)$$ for any $$h \in I_{i}$$ . ($$\mathcal{I}_{i}$$ is the **information partition 信息分割** of player $$i ;$$ a set $$I_{i} \in \mathcal{I}_{i}$$ is an **information set 信息集合** of player $$i .$$ ) 
- 使用收益来反应策略偏好.  For each player $$i \in N$$ a preference relation $$\succsim_{i}$$ on lotteries over $$Z$$ (the **preference relation** of player $$i$$ ) that can be represented as the expected value of a payoff function defined on $$Z$$

We refer to a tuple $$\left\langle N, H, P, f_{c},\left(\mathcal{I}_{i}\right)_{i \in N}\right\rangle$$ (which excludes the players' preferences whose components satisfy the conditions in the definition as an **extensive game form**.

新加入信息集 Relative to the definition of an extensive game with perfect information and chance moves (see Section 6.3.1 ), the new element is the collection $$\left(\mathcal{I}_{i}\right)_{i \in N}$$ of **information partitions**. We interpret the histories in any given member of $$\mathcal{I}_{i}$$ to be **indistinguishable 不可分辨** to player $$i .$$ Thus the game models a situation in which after any history $$h \in I_{i} \in \mathcal{I}_{i}$$ player $$i$$ is informed that some history in $$I_{i}$$ has occurred but is not informed that the history $$h$$ has occurred. The condition that $$A(h)=A\left(h^{\prime}\right)$$ whenever $$h$$ and $$h^{\prime}$$ are in the same member of $$\mathcal{I}_{i}$$ captures the idea that if $$A(h) \neq A\left(h^{\prime}\right)$$ then player $$i$$ could deduce, when he faced $$A(h),$$ that the history was not $$h^{\prime},$$ contrary to our interpretation of $$\mathcal{I}_{i} .$$




























