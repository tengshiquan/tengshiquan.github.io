---
layout:     post
title:      Game Theory 笔记
subtitle:   Osborne的博弈论经典
date:       2020-04-18 12:00:00
author:     "tengshiquan"
header-img: "img/post-bg-dice.jpg"
catalog: true
tags:

    - AI
    - Game Theory

---





# An Introduction to Game Theory

"An Introduction to Game Theory"比"A Course in Game Theory" 那本书数学上简单的多

总体上的区别,   博弈中, 对具体问题都是具体建模, 力求精确地求纳什均衡的解. 





#### 总体结构

<img src="/img/2020-04-18-Game.assets/image-20200505013213150.png" alt="image-20200505013213150" style="zoom:50%;" />



### 1	引论

#### 1.1 何为博弈论？

博弈论旨在帮助找们理解决策者互动的情形。



#### 1.2 理性选择理论 The theory of rational choice

##### 1.2.1 Actions

##### 1.2.2 Preferences and payoff functions

如何描述决策者的**偏好preferences** 呢 ：  **收益函数 payoff function**

payoff function $u$ represents a decision-maker's preferences if, for any actions $a$ in $A$ and $b$ in $A$ ，
$u(a)>u(b)$ if and only if the decision-maker prefers $a$ to $b$.

这里所使用的决策者偏好从某种意义上来说，仅传递了**次序ordinal** 方面的信息。例如，它能告诉我们，决策者喜欢行动α 甚于行动b，但是它并不能告诉我们，和行动b 相比她究竟有多喜欢行动α ，或者她喜好a甚于b 的程度是否"多于"她喜好b 甚于c 的程度。因此，描述决策者偏好的盈利函数仅仅传递了次序的信息。

那么， 很自然想到能不能用数值函数把喜欢的程度表示出来呢 ?  例如，  $u(a)=0, u(b)=1, u(c)=100,$ 那么决策者喜欢 $c$ 远远胜过喜欢 $b$,而对于 $a$ 和 $b$ 之间的差别则不大。
结论是**不能**！！盈利函数并不包涵这些信息！我们从 $u(a)=$ $0, u(b)=1, u(c)=100$ 中得出的唯一结论是,决策者喜欢 $c$ 甚于 $b$ 更甚于 $a$ 。 如果用盈利函数 $v$ 来描述她的喜好,其中 $v(a)=0, v(b)=100, v(c)=101$, 这两个函数是一样的。或者说,任何满足 $w(a)<w(b)<w(c)$ 的其他函数 $w$ 也都是一样的。

从上述讨论中我们可以看到，决策者的偏好可出用各种不同的盈利函数来描述。



##### 1.2.3 The theory of rational choice  理性选择理论

在任何给定情况下，决策者根据自己的偏好好，从A 的可选子集中挑选出最好的方案。在允许存在多个同样吸引
人的最优方案的情况下，理性选择理论定义如下：
**依据决策者的偏好，其所选行动至少如其他可选的行动一样好。 the action chosen by a decision-maker is at least as good, according to her preferences, as every other available action.**

此理论是有其局限性的， 因为现实中很多时候，人们会冲动不理性。



## Part I:  Games with Perfect Information 完全信息博弈

### 2	Nash Equilibrium 纳什均衡：理论  

#### 2.1 Strategic games 策略型博弈 

概念: *players*, *actions* , *preferences* ,  
**action *profile***—the list of all the players’ actions    策略组合， 策略配置
*payoff functions* 收益函数

**DEFINITION 11.1** (*Strategic game with ordinal preferences*) A **strategic game** (with ordinal preferences) consists of

- a set of **players**  
- for each player, a set of **actions**
- for each player, **preferences** over the set of action profiles.


**ordinal preferences 序数偏好 的博弈， 即代表着，策略是纯策略。**

请记住，这些payoff只有**序数**意义 ***ordinal* significance**。例如，如果一个玩家对a、b和c这三个动作的payoff分别为1、2和10，我们唯一能得出的结论是，玩家更喜欢c而不是b，b更喜欢a；这些数字并不意味着玩家在c和b之间的偏好比他在a和b之间的偏好更强。

**模型中没有时间的概念。** 它的想法是，每个玩家选择自己的行动是一锤定音 once and for all的，而玩家们选择自己的行动是 "**同时 simultaneously**"进行的。 因此，策略游戏有时被称为 "同时行动游戏"。
然而，一个行动可能涉及到的活动会随着时间的推移而延长，并可能考虑了很多的突发事件。例如，一个行动可以规定，"如果X公司的股票跌到10美元以下，买入100股；否则，不要买入任何股票"。(因此，一个行动有时被称为 "**策略strategy**"。) 
模型中没有时间这一事实意味着，当把一个状况作为一个策略博弈case来分析时，我们可以从可能出现的复杂问题(如果允许玩家随着事件的发展而改变他的计划)中抽离出来：我们假设actions are chosen once and for all。 
如果按照 Strategic games 建模， 则各方的策略是一开始就定好了的。



#### 2.2 例：囚徒困境 the Prisoner’s Dilemma

最著名的策略博弈之一是 "囚徒困境" ;  收益矩阵

![image-20201201155437426](/img/2020-04-18-Game.assets/image-20201201155437426.png) 

从左边横着看过去的是P1的action， 从上面横着看下来的是P2的action

|        | 沉默 | *坦白* |
| :---: | :--: | :--: |
|  沉默  | 2,2  |  0,3   |
| *坦白* | 3,0  |  1,1   |

**囚徒困境主要适用于 合作是有益的, 但每个玩家都有投机取巧的动机.** 



##### 2.2.1 Working on a joint project  一起工作

大家都偏好偷懒，虽然厌恶项目失败，但更厌恶自己努力别人偷懒。 收益矩阵跟囚徒困境一样

你正在和朋友一起做一个联合项目。你们可以选择努力工作，也可以选择 "傻乐"。如果你的朋友努力工作，那么你更喜欢 "傻乎乎"（如果你也努力工作，项目的结果会更好，但对你来说，项目的价值增量并不值得额外的努力）。你更喜欢你们两个人都努力工作的结果，而不是你们两个人都傻乎乎的结果（在这种情况下，什么都没有完成），对你来说，最坏的结果是你努力工作，而你的朋友傻乎乎的结果（你讨厌被 "利用"）。如果你的朋友也有同样的偏好，那么你所面临的情况的游戏模型如图14.1所示，正如你所看到的，它与 "囚徒困境 "只是在行动的名称上有所不同. 



##### 2.2.2 Duopoly  双寡头垄断

在一个简单的二元垄断模型中，两家公司生产同样的产品。每家公司都希望获得尽可能高的利润。如果两家公司都选择高价，那么每家公司的利润为1000美元。如果一家公司选择高价，另一家公司选择低价，那么选择高价的公司没有顾客，亏损200美元，而选择低价的公司则赚取1200美元的利润（单位利润很低，但销量很高）。如果两家公司都选择Low，那么每家公司的利润为600美元。每个公司只关心自己的利润，所以我们可以用它所获得的利润来表示它的偏好，得出图14.2中的博弈。

|      |   High    |    Low    |
| :--: | :-------: | :-------: |
| High | 1000,1000 | -200,1200 |
| Low  | 1200,-200 |  600,600  |



##### 2.2.3 The arms race 军备竞赛

##### 2.2.4 Common property 公共财产



#### 2.3 例：欣赏巴赫音乐还是斯特拉文斯音乐？ BoS

这个例子中，玩家们一致认为合作比不合作好，但对最佳结果有不同意见。 例如两个政党制定政策.

这个在现实中比较多见， 大家意见不同，但目标统一后都会去执行。 

|              | *Bach* | *Stravinsky* |
| :---: | :--: | :--: |
| *Bach*       | 2,1    | 0,0          |
| *Stravinsky* | 0,0    | 1,2          |



#### 2.4 例：抛掷硬币打赌  Matching Pennies

两个人同时出示硬币的正面或反。如果出示相同的一面，那么P2 向P1 付1 美元， 否则P1向P2付。

这个例子是 纯粹的冲突性博弈.   **strictly competitive 严格竞争**

|      | Head | Tail |
| :--: | :--: | :--: |
| Head | 1,-1 | -1,1 |
| Tail | -1,1 | 1,-1 |



#### 2.5 例：猎鹿  the Stag Hunt

一群猎人中的每个人都有两个选择：可以继续专心致志地去追捕一只雄鹿，也可以去抓一只野兔。如果所有的猎人都去追赶雄鹿，那么他们就会抓到雄鹿并平分；如果任何一个猎人把精力放在抓野兔上，那么雄鹿就会逃跑，而野兔就属于叛变的猎人一个人。每一个猎人都喜欢分得部分雄鹿，而不是一只野兔。

2个猎人的情况

|      |  鹿  | 兔子 |
| :--: | :--: | :--: |
|  鹿  | 2,2  | 0,1  |
| 兔子 | 1,0  | 1,1  |





#### 2.6 纳什均衡

在策略型博弈中, 怎么选择行动呢? 

理性决策者理论, 假定每一个玩家选择最优的可行性行动。  

在博弈中, 一般来说,任何已知玩家的最优行动依赖于其他玩家的行动。因此,在 选择行动时,玩家必须考虑到其他玩家将采取的行动。  
这也就是说, 必须对其他玩家的行动形成一个“**信念 belief**”。 在什么样的基础上可以形成这样的信念呢？在本章和下面两章的分析中所隐含的假设是,每个玩家的信念来自于她过去参与博奕的经验,这个经验充分广泛,她知道她的对手将如何行动。没有一个人会告诉她有关对手将选择的行动,可是她凭借以往的博弈经验,对这些行动有所把握。  **经验 => 信念**  

虽然我们假设每个玩家有参与博弈的经验,我们还是要假设她会孤立地考虑每一次博弈。她不熟悉特定对手的习性,因而不会将自己的行动受缚于她的对手;也不会指望自己当前的行动会影响其他玩家将来的行动。

A ***Nash equilibrium*** is an **action profile** $a^∗$ with the property that no player $i$ can do better by choosing an action different from $a^∗_i$ , given that every other player $j$ adheres to $a^∗_j$ .

在理想化的情况下，在任何给定博弈中的玩家都是从一组人群中随机抽取的，**纳什均衡对应于稳定状态*steady state***。无论何时博弈开始时，行动配置是相同的纳什均衡$a^∗$，那么没有任何玩家有理由选择与他的分量$a^∗$不同的行动. 
换个说法，**纳什均衡体现了一个稳定的 "社会规范 social norm"**：如果其他人都遵守这个规范，没有人愿意偏离这个规范。

纳什均衡理论的第二部分玩家关于互相行动的信念是正确的一一意味着，两个玩家关于第三个玩家行为的信念是相同的。出于这个理由，有时候这个条件被称为要求玩家的"预期是一致的"。

我们希望应用纳什均衡理论的情况，通常并不恰好对应于**理想化模型**。例如，在某些情况下，玩家没有太多博弈经验;在另一些情况下，她们并不是孤立地看待每次博弈。
在任何给定的情况中，纳什均衡概念是否适用是需要判断的。**有些情况与理想化模型拟合得很差**，这可以通过别的考虑而得到缓解。例如，一个缺乏经验的玩家可能通过她们在其他场合的经验或从别的渠道对她们对手的可能行为得出结论。 最终，纳什均衡概念适用性的检验是，它是否能让我们洞察手头的问题。



符号表示：  
令 $a$ 是一个action配置,其中每个玩家 $i$ 的行动是 $a_{i}$ , 令 $a_{i}^{\prime}$ 是玩家 $i$ 的任意行动 （要么等于 $a_{i},$ 要么不等于 $a_{i}$ ) 。  
那么 $\left(a_{i}^{\prime}, a_{-i}\right)$ 表示这样的action配置,其中除 了玩家 $i$ 之外,每一个玩家 $j$ 选取由 $a$ 所确定的她的行动 $a_{j},$ 而玩家 $i$ 则选 $a_{i}^{\prime} $  （下标$-i$ 表示“除 $i$ 以外”)。  
这就是说 $\left(a_{i}^{\prime}, a_{-i}\right)$ : 除了 $i$ 之外,所有玩家坚持 $a,$ 而 $i$ 则“偏离”到 $a_{i}^{\prime}$ 。 (如果 $a_{i}^{\prime}=a_{i},$ 那 么当然有 $\left(a_{i}^{\prime}, a_{-i}\right)=\left(a_{i}^{\prime}, a_{-i}\right)=a$ ) 

例如,假设有三个玩家,那么 $\left(a_{2}^{\prime}, a_{-2}\right)$ : 玩家 1 和玩家 3 坚持采取 $a$ (玩家 1 选择 $a_{1},$ 3 选择 $a_{3}$ ) , 而玩家2 偏离到 $a_{2}^{\prime}$ 。 



**DEFINITION 21.1** (**Nash equilibrium of strategic game with ordinal preferences**) 

The action profile $$a^{*}$$ in a strategic game with ordinal preferences is a **Nash equilibrium** if, for every player $$i$$ and every action $$a_{i}$$ of player $$i$$ ,    $$a^{*}$$ is at least as good according to player $$i$$ 's preferences as the action profile $$\left(a_{i}, a_{-i}^{*}\right)$$ in which player $$i$$ chooses $$a_{i}$$ while every other player $$j$$ chooses $$a_{j}^{*} .$$ Equivalently, for every player $$i$$,  
$$u_{i}\left(a^{*}\right) \geq u_{i}\left(a_{i}, a_{-i}^{*}\right)$$ for every action $$a_{i}$$ of player $$i$$ ,  
where $$u_{i}$$ is a payoff function that represents player $$i$$ 's preferences.

**纳什均衡** :  $$u_{i}\left(a^{*}\right) \geq u_{i}\left(a_{i}, a_{-i}^{*}\right)$$

纳什均衡就是一个点(也可能是区域), 达到这个稳态后, 任何人自己私自偏离,都会有导致自己收益减少. 

**这个定义既不意味着一个策略博弈一定有纳什均衡，也不意味着它最多有一个纳什均衡。**   纯策略均衡可能不存在。



#### 2.7 纳什均衡例题

##### 2.7.1 Prisoner’s Dilemma

|        | 沉默 | *坦白* |
| :----: | :--: | :----: |
|  沉默  | 2,2  |  0,3   |
| *坦白* | 3,0  |  1,1   |

(*Fink*, *Fink*) is the unique Nash equilibrium.

(告密，沉默) 不满，因为当玩家 1 选择"告密"时，玩家 2 选择"告密"的盈利超过选择"玩默"的盈利,  (沉默,沉默)每个人都有动机偏离.   

当一个人选择坦白, 追求自己的高收益的时候, 需要一个人沉默, 而另外一个也会选择该前提下自己的高收益, 这时会造成前一个人高收益落空.





##### 2.7.2 BoS

two Nash equilibria: (*Bach*, *Bach*) and (*Stravinsky*, *Stravinsky*) 



##### 2.7.3 Matching Pennies

**该问题没有纳什均衡（没有纯策略的纳什均衡）**;  即每个玩家都用确定策略来玩,其中一个玩家如果输了,则改变其策略肯定能获利



##### 2.7.4 The Stag Hunt

two Nash equilibria: (*Stag*, *Stag*) and (*Hare*, *Hare*)



##### 2.7.6 A coordination game  协调博弈

|              |  *Bach*   | *Stravinsky* |
| :----------: | :-------: | :----------: |
|    *Bach*    | 2, 2 | 0,0 |
| *Stravinsky* |    0,0    |     1,1      |



##### 2.7.7 Provision of a public good  公共商品供给



##### 2.7.8 Strict and nonstrict equilibria 严格均衡

在我们迄今所研究的所有纳什均衡的博弈中，玩家的偏离导致的结果比均衡结果**更差**。然而，纳什均衡的定义(21.1)只要求**偏离的结果不比均衡结果好 no better, 不一定需要更差 worse**. 而且，事实上，有些博弈中的平衡状态是，鉴于其他博弈者的行动，玩家在他的平衡行动和其他的行动之间无动于衷。 

<B><mark>自己与对方都在均衡点，自己偏离了，收益不会下降的情况， 叫 非严格均衡 </mark></B>

考虑图31.1中的博弈。这个博弈有一个独特的纳什均衡，即（T，L）。(对于其他每一对行动，其中一个玩家的行动最好是改变他的行动)。当玩家2选择了L，就像他在这个均衡中一样，玩家1选择T或B是同样快乐的；如果他偏离了B，那么他的情况并不比他在均衡中的情况更糟。我们说，纳什均衡（T，L）不是一个**严格均衡*strict equilibrium***。

|      |  L   |  M   |  R   |
| :--: | :--: | :--: | :--: |
|  T   | 1,1  | 1,0  | 0,1  |
|  B   | 1,0  | 0,1  | 1,0  |

对于一个一般博弈，如果每个玩家的均衡行动都比该玩家其他的行动好，那么这个**均衡是严格**的。  
an action profile $$a^{*}$$ is a **strict Nash equilibrium**  if   
for every player $i$ we have $$u_{i}\left(a^{*}\right)>  u_{i}\left(a_{i}, a_{-i}^{*}\right)$$   
for every action $$a_{i} \neq a_{i}^{*}$$ of player $i$.     
看定义， 是在一个均衡点， 对方仍然采用均衡策略，自己偏移，然后收益下降，叫 严格均衡。

显然， 严格均衡点类似于山峰， 整个山脉但不一定只有一个， 但是平顶或者一条平线就不是严格均衡。



#### 2.8 best response function 最优反应函数,  最佳应对

##### 2.8.1 Definition

Precisely, we define the function $$B_{i}$$ by

$$
B_{i}\left(a_{-i}\right)=\left\{a_{i} \text { in } A_{i}: u_{i}\left(a_{i}, a_{-i}\right) \geq u_{i}\left(a_{i}^{\prime}, a_{-i}\right) \text { for all } a_{i}^{\prime} \text { in } A_{i}\right\}:
$$

any action in $$B_{i}\left(a_{-i}\right)$$ is at least as good for player $$i$$ as every other action of player $$i$$ when the other players' actions are given by $$a_{-i}$$. We call $$B_{i}$$ the **best response function** of player $$i$$ . 

该函数返回, **给定其他人动作的情况下, 玩家i能获得最大回报的那些动作的集合. 显然该函数与其他人的动作策略相关**.



##### 2.8.2 Using best response functions to define Nash equilibrium   用最优应对函数定义均衡

纳什均衡是一个行动配置，具有这样的属性：给定其他玩家的行动，没有一个玩家可以通过改变自己的行动来做得更好。使用刚才的术语，我们可以将**纳什均衡定义为**：**每个玩家的行动都是对其他玩家行动的最佳反应**。

占优策略. 

**PROPOSITION 34.1** The action profile a* is a **Nash equilibrium** of a strategic game with ordinal preferences if and only if every player's action is a **best response** to the other players' actions:  
$$
a_{i}^{*} \text{ is in }B_{i}\left(a_{-i}^{*}\right) \text{ for every player }i \tag{34.2}
$$

B这里指Best的集合.



若每个玩家都只有一个最优反应的情况 , 可以简化改写为:  for each player $i$ and each list $a_{-i}$ of the other players' actions, denote the single member of $$B_{i}\left(a_{-i}\right)$$ by $$b_{i}\left(a_{-i}\right)$$ (that is, $$B_{i}\left(a_{-i}\right)=\left\{b_{i}\left(a_{-i}\right)\right\}$$ ). Then (34.2) is equivalent to 
$$
 a_{i}^{*}=b_{i}\left(a_{-i}^{*}\right) \text{ for every player }i  \tag{34.3}
$$



##### 2.8.3 Using best response functions to find Nash equilibria  使用最优反应函数寻找纳什均衡

根据最优反应函数所做的纳什均衡定义提出了一个求纳什均衡的方法：

1. 求每个人的最优反应函数
2. find the action profiles that satisfy (34.2) (which reduces to (34.3) if each player has a single best response to each list of the other players’ actions).



为了说明这个方法，考虑35.1 中的博弈；    **星号法**。。。

![image-20201201204340072](/img/2020-04-18-Game.assets/image-20201201204340072.png)

首先,求玩家 1 关于玩家 2 的每个行动的最优反应。如果玩家 2 选择 $L,$ 那么玩家 1 的最优反 应是 $M$  ； 在 $(M, L)$中,玩家1 的盈 利上标有一个星号代表该行动为最优反应。其次,求玩家 2 关于玩家 1 的每个行动的最优反应（在每一行,求玩家 2 的最高盈利) ;
最后,寻求两个玩家的盈利都被赋予星号的方格。这样的方格是纳什均衡 : 
因此,我们得出结论 : 该博弈有两个纳什均衡 : $(M, L)$ 和 $(B, R)$ 。



下面一个例子， 求收益函数的最值，该最值是对方action的一个函数， 然后将两个玩家的画到一个图中，再求交点，就是纳什均衡。

例题37.1（协同synergistic 关系）两个人参与了一种协同关系。如果两个人都对这种关系付出更多的努力，他们都会得到更好的回报。先固定玩家j的努力，玩家i的回报随着其自身的努力先增加，然后减少。具体来说，努力水平是一个非负数，玩家i的偏好 (for $i=1,2$ ) 由报酬函数$a_{i}\left(c+a_{j}-a_{i}\right)$表示，其中$a_i$是$i$的努力水平，$a_{j}$是另一个人的努力水平，$c>0$是一个常数。

下面建模: 

- Players The two individuals.
- Actions,  set of effort levels (非负数).
- Preferences,  Player $i^{\prime}$ s preferences are represented by the payoff function $a_{i}(c+  a_{j}-a_{i} )$,  for $i=1,2$ 



特别是，每个玩家都**有无限多的动作**，所以我们不能像以前那样用表格来解决. 

为了找到博弈的纳什均衡，我们可以构造和分析玩家的最佳反应函数。给定$a_{j}$，个体$i$的报酬率是$a_{i}$的二次函数，极值点 $b_{i}\left(a_{j}\right)=\frac{1}{2}\left(c+a_{j}\right)$ , 

 最佳响应函数如图38.1所示。

<img src="/img/2020-04-18-Game.assets/image-20200505205335276.png" alt="image-20200505205335276" style="zoom:33%;" />

两条线的交点就是纳什均衡. 



在这个例题的博弈中，每个玩家对于其他玩家的每一个行动都有唯一的最优反应，所以最优反应函数呈现线状。如果一个玩家对于其他玩家的某些行动具有许多最优反应，那么她的最佳反应函数在某些点是"密集的"

图39.1所示是一对BR函数， 黑色以及阴影是Br1，灰色是Br2，它说明了一些可能性。对于P2的  $$a_{2}$$ between $$\bar{a}_{2}$$ and $$\underline{a}_{2},$$  player 1 的阴影部分都是 best responses.  例如，P1 $$a_{1}^{* *}$$ to $$a_{1}^{* * *}$$  的所有action 是 best responses to  $$a_{2}^{* * *}$$ of player2.

set of Nash equilibria consists of  $$\left(a_{1}^{*}, a_{2}^{*}\right)$$ and all the pairs of actions on player $$2^{\prime}$$ s best response function between $$\left(a_{1}^{* *}, a_{2}^{* *}\right)$$ and $$\left(a_{1}^{* * *}, a_{2}^{* * *}\right)$$  。 所以最后的均衡点是  $$\left(a_{1}^{*}, a_{2}^{*}\right)$$以及灰色线与阴影部分的交集，B2线在 $$\left(a_{1}^{* *}, a_{2}^{* *}\right)$$ 与$$\left(a_{1}^{* * *}, a_{2}^{* * *}\right)$$ 之间的部分。

![image-20201202113039161](/img/2020-04-18-Game.assets/image-20201202113039161.png)





##### 2.8.4 Illustration: contributing to a public good 例证;对公共财产局贡献





#### 2.9 Dominated actions 被支配行动, 劣行动

##### 2.9.1 Strict domination  严格支配   严优

在任何博弈中，**假如不管其他玩家如何做，玩家的一个行动比另一个行动总是优越**，那么这个行动"**严优 strictly dominates**"于另一个行动。

即某action的收益函数总是大于其他action的收益。    a1 严优于 a2， 则a2 严劣于 a1。

**DEFINITION 43.1** (**Strict domination 严优**)

In a strategic game with ordinal preferences, player $i^{\prime}$ 's action $a_{i}^{\prime \prime}$ **strictly dominates** her action $a_{i}^{\prime}$  , if  
 $u_{i}\left(a_{i}^{\prime \prime}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions,   
where $u_{i}$ is a payoff function that represents player $i$ 's preferences.

例如，在囚徒困境中，Fink的动作严格地支配着Quiet的动作：无论对手的动作如何，玩家选择Fink时的结果比选择Quiet时的结果更倾向于选择Fink的结果。另一方面，在BoS博弈中，两个动作都不能严格地支配另一个动作。如果对方选手选择巴赫，则巴赫比斯特拉文斯基好，但如果对方选手选择斯特拉文斯基，则巴赫比斯特拉文斯基差。

如果一个行动严优于行动 $a_i$，我们说 $a_i$ 是**严格被支配 strictly dominated （严劣）**行动。

**一个严劣的行动并不是对其他玩家的任何行动的最佳反应**：无论其他玩家做什么，其他一些行动都是更好的。
由于一个玩家的纳什均衡行动是对其他玩家的纳什均衡行动的最佳响应。*a strictly dominated action is not used in any Nash equilibrium.* **一个严劣行动不会用在任何纳什均衡中**.   
比如绝对大牌却fold

在寻找博弈中的纳什均衡时，我们可以将所有的**严劣**行动从考虑中**剔除**。



![image-20201201223954805](/img/2020-04-18-Game.assets/image-20201201223954805.png)

图44：只看P1的收益，  M严优于T。  对右边， B严优于M。





##### 2.9.2 Weak domination 弱支配  弱优  

**DEFINITION 45.1** (**Weak domination 弱优**) 

In a strategic game with ordinal preferences, player $i^{\prime}$ s action $a_{i}^{\prime \prime}$ weakly dominates her action $a_{i}^{\prime}$   
if   
 $u_{i}\left(a_{i}^{\prime \prime}, a_{-i}\right) \geq u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions  
and  
$u_{i}\left(a_{i}^{\prime \prime}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for some list $a_{-i}$ of the other players' actions.    

**弱优是部分优, 部分一样， 严优是全部优；   严优是大于, 弱优是有的大于有的等于. ** 



![image-20201201225306323](/img/2020-04-18-Game.assets/image-20201201225306323.png)

图45 ： M 弱优于 T， B 弱优于 M。



In a **strict** Nash equilibrium **no** player’s equilibrium action is **weakly dominated** 。  
an action be **weakly dominated**  can in a **nonstrict** Nash equilibrium。 

在**严格纳什均衡**中，没有一个玩家的均衡action是弱劣于其他action的，即 非均衡action都不会 弱优于 均衡action。  
在**非严格纳什均衡**中的均衡action**可能是弱劣** 的。    该弱劣action的均衡点可能总收益还高于弱优的均衡配置。下面这个特例。



![image-20201201225846707](/img/2020-04-18-Game.assets/image-20201201225846707.png)

图46， 双方而言（每个人，固定对方action，然后只看自己的收益）， 发现 B弱优于 >= C, C弱劣于 <=B， 但(C,C) 仍然是纳什均衡点。 同时另外一个 均衡点(B,B),  在左边博弈，二人的总体收益， (B,B)好于(C,C) ； 但在右边博弈中 (B,B) 差于(C,C)

严优，弱优， 都是 无论对手选什么action， 从自己的角度来看；但均衡策略是涉及两个人的。  
对上图左边， 若碰巧两个人都在上面左边的(C,C)， 都没有动机去改变（比如不知道 (B,B) 是可以达到的）； 但如果两个人积极一点，可能使得慢慢移到 （B,B）。  
上图右边，有点类似于 合作与投机。  别人合作，自己投机，总是期望上更好一点。



##### 2.9.3 Illustration: voting  例证 选举

##### 2.9.4 Illustration: collective decision-making  例证:共同决策



#### 2.10 Equilibrium in a single population: symmetric games and symmetric equilibria 单一群体中的均衡：对称博弈和对称均衡

大意就是, 一个群体有统一的策略.  那么来自同一个群体的玩家之间达成的平衡是什么样的. 

一个策略博弈的纳什均衡对应于多个种群成员之间相互作用的**稳定状态**，每个博弈中的每个玩家都有一个种群成员参与其中。有时，我们想建立一个模型，在这种情况下，单个同质种群的成员匿名参与到对称互动中。例如，考虑一下，行人在人行道上互相接近，或者汽车司机从不同方向同时到达十字路口。在每种情况下，每次相遇的成员都来自于同一人群：来自单一人群的行人相互相遇，而来自单一人群的汽车司机群体同时接近交叉路口。而在每种情况下，每个参与者的角色都是一样的。

两人博弈为"**对称的 symmetric**"如果每个人有相同的行动集，以及每个人的收益仅依赖于他和对手的行动，不取决于他的角色是P1还是P2.

**DEFINITION 49.3**  (**Symmetric two-player strategic game with ordinal preferences 对称的二人策略博弈**) A two-player strategic game with ordinal preferences is **symmetric** if the players’ sets of actions are the same and the players’ preferences are represented by payoff functions $u_1$ and $u_2$ for which $u_1(a_1, a_2) = u_2(a_2, a_1)$ for every action pair $(a_1, a_2)$.

**行动集相同, 且收益函数对称, 所以偏好也是相同的.  纳什均衡也是对称的.** 

<img src="/img/2020-04-18-Game.assets/image-20200508043410979.png" alt="image-20200508043410979" style="zoom:50%;" />



**DEFINITION 50.2** (**Symmetric Nash equilibrium**) An action profile $$a^{*}$$ in a strategic game with ordinal preferences in which each player has the same set of actions is a symmetric Nash equilibrium if it is a Nash equilibrium and $$a_{i}^{*}$$ is the same for every player $i$ 

**对称纳什均衡**  即该博弈里的所有玩家的均衡策略都一样.

例子，考虑一个正在接近的行人的模型。在任意给定的遭遇中，每个参与者有两个可能的行动, 朝右或左, 当参与者都以同样的方向行走，结果好于以不同的方向行走 (在后一种情况，会发生相撞)

<img src="/img/2020-04-18-Game.assets/image-20200508043811278.png" alt="image-20200508043811278" style="zoom:33%;" />

**对称博弈可以没有对称的纳什均衡。**  这个例子中， 均衡策略是， 一个人选了左，另外一个人就必须选右，总是不相同。

<img src="/img/2020-04-18-Game.assets/image-20200508044038682.png" alt="image-20200508044038682" style="zoom:33%;" />







### 3 纳什均衡：例证

#### 3.1 古诺特寡头垄断模型

#### 3.2 伯川德寡头垄断模型

#### 3.3 竞选

#### 3.4 消耗战

#### 3.5 拍卖

#### 3.6 民事法



### 4 Mixed Strategy Equilibrium 混合策略均衡

大意, 之前一个策略就是确定的一个动作, 现在把一些动作混合在一起, 随机的抽取, 就叫混合策略. 理解为随机策略也可. 纯策略之所以会劣于随机策略, 是因为随机策略里面包含随机因素, 相当于本次出招这块的信息不对称, 对方不知道要出什么招,  所以会有优势. 

对于一些博弈， 结局是比较确定性的， 一个人可能一辈子只能玩一次，比如囚徒困境，那么纯策略均衡就够了。 但一些博弈，比如猜拳， 可能连续进行很多次，这种博弈，更偏赌博和运气， 则这个时候，需要混合策略均衡。



#### 4.1 引言

##### 4.1.1 Stochastic steady states  随机稳态

之前是理想化的稳态, 在这个稳态中，游戏中的每个玩家都有一个群体，每当游戏进行时，从每个群体中随机抽取一个玩家（见第2.6节）。在稳态下，每当玩家进行游戏时，每一个玩家的行为都是一样的，没有一个玩家希望改变自己的行为，因为他知道（根据他的经验）其他玩家的行为。在稳定状态下，每个玩家的 "行为"只是一个动作，而在每个群体中，所有玩家选择的动作都是一样的，在**稳定状态**下，每一次游戏的结果都是相同的纳什均衡。

更一般的稳态概念允许玩家的选择有变化，只要选择的模式保持不变。例如，在一个给定的群体中，不同的成员可能会选择不同的行动，每一个玩家在玩游戏时都会选择相同的行动。或者每个人在每次玩游戏的时候，都可能根据相同的、不变的分布，在概率上选择自己的行动。这两种更一般的稳态概念是等价的：第一种类型的稳态，其中代表玩家i的群体中选择行动a的部分p对应于第二种类型的稳态，其中代表玩家i的人口中的每一个成员都以概率p选择a。为了解释的方便，在本章的大部分内容中，我将这样的均衡解释为第二种稳态的模型，在这种稳态中，每个玩家都是以概率的方式选择自己的行动；这样的**稳态**被称为**随机的（"涉及概率"）**。 

按群体成员的统计来解释随机策略。

 

##### 4.1.2 Example: Matching Pennies

|      | Head | Tail |
| :--: | :--: | :--: |
| Head | 1,-1 | -1,1 |
| Tail | -1,1 | 1,-1 |



重要例子, 该博弈**没有纯策略纳什均衡**;  但有一个**随机*stochastic*的稳态**，即 每个玩家选择他的每一个动作的概率为1/2.  可以证明, 只要玩家选择1/2的概率, 则不论另外一个玩家怎么改变策略, 收益期望都是不变的.





##### 4.1.3 Generalizing the analysis: expected payoffs  推广分析：期望收益

匹配硬币对每个玩家只有两种结局,使得随机稳态状态的分析特别简单,因为它允许我们在较弱的假设下通过玩家对确定结局 (肯定发生的结局)的偏好推断玩家关于随机结局(概率分布) 的偏好。    
如果一个玩家喜欢确定的结局 $a$ 甚于确定的结局 $b$,似乎很合理的是, 若 $p>q$,那么她喜欢这样的随机结局, $a$ 发生的概率是 $p(b$ 发生的概率是 $1-p)$; 而不喜欢那样的随机结局, $a$ 发生的概率为 $q$.

在某些玩家有超过两个结局的博弈中,我们不能以这种方法从确定结局的偏好推导出关于随机结局的偏好。例如,假设博弈有三个可能结果 $a, b$ 和 $c,$ 并且玩家喜欢 $a$ 甚于 $b$ 更甚于 $c_{\circ}$ 她是否喜欢确定的结局 $b$ 胜过“ $a$ 和 $c$ 各以 $\frac{1}{2}$ 的概率发生”的随机结局,或者反过来?  玩家对确定性结局偏好的信息没有提示我们有关这个问题的答案。她可能喜欢 $b$ 甚于“ $a$ 和 $c$ 各以 $\frac{1}{2}$ 概率发生”的随机事件,或者她可能喜欢这样的随机事件甚于 $b ;$ 这两种偏好与“她喜欢 $a$ 甚于 $b$ 更甚于 $c$ ”是相容的。为了研究面临随机结局的选择时她的习性,我们需要给模型添加她关于随机结局偏好的描述。 

**lottery** ， 抽签，彩票，这里表示随机结局， 其实就是说该收益是包含随机因素的。所以用确定性收益的期望表示。

A standard assumption in game theory restricts attention to preferences regarding lotteries over outcomes that may be represented by the  expected value of a payoff function over deterministic outcomes.  博弈论的标准假设只关注“lottery 结果”上的偏好，对这些随机结局的偏好可以用确定性结局的收益函数的期望来表示。  
即,对于每一个玩家 $i,$ 存在一个具有如下性质的盈利函数 $u_{i}:$ 使得玩家 $i$ 喜欢一种随机结局甚于另一种,当且仅当根据 $u_{i}$ 计算的第一种 随机结局的期望值超过第二种随机结局的期望值。 That is, for every player $i$ there is a payoff function $u_i$ with the property that player $i$ **prefers one lottery** over outcomes to another if and only if, according to  $u_i$ , the **expected value** of the first lottery exceeds the expected value of the second lottery.



例, 两种lottery,  P出大奖的几率高于Q, 则偏好选P；

假定有三个结局 outcomes $a, b,$ and $c,$ and lottery $P$  ：yields $a$ with probability $p_{a}$ ， 以 $p_{b}$ 产生b ;  $c$  : $p_{c},$ 而另一个 $Q$： $q_{a}, q_{b},$ and $q_{c} .$  那么假定，对每个玩家 $i$ ， 存在 $u_{i}(a), u_{i}(b),$ and $u_{i}(c)$  使得玩家 $i$ 喜欢 lottery $P$ 大于 lottery $Q$ if and only if $p_{a} u_{i}(a)+p_{b} u_{i}(b)+p_{c} u_{i}(c)> q_{a} u_{i}(a)+q_{b} u_{i}(b)+q_{c} u_{i}(c) $.  

**vNM preferences**  对随机的情况, 偏好选 期望结果比较好的那个.  即对随机的情况，有个统计上的正确的偏好。   
拥有该偏好的博弈，玩家使用的是混合策略。

**Bernoulli payoff function** , $p_{a} u_{i}(a)+p_{b} u_{i}(b)+p_{c} u_{i}(c)$  ,  凸配置, 权重和为1 。   **伯努利收益函数**



假设一个玩家的偏好由一个收益函数的期望值来表示，这并不限制她对风险的态度：一个偏好由这样一个函数表示的人可能对风险有着任意强烈的喜欢或厌恶。

risk neutral 风险中性： compares lotteries according to the expected amount of money involved 。   
比如，稳赚  $100$ 与  $0$ $\frac{9}{10}$  +  $1000$  $\frac{1}{10}$ ， 对其来说一样。  

ps， 风险中性， 只对模型有意义。 因为人的生命是有限的。  偏向稳赚是更符合人类发展的。

risk averse 风险厌恶：  更喜欢 稳赚的。 怕失去，更多看失去。  
risk preferring 风险偏好： 会去买彩票。       更多看获得。

在这两种情况下，对lottery的偏好并不是用预期的货币价值来表示的，尽管它们仍然可以用报酬函数的预期值来表示（其中结果的报酬与结果的货币价值不同）。



在确定性结局上，任何给定的偏好可以由许多不同的收益函数来描述（即数值只表示序号关系，不表示程度）。对于随机结局的偏好也是如此。只要相关的期望符合玩家的偏好即可。

例如,假定有三个结 局 $a 、 b$ 和 $c$,某人喜欢 $a$ 甚于 $b$ 更甚于 $c$,并且在 $b$ 与“以概率 $\frac{1}{2}$ 产生 $a$ 和以概率$\frac{1}{2}$ 产生 $c$ ”的随机结果之间表现出无所谓(偏好一样)。那么我们可以选择 $u(a)=3$ 和$u(c)=1,$ 此时 $u(b)=2$; 或者我们可以选择 $u(a)=10$ 和 $u(c)=0,$ 此时 $u(b)=$ $5 ;$ 或者 $u(a)=1, u(c)=-1,$ 此时 $u(b)=0$ 。 



#### 4.2 Strategic games in which players may randomize 有随机行为的策略型博弈

**DEFINITION 103.1**   A **strategic game** (with vNM preferences) consists of

- a set of **players**
- for each player, a set of **actions**
- for each player, **preferences** regarding lotteries over action profiles that may be represented by the expected value of a (“Bernoulli”) payoff function over action profiles.



具有vNM偏好的双人策略博弈，其中每个玩家都有有限的行动，可以用一个类似于第2章中的表格来表示。这样的表格看起来和之前的完全一样，但方框中的数字的解释是不同的。在第2章中，这些数字是收益函数的值，代表玩家对确定性结果的偏好；这里它们是（Bernoulli）收益函数的值，其期望值代表玩家对随机结果的偏好。

鉴于对报酬的解释发生了变化，两张代表同一策略博弈的序数偏好的表格不再一定代表同一策略博弈的vNM偏好。图104， 囚徒困境， 下面两种情况都描述了 相同的序数偏好为 (F,Q) > (Q,Q)>(F,F)>(Q,F) ； 但vNM偏好则不同，左边，$$\left(\frac{1}{2} u_{1}(F, Q)+\frac{1}{2} u_{1}(F, F)=\frac{1}{2} \cdot 3+\frac{1}{2} \cdot 1=2=u_{1}(Q, Q)\right)$$ ,  右边  关于 $(Q, Q)$ 的盈利大于这个随机结局的期望盈利 $\left(3>\frac{1}{2} \cdot 4+\frac{1}{2} \cdot 1\right)$ 。    所以两个表有不同的 vNM 偏好。

![image-20201202201322705](/img/2020-04-18-Game.assets/image-20201202201322705.png)

如果玩家不被允许随机选择他们的行动，那么报酬表中的数字是代表玩家的序数偏好的收益，而如果玩家被允许随机选择，那么这些数字则是收益，这些收益的期望值代表玩家的偏好。



#### 4.3 Mixed strategy Nash equilibrium 混合策略纳什均衡





##### 4.3.1 Mixed strategies 混合策略

**混合策略**就是在几个action上有概率的随机选择, 例如,猜拳, 每个1/3. 

混合策略可以将概率1分配给一个单一行动：通过允许玩家选择概率分布，允许其选择确定性行动。我们把这种混合策略称为**纯策略 pure strategy**。



##### 4.3.2 Equilibrium 均衡

**定义 105.1** (**具有 vNM 偏好的策略型博弈的混合策略纳什均衡** *Mixed strategy Nash equilibrium of strategic game with vNM preferences*)  

如果 $$U_{i}\left(\alpha^{*}\right) \geq U_{i}\left(\alpha_{i}, \alpha_{-i}^{*}\right)$$ , 混合策略配置$$\alpha^*$$ 是一个纳什均衡

把之前的收益函数改成mixed strategy profile $$\alpha$$的 期望收益$$U_{i}(\alpha)$$即可. 



##### 4.3.3 Best response functions 最优反应函数

从混合策略均衡的定义来看，**如果且仅当每个玩家的混合策略都是对其他玩家的混合策略的最佳反应时，则混合策略配置$\alpha^{*}$ 就是混合策略的纳什均衡**.     
 $$\alpha^{*}$$ is a mixed strategy Nash equilibrium if and only if $$\alpha_{i}^{*}$$ is in $$B_{i}\left(\alpha_{-i}^{*}\right)$$ for every player $i$ 



##### 4.3.4 Best response functions in two-player two-action games 特殊情况的最优反应函数

混合策略pair $\left(\alpha_{1}, \alpha_{2}\right)$在四种可能的游戏结果上产生的概率分布如图

|        |  L(q)  |   R(1-q)   |
| :----: | :----: | :--------: |
|  T(p)  |   pq   |   p(1-q)   |
| B(1-p) | (1-p)q | (1-p)(1-q) |



玩家1的期望收益为:

$$
p q \cdot u_{1}(T, L)+p(1-q) \cdot u_{1}(T, R)+(1-p) q \cdot u_{1}(B, L)+(1-p)(1-q) \cdot u_{1}(B, R)
$$

改写为:  即，从P1横向看过去，

$$
p\left[q \cdot u_{1}(T, L)+(1-q) \cdot u_{1}(T, R)\right]+(1-p)\left[q \cdot u_{1}(B, L)+(1-q) \cdot u_{1}(B, R)\right]
$$

第一个方括号是玩家1使用纯策略T, 玩家2使用混合策略$\alpha_{2}$时的预期回报,   第二个是玩家1使用纯策略B, 玩家2使用混合策略$\alpha_{2}$时的预期回报;  分别记为 $E_{1}\left(T, \alpha_{2}\right)$ and $E_{1}\left(B, \alpha_{2}\right) .$    玩家1的期望收益改写为:   即在自己的动作上将期望拆分. 

$$
p E_{1}\left(T, \alpha_{2}\right)+(1-p) E_{1}\left(B, \alpha_{2}\right)
$$

给定玩家2的混合策略以后, 玩家1的期望收益就是线性函数.

<img src="/img/2020-04-18-Game.assets/image-20200505221618206.png" alt="image-20200505221618206" style="zoom: 50%;" />

**给定对方采用混合策略以后, 自己的收益函数是线性的, 而且最优的点在两端.  如果对方在均衡点上, 则自己没法通过单独改变混合策略来获益. 自己在均衡点上, 对方也没法单独改变策略来获益.  对方在均衡点上, 不让自己有机可乘; 自己在均衡点上, 不让对方有机可乘**

玩家1的线性预期回报的一个重要结论是，他对玩家2的混合策略有三种可能的最佳反应。

1. 玩家1唯一的最佳反应是纯策略T (if $E_{1}\left(T, \alpha_{2}\right)>E_{1}\left(B, \alpha_{2}\right)$) 

2. 玩家1唯一的最佳反应是纯策略B (if $E_{1}\left(B, \alpha_{2}\right)>E_{1}\left(T, \alpha_{2}\right)$)，在这种情况下，玩家1的预期回报率与图108.1中的p的函数关系线向下倾斜

3. 玩家1的所有混合策略都会产生相同的预期回报，因此都是最好的反应($E_{1}\left(T, \alpha_{2}\right)=E_{1}\left(B, \alpha_{2}\right)$)，在这种情况下，在图108.1的类比中，代表玩家1的预期回报率与p的函数的线是水平的

特别是， 混合策略$(p, 1-p)$ $0<p<1$永远不是唯一的最佳反应，要么它不是最佳反应，要么所有的混合策略都是最佳反应。 因为如图，给定P2策略， P1的最优收益是线性，在两端； 如果P2是均衡策略，则P1的整个中间线段都是最佳反应， 因为这个线是水平的。



##### 4.3.5 Example: Matching Pennies 

4.1.2 已经证明了有唯一的混合策略纳什均衡.  现在用2.8.3节的方法.

设玩家1选head几率为p, 玩2选head几率为q.   
则玩家1选纯策略,head的预期收益为 q · 1 + (1 − q) · (−1) = 2q − 1, 选tail的预期收益为 q·(−1)+(1−q)·1 = 1−2q .  这时的预期收益完全由玩家2的q来决定.    
当知道了玩家2 的q之后, 玩家1的纯策略最佳反应函数为: 

$$
B_{1}(q)=\left\{\begin{array}{ll}
\{0\} & \text { if } q<\frac{1}{2} \\
\{p: 0 \leq p \leq 1\} & \text { if } q=\frac{1}{2} \\
\{1\} & \text { if } q>\frac{1}{2}
\end{array}\right.
$$


同理,如果玩家1采样p的概率, 玩家2的用纯策略, 则相应的最近反应函数也类似.

将这两个函数都画到下图里面, 唯一的交点就是 混合策略的纳什均衡.

<img src="/img/2020-04-18-Game.assets/image-20200508033716605.png" alt="image-20200508033716605" style="zoom:50%;" />



##### 4.3.6 Example: BoS

**纯策略有两个纳什均衡.   对于这种, 2个人2个动作的, 对于混合策略, 因为别人走了随机, 所以只要别人不是在均衡点上, 自己这边肯定需要把策略偏向某个方向. 只有自己也在均衡点上, 就不用管对方怎么变, 自己都是期望最优了.  使用混合策略以后,得到的纳什均衡, 可以使得两个玩家得到的收益一样. 而不是像之前一样, 只有1个人能最大化; 不过这样的后果就是总收益降低, 每个人 平均收益是 2/3 ;  之前的纯策略平均每个人是3/2, 不过需要一个人做牺牲. 而相关均衡则是, 两个人通过通信, 比如轮流的选择对方最喜欢的, 这样可以达到两个人的收益都一样又都最大化的情况, 这里是3/2, 即两个人一起选B一次, 再一起选S一次** 



<img src="/img/2020-04-18-Game.assets/image-20200508034115026.png" alt="image-20200508034115026" style="zoom:33%;" />
$$
B_{1}(q)=\left\{\begin{array}{ll}
\{0\} & \text { if } q<\frac{1}{3} \\
\{p: 0 \leq p \leq 1\} & \text { if } q=\frac{1}{3} \\
\{1\} & \text { if } q>\frac{1}{3}
\end{array}\right.
$$

<img src="/img/2020-04-18-Game.assets/image-20200508034351923.png" alt="image-20200508034351923" style="zoom:50%;" />

黑点是纳什均衡, 中间的交点的黑点是混合策略的纳什均衡. 



##### 4.3.7 A useful characterization of mixed strategy Nash equilibrium 混合策略均衡的有用特征



目前为止，用来研究混合策略纳什均衡集合的方法涉及 构建最佳响应函数。其他的方法有时也是有用的。我现在提出一个混合策略均衡的特征，它为我们提供了一个简单的方法来检查一个混合策略配置是否是均衡，并且是寻找一个博弈的所有均衡的程序（在4.10节中描述）的基础。

关键是在第4.3.4节中对双人双动博弈的分析：玩家对**混合策略配置的预期回报是他对纯策略的预期回报的加权平均**，其中每个纯策略的权重是玩家的混合策略分配给该策略的概率。这个属性对于任何博弈（有任意数量的玩家）都适用。我们可以更精确地说明如下：

玩家对混合策略配置 $\alpha$ 的预期收益为, 其对所有形式为 $\left(a_{i}, \alpha_{-i}\right)$ 的混合策略(这里自己的部分是纯策略)的配置的预期收益的加权平均, 权重是  $\alpha_i(a_i)$ , 表示 $\alpha_{i}$ 分配给 $a_i$ 的概率. 

$$
U_{i}(\alpha)=\sum_{a_{i} \in A_{i}} \alpha_{i}\left(a_{i}\right) U_{i}\left(a_{i}, \alpha_{-i}\right)  \tag{113.1}
$$

其中,  $$A_{i}$$ 是玩家 $$i$$ 的纯策略动作集,  $$U_{i}\left(a_{i}, \alpha_{-i}\right)$$ 是玩家以概率1执行纯策略, 其他人 $$j$$ 使用混合策略$$\alpha_{j}$$ 的预期收益. 

该性质可以推出混合策略均衡的一个有用的特性:   $$\alpha^{*}$$ 为混合策略均衡,   $$E_{i}^{*}=U_{i}\left(\alpha^{*}\right)$$ 为该均衡策略的预期回报.  因为 $$\alpha^{*}$$ 为混合均衡, 则给定 $$\alpha_{-i^{\prime}}^{*}$$ 的情况下, 玩家i的所有策略(包含纯策略)的预期回报最多是 $$E_{i}^{*}$$.  由$$(113.1)$$, 可得, $$E_{i}^{*}$$  是 属于混合策略均衡的那些纯策略$$a^*_i$$ (即被分配了正概率)的预期回报的加权平均, 权重是分配给各个纯策略$$a^*_i$$的概率. 于是, 这些纯策略$$a^*_i$$的预期回报都等于$$E_{i}^{*}$$ .(如果那个纯策略的回报小了,则总体的加权平均值肯定要下降).   同时, 其他的那些不属于混合策略均衡的纯策略$$a_i$$的预期回报$$ \leq E_{i}^{*}$$ .   

反过来说,  找到那些纯策略 $$a_{i}^{*}$$的预期回报都是$$E_{i}^{*}$$的, 那么这些纯策略配置起来的混合策略就是纳什均衡. 

PROPOSITION 113.2  (**Characterization of mixed strategy Nash equilibrium of finite game 有限搏弈的混合策略纳什均衡的特性**)      
策略型博弈中, 混合策略配置 $$\alpha^*$$ 是纳什均衡,当且仅当,   对每个玩家$$i$$,  

- 给定对手策略$$\alpha_{-i}$$的情况下, $$\alpha^*$$ 分配正概率的每个行动的预期收益是相同的 $$ = E_{i}^{*}$$ , 说明其他人在均衡点, 自己怎么调都没用,不能额外获利
- 给定对手策略$$\alpha_{-i}$$的情况下, $$\alpha^*$$ 分配0概率的每个行动的预期收益 $$ \leq E_{i}^{*}$$ ,  劣的直接排除.

该结论的重要意义是, 它给出了混合策略纳什均衡的条件，即每个玩家的预期回报跟他的纯策略相关。对于有限多行动的博弈，可以很容易地检验混合策略配置是否是均衡。

例,  BoS ,  策略对 $\left(\left(\frac{2}{3}, \frac{1}{3}\right),\left(\frac{1}{3}, \frac{2}{3}\right)\right)$ 是混合策略均衡, 因为给定玩家2的策略 $\left(\frac{1}{3}, \frac{2}{3}\right)$, 玩家1的关于B和S的预期收益都是 $\frac{2}{3},$ 说明玩家2在均衡点上;  并且 给定玩家1的策略 $\left(\frac{2}{3}, \frac{1}{3}\right)$, 玩家2关于B和S的预期收益也都等于 $\frac{2}{3}$ , 说明玩家1在均衡点上. 



**很有用**  EXAMPLE 114.1 (检测一个策略配置是不是混合策略均衡) 

<img src="/img/2020-04-18-Game.assets/image-20200508172839897.png" alt="image-20200508172839897" style="zoom: 50%;" />

玩家1的策略$\left(\frac{3}{4}, 0, \frac{1}{4}\right)$,  玩家2的策略$\left(0, \frac{1}{3}, \frac{2}{3}\right)$ . 下面验证.  
对玩家1的收益预期为  
$T: \frac{1}{3} \cdot 3+\frac{2}{3} \cdot 1=\frac{5}{3}$  
$M: \frac{1}{3} \cdot 0+\frac{2}{3} \cdot 2=\frac{4}{3}$  
$B: \frac{1}{3} \cdot 5+\frac{2}{3} \cdot 0=\frac{5}{3}$  
所以玩家1满足定理113.2  
玩家2 , 纯策略的收益为$\frac{5}{2}\left(\frac{3}{4} \cdot 2+\frac{1}{4} \cdot 4=\frac{3}{4} \cdot 3+\frac{1}{4}  1=\frac{3}{4} \cdot 1+\frac{1}{4} \cdot 7=\frac{5}{2}\right),$ 所以也满足条件.

 

命题113.2的一个含义是，一个非退化的混合策略均衡（不是概率为1的纯策略均衡的那种混合）从来都不是**严格 strict 的纳什均衡**：every player whose mixed strategy assigns positive probability to more than one action is indifferent between her equilibrium mixed strategy and every action to which this mixed strategy assigns positive probability. 每个玩家对混合策略里面的选哪个动作无所谓, 因为其他人都在均衡点上. 



##### 4.3.8 Existence of equilibrium in finite games  有限博弈均衡的存在性

玩家有限多个行动的博弈都至少有一个混合策略纳什均衡。



#### 4.4 Dominated actions 劣行动

注意, **这里的比较, 都是 纯策略与混合策略的比较**.   纯策略之间比没啥意思, 一眼就看出来了.

DEFINITION 117.1 (**Strict domination 严优**)  

注意, 前面是alhpa, 后面是a ;  严劣就是确定比别的东西差的.

混合策略配置 $\alpha_{i}$ **严优strictly dominates** 于 $a_{i}^{\prime}$ ,  if  $U_{i}\left(\alpha_{i}, a_{-i}\right)>u_{i}\left(a_{i}^{\prime}, a_{-i}\right)$ for every list $a_{-i}$ of the other players' actions . 

即,玩家i的这个混合策略$\alpha_{i}$, 比任何其他的纯策略的回报都要好.



例子, 图117.1(其中只给出了玩家1的回报)  ,  行动T不**严劣strictly dominated**于M或者B,   即T 不弱于M或者B, 但T 弱于"1/2 选M ,1/2选B",  玩家2最好的应对是选R, 这时玩家1的期望回报是 3/2 , 大于1.

<img src="/img/2020-04-18-Game.assets/image-20200508022703992.png" alt="image-20200508022703992" style="zoom:33%;" />

**在任何混合策略纳什均衡中，严劣行动不被使用。** 



#### 4.5 Pure equilibria when randomization is allowed 随机的纯策略均衡

证明:  对一般的博弈, 不允许玩家随机选择行动时的均衡，在允许玩家随机选择后仍然为均衡; 并且，允许玩家随机时存在的任何纯策略均衡，在不允许随机后也存在。



#### 4.6 例证：专家诊断



#### 4.7 Equilibrium in a single population 单一总体中的均衡

定义都与之前一样, 只不过加上了 vNM偏好.

<img src="/img/2020-04-18-Game.assets/image-20200508044620628.png" alt="image-20200508044620628" style="zoom:33%;" />

对路人接近问题, 除了纯策略的两个均衡, (Left, Left) and (Right, Right); 有个对称的混合策略均衡. 即 1/2选择左右. ?? 这个点是高点还是低点??

下例中, 没有纯策略对称均衡, 却有混合策略对称均衡.  还是1/2的几率.

<img src="/img/2020-04-18-Game.assets/image-20200508044816686.png" alt="image-20200508044816686" style="zoom:33%;" />



#### 4.8 例证：报案



#### 4.9 The formation of players’ beliefs 玩家信念的形成

在纳什均衡中，每个玩家在知道其他玩家的策略的情况下，选择一个能使其预期收益最大化的策略。到目前为止，我们还没有考虑过玩家是如何获得这些信息的。从非正式的角度来说，前面的分析的基本思想是，玩家们从他们的游戏经验中了解到了对方的策略。**epsilon greedy 采样 learn出来的**.  在理想化情况下，对于游戏中的每一个玩家，都对应一个群体, 其中大量的个体；在游戏的任何一局游戏中，每个群体中随机抽取一个参与者。在这种情况下，一个新的个体加入一个处于稳定状态的群体（即正在使用纳什均衡策略），他可以通过观察其他玩家在多次博弈中的行动来学习其他玩家的策略。只要玩家的更替率足够小，现有老玩家与新手（可能使用非均衡策略）的相遇就会足够少，以至于老玩家对稳态的信念不会受到干扰，因此，新玩家的问题只是学习其他玩家的行动。

下面的问题是, 如果博弈中的玩家都是缺乏经验的新手玩家, 那能达到纳什均衡么

##### 4.9.1 Eliminating dominated actions 剔除劣行动

排除法, 先去掉一些差动作, 减少搜索空间. 

第一个办法, 对某些博弈, 纯推理.

某些博弈中，可以期盼玩家通过对博弈的内在分析，合理选择他们的纳什均衡行动。在极端的情况下，每个玩家的最佳行动可能独立于其他玩家的行动，就像囚徒困境那样。在不太极端的情况下，一些玩家的最佳行动可能取决于其他玩家的行动，但其他玩家将选择的行动可能是明确的,  因为这些玩家都有严优于所有其他行动的行动.

<img src="/img/2020-04-18-Game.assets/image-20200508120053026.png" alt="image-20200508120053026" style="zoom:33%;" />

上例中, 玩家2的R 优于L, 所以玩家1可以推断自己应该选B, 也就是说, 新手玩家也可以导致这个唯一的纳什均衡.

延伸该思路, 

<img src="/img/2020-04-18-Game.assets/image-20200508141746314.png" alt="image-20200508141746314" style="zoom:33%;" />

上例中， 玩家1的T是严劣的， 所以玩家1可以推理出:玩家2能考虑到玩家1不会选T, 玩家2会选择R; 所以玩家1 会选择B.  即相信大家都是绝对理性的.



##### 4.9.2 Learning 学习 

重要!!

另一种方法是假设每个玩家在开始时对其他玩家的行为都有一个无法解释的 "先验 "信念，然后根据他收到的信息改变这些信念--"学习"。在这里，我简单地讨论了两个理论，即同一组参与者重复地玩一个游戏，每个参与者都会根据自己对其他人的行为的观察，改变自己对其他人的策略的信念。

**Best response dynamics 动态最优反应** :  其实就**多次游戏迭代,会收敛到纳什均衡**;  一个特别简单的理论假设，在第一个时期之后的每个时期，每个玩家都相信其他玩家会选择他们在**前一个时期**选择的行动。在第一个时期，每个玩家对其他玩家的行动选择一个任意的决定性信念，选择一个最佳反应。在随后的每一个时期，每个玩家都会选择一个最佳反应来回应上一时期其他玩家的行动。这个过程被称为最佳反应动态。一个从一个时期到另一个时期保持不变的行动配置就是一个**纯策略纳什均衡**。此外，在纯纳什均衡中，每个玩家的行动是他对其他玩家的行动的唯一最佳反应，这就是一个纯纳什均衡的行动配置，从一个时期到另一个时期保持不变。

在一些博弈中，不管玩家的初始信念如何，最优反应动态产生的行动配置序列收敛于一个纯策略纳什均衡。  
另外有一些博弈，存在一些初始信念，之后产生的行动配置序列**并不收敛**。例如，在BoS（例16.2）中，如果玩家1最初相信玩家2会选择斯特拉文斯基，而玩家2最初相信玩家1会选择巴赫，那么玩家的选择将在（巴赫、斯特拉文斯基、巴赫）和（斯特拉文斯基、巴赫）这两个动作对之间无限期地交替进行。这个例子突出了玩家在模式中的推理能力的有限性。即没有考虑到对方的行动总是对自己之前的行动作出最好的反应的这种可能性。

还有个前提: 每个玩家都相信其他每个玩家都在使用纯策略. 

**Fictitious play 假想博弈** : **统计概率,作为其混合策略**. 假设玩家在形成对对手策略的信念时，会考虑**之前所有时期的行动**。他们把这些行动看作是混合策略的实现。考虑一个双人博弈。每个玩家开始时都对对方的行动有一个任意的概率信念。在游戏的第一局中，他选择了一个对这个信念的最佳反应，并观察对方的行动，比如说行动A。然后，他将自己的信念改变为将概率1分配给A；在第二个时期，他选择一个对这个信念的最佳反应，并观察对方的行动，比如说B。 然后，他把自己的信念改成给A和B都分配了1/2概率，并选择了一个最佳的应对措施。 他每个时期都会继续改变自己的信念；在任何时期，他都认为对手使用的是混合策略，在这种策略中，每个动作的概率与频率成正比。

在匹配硬币, 这个过程运作如下。假设玩家1 从"玩家 2 的行动将是反面"的信念出发，玩家2 从"玩家1的行动将是正面"的信念开始。然后，两个玩家在周期 1 都选择了"反面"。于是, 两个玩家在周期2中都相信对方选了反面, 因此玩家1选择反面, 玩家2选择正面; 到周期3, 玩家1认为:玩家2选正反的几率是1/2, 玩家2认为: 玩家1肯定选反面; 于是,正反面都是玩家1关于其信念的最优反应, 玩家2 唯一的最优反应是正面; 然后一直继续下去...

像 "匹配便士 "这样的双人博弈，玩家的利益是直接对立的，在任何双人游戏中，每个玩家都有两个行动，这个过程从任何初始信念开始都**收敛到混合策略纳什均衡**。也就是说，在足够多的时间段后，每个玩家选择行动的频率接近于混合策略在纳什均衡中的频率。对于其他博弈来说，有一些初始信念，其过程并不收敛。(即使最简单的例子太复杂了，无法简单介绍)。



#### 4.10 Extension: Finding all mixed strategy Nash equilibria   延伸: 求混合策略纳什均衡

对于有两个行动的两人博弈，我们可以 通过构**建最优反应函数**，求得所有的混合策略纳什均衡。在更复杂的博弈中，这个方法一般不实用。

下面求博弈中全部混合策略纳什均衡的方法由命题 113.2 中的均衡特征推导出来。

- 对每个玩家$i$, 从其行动集 $A_i$ 中选择一个子集$S_i$
- 核实是否存在一个混合策略配置$\alpha$ ，使得
  - 每个策略 $\alpha_i$ 分配正概率的行动集是 $S_i$ 
  - $\alpha$ 满足命题113.2 中的条件。
- 对玩家行动集中的每一个子集配置，重复地分析。 



这个方法工作量蛮大的..

例子, 下图, 每个玩家的动作集有三个非空子集(1,2,(1,2)); 因此存在9个 玩家1玩家2的行动对.  对每一对($S_1,S_2$) , 核实是否存在一堆混合策略($\alpha_1, \alpha_2$) , 使得每个$\alpha_i$ 仅对$S_i$的行动分配正概率, 并且满足113.2.

<img src="/img/2020-04-18-Game.assets/image-20200508181252013.png" alt="image-20200508181252013" style="zoom:33%;" />

- 考虑四对子集，其中每个玩家的子集由一个动作组成，就等于检查是否是纯策略均衡。(对每个玩家来说，自动满足命题113.2中的第一个条件，因为每个子集中只有一个动作)。
- 考虑玩家1的子集 $\{T, B\}$和玩家2的子集 $\{L\}$ : 对于玩家1来说，第113.2条中的第二个条件是自动满足的，因为玩家1没有任何行动的概率为0，而对于玩家2来说，第一个条件是自动满足的，因为他只给一个行动分配了正概率。因此，如果要有一个混合策略均衡，其中玩家1使用T的概率是p , 我们需要$u_{11}=u_{21}$ , 因为玩家1的两个动作的期望回报必须一样. 并且, $p v_{11}+(1-p) v_{21} \geq p v_{12}+(1-p) v_{22}$, 即考虑到玩家1的混合策略，L至少要和R一样好。 如果$u_{11} \neq u_{21}$ , 或者 不存在满足不等式的p, 那么就不存在这种类型的均衡. 其他三组子集也同理.
- 考虑$\{T, B\}$ 和 $\{L, R\}$ . 我们需要找到一对混合策略，并满足命题113.2中的第一个条件（第二个条件是自动满足的，因为两个玩家都给他们的行为赋予正概率）。也就是说，我们需要找到概率p和q(如果有的话), 使得  $q u_{11}+(1-q) u_{12}=q u_{21}+(1-q) u_{22} \quad$ and $\quad p v_{11}+(1-p) v_{21}=p v_{12}+(1-p) v_{22}$

例如，在 BoS 中，检查其中每个子集由单一行动组成的子集对时，发现了两个纯策略均衡; 检查其中一个子集只含有单一行动而另 个子集由两个行动组成的子集对时，发现没有均衡;  剩下的情况, 求得混合策略均衡。



#### 4.11 延伸：每个玩家的行动具有连续统势时的博弈

#### 4.12 附录：以期望盈利体现优先选择



### 5 Extensive games with perfect information: Theory 完全信息展开型博弈：理论

策略型博弈没有决策的序列结构。当把这个模型应用到决策者 会有序行动的情况时，我们假定每一个决策者"一劳永逸"地选择了他的行动计划, 随着事件的展开，他不能修改计划。相反，展开型博弈模型清晰地描述了决策的序列结构，随着事件的展开，每个决策者可以自由地改变自己的决策。



#### 5.2 Extensive games with perfect information 完全信息展开型博弈

##### 5.2.1 Definition

之前只需 玩家集与偏好;  现在需要说明 玩家的动作次序,  和在每个时刻每个玩家可能采取的行动。为了做到这一点，需要详细说明所有可能发生的行动序列的集合，以及在每个序列中每个时刻采取该动作的玩家.  我们称每个可能的动作序列sequence of actions为**终端历史terminal history**.  在 terminal history的每个时刻指出是哪个玩家的函数叫 **player function**.    terminal history 就是包含结束的从头到尾的历史.

一般地说，假设（C，D）和（C，E）是终端历史，玩家函数将玩家1分配给游戏开始时，玩家2分配给历史C时刻之后，那么玩家1在游戏开始时选择了C后，玩家2可以使用的两个动作是D和E。一个游戏的终端历史记录被指定为一组序列。但不是每一个序列集都是合法的终端历史集。例如，如果(C，D)是终端历史，那么指定C为终端历史是不对的：事实上，(C，D)是终端历史意味着，在游戏开始时选择了C之后，有的玩家可能会选择D，这样，C的动作就不会结束游戏。更一般地说，作为终端历史的**真子历史 proper subhistory**的序列本身不能成为终端历史。这个限制是我们唯一需要对一个序列集施加的限制，以便这个序列集可以被解释为终端历史的集合。

为了精确地陈述这个限制，定义行动的一个有限序列$\left(a^{1}, a^{2}, \ldots, a^{k}\right)$ 的"**子历史 subhistories**"是 空, $\varnothing$ (表示博弈的开局) , 和 所有形式为 $\left(a^{1}, a^{2}, \ldots, a^{m}\right)$ $1 \leq m \leq k$ ; 同理也可以定义无限序列的. 

不等于整个序列的子历史 称为**真 子历史 proper subhistory** ; 一个行动序列，它是某个终端历史的子历史，简单地称作 "**历史 history**"。 

**子历史都是包含开头的 ; 真子历史,  含头不含尾** , 



DEFINITION 153.1 (**Extensive game with perfect information**) An extensive game with perfect information consists of   **完全信息的展开型博弈** 的要素

- a set of **players**
- a set of sequences (**terminal histories**) with the property that no sequence is a proper subhistory of any other sequence  终端历史集合;  因为是终端历史, 所以肯定不是其他的真子历史
- a function (**player function**) that assigns a player to every sequence that is a proper subhistory of some terminal history ;  即P(真子历史) = 该时刻玩家;  
- for each player, **preferences** over the set of terminal histories.  关于终端历史集合的偏好

就策略型博弈来说，我们可以通过给出一个描述偏好的收益函数来确定玩家的偏好;  某些情况下，结果与每个终端历史相连，玩家的偏好自然地定义在这些结果上，而不是直接地定义在终端历史上。



EXAMPLE 153.2 (Entry game 进入博弈)  建模

- **Players** The challenger and the incumbent. 挑战者和在位者。
- **Terminal histories** $(\text {In, Acquiesce}),(\text {In, Fight}),$ and Out.  
- **Player function** $P(\varnothing)=$ Challenger and $P(\operatorname{In})=$ Incumbent.
- **Preferences**   挑战者的偏好: $u_{1}$ ,  $u_{1}(\text { In, Acquiesce})=2, u_{1}(\text { Out })=1,$ $u_{1}(\operatorname{In}, \text { Fight})=0$  
  在位者的偏好 $u_{2}$ ,   $u_{2}(\text { Out })=2, u_{2}(\text { In, Acquiesce})=1,$ $u_{2}(\operatorname{In}, \text { Fight})=0$

这个博弈可以用一个图表示:  最上层的小圆圈,表示开始时历史是空. 下面的节点都是黑点.

<img src="/img/2020-04-18-Game.assets/image-20200506165524265.png" alt="image-20200506165524265" style="zoom:33%;" />

可以由终端历史集以及玩家函数推断出 玩家在某个时刻的可选动作集. 

$$
A(h) = \{a: (h, a) \text{ is a history } \}
$$

如上例, 历史有 $\varnothing, \operatorname{In},$ Out, $(\text { In, Acquiesce})$ and $(I n, \text { Fight})$ ;   
可选动作集:   $A(\varnothing)=\{I n, O u t\},$ $A(I n)=\{\text {Acquiesce}, \text { Fight}\}$



##### 5.2.2 Solutions

之前的进入博弈，"挑战者将进入和随后在位者将默许"似乎是很清楚的。挑战者可以这样推理, 如果自己进入，那么在位者将会默许，因为这样做的话对于在位者来说比斗争要好些。考虑到在位者将会以这种方式应对进入，挑战者进入会使自己处境更好。

论证的思路称为**反向归纳法 (backward induction)**。每当玩家必须行动时，对于他的每一个可能的行动，他推断玩家(包括他自己)随后会理性采取的行动，并且选择一个行动以产生他最喜欢的终端历史。虽然反向归纳法可以适用于上例中的博弈，但是它不能适用于每一个 完全信息展开型博弈. 

<img src="/img/2020-04-18-Game.assets/image-20200506175326829.png" alt="image-20200506175326829" style="zoom:33%;" />

对这个变体, 如果挑战者进入，在位者不在乎默许还是斗争。反向归纳法没有告诉挑战者，在这种情况下在位者将采取什么行动，于是留下来一个未解的问题:挑战者应选择什么行动. 具有无限长历史的博弈提出了关于反向归纳法的另一个难题:没有一个终端可作为归纳的出发点。完全信息展开型博弈的一个推广-- 允许玩家同时行动还提出了另一个问题:当玩家同时行动时，我们一般不能直接推断每个玩家的最优行动。 现在是回合制.

另一种定义均衡的方法是从纳什均衡的概念出发。试图对可以在稳定状态下持续的行为模式进行建模。由此得出的均衡概念适用于所有具有完全信息的扩展博弈。首先讨论的是稳态方法。稳定状态方法的结果和反向归纳法一样. 



#### 5.3 Strategies and outcomes  策略和结果

##### 5.3.1 Strategies 策略

展开型博弈的**关键概念是策略**。玩家的策略表明了对于每一个历史(在这个历史之后轮到他行动)玩家所选择的行动。

DEFINITION 157.1 (**Strategy**) A strategy of player i in an **extensive game with perfect information** is a function that assigns to each history h after which it is player i’s turn to move (i.e. P(h) = i, where P is the player function) an action in A(h) (the set of actions available after h).

下图是个例子. 表格是玩家2的所有可能策略. 

<img src="/img/2020-04-18-Game.assets/image-20200506185714297.png" alt="image-20200506185714297" style="zoom: 33%;" />



在一些博弈中，某些玩家的策略不仅仅是行动计划。

定义157.1要求任何玩家i的策略在每一个历史之后都指定了一个动作，即使对于 执行该策略过程中没有发生的历史也一样。

<img src="/img/2020-04-18-Game.assets/image-20200507002112934.png" alt="image-20200507002112934" style="zoom: 33%;" />



##### 5.3.2 Outcomes  结果

strategy profile 决定了 terminal history (不考虑随机).  记策略配置strategy profile为 $s$ ,  player function为 $P$.  起始玩家 $P(\varnothing)$ , 其 strategy 记为 $s_{P}(\varnothing),$ 选择 action $s_{P(\varnothing)}(\varnothing)$ , 记为 $a^{1}$. 如果历史history $a^{1}$ 不是 terminal, 后继玩家 $P\left(a^{1}\right)$ 行动, 策略为 $s_{P\left(a^{1}\right)}$,  action $s_{P\left(a^{1}\right)}\left(a^{1}\right)$, 记为 $a^{2}$.  若 $\left(a^{1}, a^{2}\right)$ 不是终端, 则继续..直到terminal. 我们将 terminal history 称为 $s$ 的**outcome 结果**, 记为 $O(s)$ 

例如158.1, outcome of the strategy pair $(D G, E)$ is the terminal history $D,$ and the outcome of $(C H, E)$ is the terminal history $(C, E, H)$

注意, 策略配置 $s$ 的结果$O(s)$ 仅仅依赖于玩家的行动计划, 而不是他们的全部策略. 即不需要知道那些不包含在当前历史中的策略相关部分。为了确定$O(s)$，我们不需要参考任何玩家的策略中指定他在被该策略排除的历史之后的行动的任何组成部分。 



#### 5.4 纳什均衡

对于策略博弈，纳什均衡是对玩家在**稳定状态steady state**下的行为建模。也就是说，我们寻找的行为模式是，如果每个玩家都知道其他玩家的行为，那么他没有理由改变自己的行为。对展开型博弈, 首先定义了一个纳什均衡：考虑到其他玩家的策略，没有任何一个玩家希望偏离这个策略配置。这个定义是对战略博弈中的纳什均衡的改编（21.1）。

DEFINITION 159.2  (**Nash equilibrium of extensive game with perfect information**) The strategy profile $$s^∗$$ in an extensive game with perfect information is a **Nash equilibrium** if, for every player $$i$$ and every strategy $$r_{i}$$ of player $$i$$, the terminal history $$O\left(s^{*}\right)$$ generated by $$s^{*}$$ is at least as good according to player $$i^{\prime}$$ s preferences as the terminal history $$O\left(r_{i}, s_{-i}^{*}\right)$$ generated by the strategy profile $$\left(r_{i}, s_{-i}^{*}\right)$$ in which player $$i$$ chooses $$r_{i}$$ while every other player $$j$$ chooses $$s_{j}^{*} .$$ Equivalently, for each player $$i$$
$$u_{i}\left(O\left(s^{*}\right)\right) \geq u_{i}\left(O\left(r_{i}, s_{-i}^{*}\right)\right)$$ for every strategy $$r_{i}$$ of player $$i$$ ; where $$u_{i}$$ is a payoff function that represents player $$i$$ 's preferences and $$O$$ is the outcome function of the game. 

**完全信息展开型博弈的纳什均衡** : 

若 $$u_{i}\left(O\left(s^{*}\right)\right) \geq u_{i}\left(O\left(r_{i}, s_{-i}^{*}\right)\right)$$  	对每个玩家$i$的每个策略$r_i$都成立 , 则策略配置 $$s^∗$$ 是一个纳什均衡. 



例 160.1 (Nash equilibria of the entry game) **进入博弈的纳什均衡**.  有两个纳什均衡, (In, Acquiesce) and (Out, Fight).   
第一个可以由backward induction求得.    
第二个均衡，挑战者总是选择"在外"。给定在位者进入后选择斗争的策略，"在外"是最优的策略。 给定挑战者选择"在外"策略，在位者选择"斗争"策略是最优的; 在位者选择"默许" 或"斗争"对于他的收益是无差异的。于是，没有一个玩家可以在给定其他玩家策略的情况下，通过选择不同的策略而增加自己的收益。 所以第二个均衡点成立.  其实这个点改成1,3更好理解.

<img src="/img/2020-04-18-Game.assets/image-20200507014031558.png" alt="image-20200507014031558" style="zoom: 33%;" />

纳什均衡(Out, Fight) 在策略型形式中不会出现。挑战者如何知道如果他进入的话，在位者将选择"斗争"呢?  这样解释策略型博弈是 :每当挑战者参与博弈时，即使他选择"在外"也会观察在位者的行动。   
相对的，这样解释展开型: 总是选择"Out"的挑战者绝不会观察到在位者的行动，因为在位者不会行动。  
在策略型博弈中"在给定其他玩家策略时，每个玩家的策略是最优的"。这个纳什均衡条件的基本原理是，在稳定状态中，每个玩家参与博弈的**经验**导致他关于其他玩家行动的**信念**是正确的.这个道理不适用于(展开型)进入博弈的纳什均衡点 (Out, Fight) ，因为总是选择"在外"的挑战者绝不会观察到在历史"进入"之后的在位者的行动。所以就**学习不到这个经验**.

通过考虑一个带有稍稍扰动的稳定状态，我们就可以避免解释展开型博弈纳什均衡中的这个困难，在极少数情况下，会采取非均衡的行动(也许犯错误，或者是蓄意的实验) ，而这些扰动使得每个玩家最终可以观察到每一个历史后的其他玩家的行动。鉴于这样的扰动，每个玩家最终都会学习到其他玩家的整个策略。 **相当于探索,并学习.** 

但是，如果将纳什均衡 (Out, Fight)解释为这种带扰动的稳定状态，又会遇到另一个问题。在那些(极端)场合，当挑战者进入时，在位者随后的"斗争"行为, 则博弈的余下部分并不是稳定状态: 如果挑战者进入，在位者默许比起斗争来会使自己的境况更好一些。也就是说，纳什均衡 (Out, Fight)并不对应于展开型博弈**稳健 (robust)的稳定状态**。

注意，展开型博弈体现了这样的假设,  在博弈开始时，在位者不事先表态"如果进入的话就斗争", 则他想选什么就选什么应对。如果在位者事先宣称"如果进入则斗争", 那么分析就会不同。这样的"宣言"将导致挑战者停留在外，这是一个在位者所希望的结果。没有在位者做出"许诺"的可能性，我们可以想象在位者在博弈开始时就宣告其打算斗争;但是这样的威胁是不可信的，因为在挑战者进入之后，在任者仅有的动机是默许。  这个倒是现实中挺常见的情况.



#### 5.5 Subgame perfect equilibrium 子博弈完美均衡

非常重要!!!!   这里有bellman公式的思想了.  也是因果律, 不管之前发生了什么, 我只要从现在开始利益最大化.

##### 5.5.1 Definition

纳什均衡概念忽视了展开型博弈的有序结构，其策略为在博弈开始之前一劳永逸地做出选择。结果是，前一节所提到的，纳什均衡对应的稳定状态可能不稳健。

现在，定义模拟稳键的稳定状态的均衡概念 equilibrium that models a robust steady state。这个概念要求在给定其他人的策略情况下，每个人的策略不仅在博弈开始时，而且在每一个历史时刻都是最优的。

先定义**子游戏 subgame** :  对于任意非终端历史$h$，跟随在$h$后的子博弈(subgame)是发生$h$之后留存下来的博弈部分。 即某时刻之后剩下的全部.

DEFINITION 162.1(**Subgame**)​  Let $\Gamma$ be an extensive game with perfect information, with player function $P .$ For any nonterminal history $h$ of $\Gamma,$ the **subgame** $\Gamma(h)$ following the history $h$ is the following extensive game.

- **Players**  The players in $\Gamma$ 
- **Terminal histories**  The set of all sequences $h^{\prime}$ of actions such that $\left(h, h^{\prime}\right)$ is a terminal history of $\Gamma$

- **Player function** The player $P\left(h, h^{\prime}\right)$ is assigned to each proper subhistory $h^{\prime}$ of a terminal history.

- **Preferences**  Each player prefers $h^{\prime}$ to $h^{\prime \prime}$ if and only if she prefers $\left(h, h^{\prime}\right)$ to $\left(h, h^{\prime \prime}\right)$ in $\Gamma$

注意, 空历史 $\varnothing$ 的后面的子博弈是整个博弈自身. 其他的每个子博弈都称为真子博弈. 由于对每一个非终端历史都存在一个子博弈，所以子博弈个数等于非终端历史的个数。

下面每个人不光应对整个博弈, 而是要先应对各个子博弈. 

**子博弈完美均衡**,   策略配置$$s^*$$, **在任何的子博弈中, 都是纳什均衡**.	A **subgame perfect equilibrium** is a strategy profile  $$s^*$$  with the property that in no subgame can any player $i$ do better by choosing a strategy different from $$s^*_i$$ , given that every other player j adheres to  $$s^*_j$$.

Nash equilibrium (Out, Fight) of the entry game (Example 152.1) 就不是一个 完美均衡.  因为在历史"进入"之后的子博弈中，策略"斗争"对在位者并不是最优的, 在这个子博弈中，在位者选择"默许"比选择"斗争"会使自己的处境 更好一些。 (In, Acquiesce) 则是一个完美子博弈均衡.

DEFINITION 164.1 (**Subgame perfect equilibrium 子博弈完美均衡**)  
$$
u_{i}\left(O_{h}\left(s^{*}\right)\right) \geq u_{i}\left(O_{h}\left(r_{i}, s_{-i}^{*}\right)\right) \text { for every strategy } r_{i} \text { of player } i
$$


##### 5.5.2 Subgame perfect equilibrium and Nash equilibrium 子博弈完美均衡和纳什均衡

在子博弈完美均衡中，每个人的策略是最优的。特别地，其在空历史之后是最优的. 

**每个子博弈完美均衡是纳什均衡。**

**子博弈完美衡是在每个子博弈中导致纳什均衡的策略配置。**



##### 5.5.4 Interpretation 解释

**子博弈完美均衡**对应于一个稍有扰动的稳定状态，其中， 所有人在很少的极端情况下采取非均衡行动，这样，经过长期的经验积累，每个人对于其他人的整个策略形成正确的信念，知道其他人在每个子博弈中将如何动作。给定了这些倍念，没有一个人会在博弈开始或任何历史之后希望偏离自己的策略。

子博弈完美均衡的这个解释，如同纳什均衡解释为稳定状态一样，不要求知道其他人的偏好，也不要求先考虑其他人的理性。它需要将策略解释为一个计划，这个计划是包含探索性的.  理解为 epsilon-greedy 即可.



#### 5.6 Finding subgame perfect equilibria of finite horizon games: backward induction 求有限范畴博弈的子博弈完美均衡：反向归纳法

可以通过求纳什均衡来求得一些问题的子博弈完美均衡，并检查这些均衡中的每一个是否为子博弈完美。 

定义"子博弈的长度"为子博弈中最长的历史长度。后退自纳法操作如下: 通过寻找长度为 1 的子博弈("最后的"子博弈) 中玩家的最佳行动开始。然后，把这些行动看作为给定的;  再找长度为 2 的子博弈中首先行动的玩家的最佳行动。继续直到博弈的起始阶段.   有点类似minimax

例子: 

<img src="/img/2020-04-18-Game.assets/image-20200507045804072.png" alt="image-20200507045804072" style="zoom:50%;" />

另外一个例子:

<img src="/img/2020-04-18-Game.assets/image-20200507050304696.png" alt="image-20200507050304696" style="zoom:50%;" />

(C, FHK), (C, FIK), (C, GHK), (D, GHK), (E, GHK), and (D, GIK).



### 6 完全信息展开型博弈：例







### 7 完全信息展开型博弈：延伸与讨论

#### 7.1 Allowing for simultaneous moves  同时行动

##### 7.1.1 Definition

完全信息的展开型博弈(定义 153.1)模型，假设在每一系列事件后，**单个决策者在已知每个决策者以前行动的情况下采取行动**。现在，我们描述一个更为复杂的模型，它允许我们去研究在某些事件系列后，一组决策者的成员"同时"选择他们的行动。每个成员知道每个决策者以前的行动，但是不知道该组中其他成员同时发生的行动。

例如这样的情况, 即玩家1选择C或D，然后玩家2和3同时采取行动，各自选择E或F。那么 (C, (E, E))是一个 terminal history. 在一般模型中，玩家函数为每个非终端历史分配了一组玩家。在刚才描述的例子中，这组玩家包括初始历史的玩家1，以及历史C的玩家2和3。



DEFINITION 202.1 **完全信息且同时行动的展开型博弈** An extensive game with perfect information and simultaneous moves consists of

- a set of **players** 一样
- a set of sequences (**terminal histories**) with the property that no sequence is a proper subhistory of any other sequence 一样
- a function (the **player function**) that assigns a **set of players** to every sequence that is a proper subhistory of some terminal history   映射到多个玩家
- for each **proper subhistory** h of each terminal history and each player i that is a member of the set of players assigned to h by the player function, a set $A_i(h)$ (the set of **actions available** to player i after the history h)    在t时刻能行动玩家的所有可用动作集
- for each player, **preferences** over the set of terminal histories  一样



例子, BoS变体.  首先，人1决定是留在家里看书还是参加音乐会。如果他读了一本书，游戏就结束了。如果他决定参加一场音乐会，那么，就像在BoS中一样，他和人2在不知道对方的选择的情况下，自主选择是去欣赏巴赫还是斯特拉文斯基的听觉享受。

<img src="/img/2020-04-18-Game.assets/image-20200507114542432.png" alt="image-20200507114542432" style="zoom: 33%;" />





##### 7.1.2 Strategies and Nash equilibrium

完全信息同时行动的展开型博弈的纳什均衡 定义与 没有同时行动的博弈中的定义(Definition 159.2)一样

EXAMPLE 204.1 (Nash equilibria of a variant of BoS) In the game in Example 203.1 

three pure Nash equilibria: ((Concert, B), B), ((Book, B), S), and ((Book, S), S).

记住，玩家的策略比行动计划多

<img src="/img/2020-04-18-Game.assets/image-20200507115050848.png" alt="image-20200507115050848" style="zoom: 33%;" />



##### 7.1.3 Subgame perfect equilibrium 子博弈均衡

为了求有限的具有完全信息和同时行动的展开型博弈的子博弈完美均衡集，我们可以像以前那样，使用后向归纳法。

EXAMPLE206.1(BoS 变体的纳什均衡) 考虑图204.1中的游戏。逆向归纳的过程如下。

- Concert 后, 有两个纯策略均衡 (S, S) and (B, B) 
- 如果Concert之后的子博弈的结果是 (S, S), 那玩家1在开始时的最优选择是 Book
- 如果Concert之后的子博弈的结果是 (B, B), 那玩家1在开始时的最优选择是 Concert

所以结论是, 有两个子博弈完美均衡subgame perfect equilibria: ((Book, S), S) and ((Concert, B), B).

We conclude that the game has two subgame perfect equilibria: ((Book, S), S) and ((Concert, B), B).







### 8 Coalitional Games and the Core  联合博弈及其核心

#### 8.1 Coalitional games 联合博弈

我们把每一组玩家称为**联盟coalition**，把所有玩家的联盟称为**大联盟grand coalition**。



DEFINITION 235.1 (**Coalitional game 联合博弈**) A coalitional game consists of

- a set of **players**
- for each **coalition**, a set of **actions**
- for each player, **preferences** over the set of all actions of all **coalitions** of which she is a member. 每个玩家, 在所有(其作为成员)的联盟里所有动作集上的偏好. 

常用 $N$ 表示大联盟, 以$S$表示任意一个联盟。可以通过一个描述偏好的收益函数，确定玩家的偏好。

在下面几个例子中，每个联盟控制着某种数量的物品，这些物品可以在其成员之间分配。在这样一个博弈中，联盟S的每一个行动都是S的成员之间对S所控制的物品的分配，我把它称为**S分配**的物品 **S-allocation**。我把N次分配简单地称为**分配 allocation**。

对于每一个人来说，大联盟可能达到的结果比较好(>=)。我的称这样的博弈 为"有凝聚力的cohesive"。



EXAMPLE 236.2 (**Two-player unanimity game 两人一致博弈**)  两个人一起生产一个单位(比如1公斤)的产品，他们以自己希望的任何方式分享。没有一个人可以独自生产任何产品。每个人仅关心自己获得的产品量，并且希望多多益善.

- **Players**  The two people (players 1 and 2).
- **Actions**  每个人单独行动, 但没有产出. 两个人的联合行动集 {1, 2} 是所有非负数集合($x_1, x_2$), 且$x_1 + x_2 = 1 $ 
- **Preferences**  每个人的偏好由其得到的产量来表示.

玩家集的可能划分是$$\{\{1, 2\}\}$$，由两个玩家的单一联合组成，以及$$\{\{1\},\{2\}\}$$，其中每个玩家单独行动。后者只有一种行动配置可供其使用，其产出为0。因此，这个游戏是有凝聚力的。

 

EXAMPLE 237.1 (**Landowner and workers 地主和工人**) 当使用是k个工人时，地主的庄园产量为 f(k+1)的食物，其中f是递增融数，且f(0)=0。工人的总数是m;  地主和每个劳动者只关心自己的产量多少，宁多勿少。

- **Players**  landowner and the m workers
- **Actions**  一个完全由工人组成的联盟只有一个行动，其中没有成员收到任何产量的产品。一个由地主和k个工人组成的联盟$S$的行动集合是关于产量$f(k+1)$ 的所有$S$分配的集合。
- **Preferences**  每个人的偏好由其得到的产量来表示.

这个游戏是有凝聚力的，因为大联盟的产出比其他任何一个联盟的产出都要多，而且，对于所有玩家的任何一个划分的集合，只有一个联盟有产出。



EXAMPLE237.2 (**Three-player majority game 三人多数博弈**)   三个人有 1 单位产品的分配权。组成的任何多数的联盟可以支配该产品的分配。每个人只关心他得到的量。

- **Players**   三个人
- **Actions**   由一个玩家组成的每个联盟都有一个动作，这个动作对玩家没有输出。每个由两个或三个玩家组成的联盟S的行动集就是分配一个单位产品的S分配集。
- **Preferences**  每个人的偏好由其获得量来表示.

这个游戏是有凝聚力的，因为每一个划分的玩家集最多包含一个多数联盟，而这样的联盟的每一个动作，都有一个大联盟的动作，每个玩家的产出至少是一样多的。



在这些例子中，每个联盟S的行动集就是S所能获得的产量的S分配集，每个玩家的偏好用他所获得的产量来表示。因此，我们用一个数字来概括每个联盟的行动集，这个数字等于该联盟所能获得的总产量，可以把这个数字解释为可能在联盟成员之间分配的总 "报酬"。这就是**可转移的收益transferable payoff**。



DEFINITION 236.1 ( **Cohesive coalitional game 有凝聚力的联合博弈**)   



#### 8.2 The core 核

DEFINITION 239.1 (**Core**) The core of a coalitional game is the set of actions $a_N$ of the grand coalition N such that no coalition has an action that all its members prefer to  $a_N$ .

最好的联盟行为集就是核. 





## Part II:  Games with Imperfect Information  不完全信息博弈

### 9 贝叶斯博弈

#### 9.1 Introduction

**信息不完全的策略型博弈 - 贝叶斯博弈**

纳什均衡有一条基本的假设，每个人对其他人的行动持有正确的信念。为此，玩家必须了解他正在参与的博弈;特别是要了解其他人的偏好。在许多情况下, 玩家并不完全了解对手的特征, 比如，讨价还价者可能不太清楚其他人对谈判物品的估价，企业可能不知道对方的成本函数等等。有时候，玩家可能很了解对手的特点，但可能不知道这些对手对自己的特点了解的程度。本章将介绍"贝叶斯博弈" , 它推广了策略型博弈，将帮助我们去分析如下的情况，每个玩家不完全了解与他的行为选择有关的环境。

#### 9.2 Motivational examples 启发性例子

EXAMPLE 271.1 (**Variant of BoS with imperfect information 不完全信息的 BoS 变体**) 

玩家1 不能肯定玩家 2 是否愿意一起外出，还是想躲开自己，而玩家 2 和以前例子一样，知道玩家 1 的偏好. 具体地讲，假设玩家 1认为玩家 2愿意与自己外出的可能性有1/2，躲开自己的可能性有1/2(这种判断可能是玩家 1 的经验).  即使我们只对纯策略均衡感兴趣，但由于涉及概率，分析这种情况需要知道玩家关于随机结局的偏好;表格中的数字代表玩家的贝努利收益。



![image-20200507163912064](/img/2020-04-18-Game.assets/image-20200507163912064.png)

我们可以认为存在两种**状态states** , 一个是上图左边对应的伯努利收益, 一个是右边. 玩家2知道自己的状态, 玩家1不知道, 只能每个状态给1/2的几率.

以 1 的角度，玩家 2 有两种可能的"**类型types**"，一种类型的偏好由上图的左表给出，另一种类型的在右边。 1 不知道 2 的类型，所以为了理性地选择自己的行动，必须对每种类型的行动形成一个信念。鉴于这些信念和他对每种类型的可能性的信念，他可以计算出他对每一个动作的预期回报。例如, 玩家1 觉得如果对方今天是讨厌自己的类型,会选B, 如果今天对方是喜欢自己的类型,会选S, 则自己选B的话, 对方1/2选S, 1/2选B, 所以预期收益为1/2 * 2+1/2 * 0 = 1. 自己选S, 预期收益为 1/2. 计算各种配置, 则得到下表.  其中每一列是两种类型的玩家2的行动配置, 其中第一项是想一起的, 第二项是想回避的.



<img src="/img/2020-04-18-Game.assets/image-20200507164759512.png" alt="image-20200507164759512" style="zoom:50%;" />

对于这种情况，我们定义纯策略纳什均衡为包含三个行动的行动组，其 中一个行动是人 1 的，还有两个行动分别是 2 的两个类型的，具有如下性质:

- 给定两个类型的玩家 2 的行动(以及玩家 1 关于状态的信念) , 玩家 1 的行动是最优的。
- 给定玩家 1 的行动，每一个类型的玩家 2 的行动是最优的。

也就是说，把玩家 2 的两个类型视作两个单独的玩家，并且将这种情况作为 3人策略型博弈进行分析。

我们断言，(B, (B, S))是一个纳什均衡



#### 9.3 General definitions  一般定义

##### 9.3.1 Bayesian games  贝叶斯博弈

DEFINITION 277.1  A Bayesian game consists of

- a set of **players** 
- a set of **states**

and for each player

- a set of **actions**
- a set of **signals** that she may receive and a **signal function** that associates a signal with each state
- for each signal that she may receive, a **belief** about the states consistent with the signal (a probability distribution over the set of states with which the signal is associated)
- a **Bernoulli payoff function** over pairs (a, ω), where a is an **action profile** and ω is a **state**, the expected value of which represents the player’s **preferences among lotteries** over the set of such pairs.



对 例 271.1 建模 

- **Players** The pair of people.
- **States** The set of states is $\{\text {meet, avoid}\}$
- **Actions** The set of actions of each player is $\{B, S\}$
- **Signals** Player 1 may receive a single signal, say $z$ ; her **signal function** $\tau_{1}$ satisfies $\tau_{1}(\text {meet})=\tau_{1}(\text {avoid})=z$ .两个状态的值一样,无法区分;  Player 2 receives one of two signals, say $m$ and $v$ ; her signal function $\tau_{2}$ satisfies $\tau_{2}(\text { meet})=m$ and $\tau_{2}(\text {avoid})=v$
- **Beliefs**  Player 1 assigns probability $\frac{1}{2}$ to each state after receiving the signal $z$ Player 2 assigns probability 1 to the state meet after receiving the signal $m$ and probability 1 to the state avoid after receiving the signal $v$
- **Payoffs**  The payoffs $u_{i}(a, \text { meet})$ of each player $i$ for all possible action pairs are given in the left panel of Figure 272.1 , and the payoffs $u_{i}(a, \text { avoid })$ are given in the right panel.



##### 9.3.2 Nash equilibrium

In a general game, denote the probability assigned by the belief of type $t_{i}$ of player $i$ to state $\omega$ by $\operatorname{Pr}\left(\omega \vert t_{i}\right) .$ 在某个状态的概率. Denote the action taken by each type $t_{j}$ of each player $j$ by $a\left(j, t_{j}\right) $.某状态下的动作.  Player $j$ 's signal in state $\omega$ is $\tau_{j}(\omega),$ so her action in state $\omega$ is $a\left(j, \tau_{j}(\omega)\right) .$ For each state $\omega,$ denote by $\hat{a}(\omega)$ the action profile in which each player $j$ chooses the action $a\left(j, \tau_{j}(\omega)\right) .$ Then the expected payoff of type $t_{i}$ of player $i$ when she chooses the action $a_{i}$ is  玩家i选择a的期望收益

$$
\sum_{\omega \in \Omega} \operatorname{Pr}\left(\omega | t_{i}\right) u_{i}\left(\left(a_{i}, \hat{a}_{-i}(\omega)\right), \omega\right)
$$

$\Omega$  set of states ,  $$\left(a_{i}, \hat{a}_{-i}(\omega)\right)$$ action profile,  every other player $j$ chooses $$\hat{a}_{j}(\omega) $$  


DEFINITION 280.1 A **Nash equilibrium of a Bayesian game** is a Nash equilibrium of the strategic game (with vNM preferences) defined as follows.

- **Players** The set of all pairs $\left(i, t_{i}\right)$ where $i$ is a player in the Bayesian game and $t_{i}$ is one of the signals that $i$ may receive. 
- **Actions** The set of actions of each player $\left(i, t_{i}\right)$ is the set of actions of player $i$ in the Bayesian game.
- **Preferences** The Bernoulli payoff function of each player $\left(i, t_{i}\right)$ is given by (279.1)   收益函数是上式. 

就是之前的加上了Bernoulli期望. 



#### 9.7 Illustration: auctions 拍卖



### 10 Extensive Games with Imperfect Information 不完全信息展开型博弈

本章只找到中文版



**dynamic Bayesian games** = **dynamic/extensive games of incomplete information**

当每个人选择行动时，可能不知道其他人以前的行动。



#### 10.1   Extensive games with imperfect information  不完全信息展开型博弈

为描述不完全信息展开型博弈， 相比完全信息博弈 , 必须添加一条:每一个玩家关于在他行动的每一时刻的历史信息的说明。以 $H_i$ 表示历史的集合，玩家 i 在这之后采取行动。通过将$H_i$划分(分隔)为若干**信息集 information set**的集成来确定玩家 i 的信息。这种集成称为玩家 i 的信息划分。玩家 i 在作出决策时，知道所发生的信息集，但不知道在该信息集中发生的是哪个历史。

**信息集之间可以区分, 信息集内部无法区分!!**



Definition: An **information set (信息集)** of a player is a collection of **decision nodes** (or **histories**) satisfying the following two conditions:

1. the player has the move at every node in the information set
2. when the play of the game reaches a node in the information set, the player with the move does not know which node in the information set has been reached, unless the information set is a singleton (单点, containing only one decision node).



例如，假设玩家 i 在历史 $C, D$ 和 $E$ , 即 $[H_i=\{C, D, E\}]$ 之后行动 。 

- 如果历史 C 发生过，那么他知道 C 已经发生，而如果D 或者 E 发生过，那么他只知道 D 或E 中有一个发生, 但不能明确知道是哪一个。于是玩家 $i$ 的**信息划分**由两个**信息集**组成: $\{C\}$ 和 $\{D, E\}$ 。
- 若他对哪个历史发生过全都不知道，那么他的信息划分由单一的信息集组成，即$\{C, D, E\}$.  
- 如果他正确地知道历史,那么他的信息划分就由三个信息集 $\{C\}$, $\{D\}$, $\{E\}$  组成

如前所述,将在历史 $h$ 之后行动的玩家的可使用行动集合记作 $A(h)$ 。只有当 $A(h)=A\left(h^{\prime}\right)$ 时 $,$ 我们认为两个历史 $h$ 和 $h^{\prime}$ 在同一个信息集中。为什么呢？在任何历史之后行动的玩家必须知道在该历史之后他可使用的行动集，因此如果 h 和 h'在同一个信息集中,并且 $A(h) \neq$ $A\left(h^{\prime}\right),$ 那么在这个信息集上采取行动的玩家可以通过观案他可使用的行动来推断在这两个历史中发生了哪一个历史。 如果包含 $h$ 和 $h^{\prime}$ 的信息集是 $I_{i}$ ,那么记 $A(h)$ 和 $A\left(h^{\prime}\right)$ 的共同部分为 $A\left(I_{i}\right)$ ; 也就是说，$A\left(I_{i}\right)$是玩家 i 在他的信息集 $I_{i}$ 上可供选择的行动集。 

许多不完全信息展开型博弈含有随机的行动， 考虑到随机行动的出现，结局outcome就是在terminal历史集合上的随机结果,因此每个玩家的偏好必定在这些随机结局上确定。 

定义 10.1(展开型博弈) （具有不完全信息和随机行动的）展开型博弈包含:

- **玩家**集合
- (终端**历史**的)序列集
- **玩家函数** : 它将玩家或“机会 chance"分配给某些终端历史的真子历史的每一个序列; 如果是chance, 则chance 随机选择动作. 
- 对于玩家函数分配给“机会chance”的每个历史,有一个**函数**对这个历史之后的可**选择行动**分配一个**概率分布**。它具有如下性质:每一个这样的概率分布独立于每一个其他的分布 。
- 对于每个玩家，由玩家函数分配给这个玩家有关历史集合的划分(玩家的信息划分)，使得对于在划分的任何给定成员中的每一个历史， 可使用的**行动集** $A(h)$是一样的
- 对于每个玩家，有终端历史的随机结局集合上的**偏好** 



先考虑最简单的imperfect展开型博弈可以建模为imperfect 策略型博弈的情况，其中每个玩家行动一次，并且没有一个玩家在行动时知道任何其他人的行动. 

例,  将BoS建模为imperfect 展开型博弈. 玩家相继选择各自的行动,但第二个行动者不知道第一个人的选择.

- 玩家:  1, 2
- terminal history:   (B，B)、(B，S)、(S，B) , (S，S)
- 玩家函数:  $P(\varnothing) = 1, P(S) = P(B) = 2$ 
- 机会行动:  无
- 信息划分:  玩家1的信息划分只包含 $\varnothing$ ;  玩家2的信息划分包含单一的信息集 $$\{B, S\}$$
- 偏好   

博弈如图所示，在每个终端历史下方的数字是伯努利收益，其期望值描述了玩家关于随机结局的偏好。连接 B S 的**虚线**表示这两个历史处于玩家2 的**同一个信息集中**。

<img src="/img/2020-04-18-Game.assets/image-20200509192550735.png" alt="image-20200509192550735" style="zoom: 50%;" />



重要例子, 理解chance  (一个纸牌游戏) : 两个玩家各bet 1 美元开始游戏。然后玩家1发到一张牌，这张牌有同等概率为"王牌"与"小牌", 玩家2 看不到这张牌。玩家1可以"摊牌"，或"追加bet"。如果他选择前者就就向玩家 2 展示他的牌。 如果大王, 玩家1赢钱, 如果小牌,玩家2赢钱, 玩家2过程中没有动作就结束.    如果玩家1追加赌注, 再押1美元, 玩家2可以放弃或者跟注. 如果放弃, 玩家1赢钱; 若跟进, 也再押1美元, 然后玩家1必须摊牌. 

如图, 玩家1有两个信息集,  王牌, 小牌;  玩家2 有两个信息集,  (王牌, 追加) , (小牌, 追加) ; 这个信息集 反映了玩家 2 不能看到手牌这一事实。注意，对玩家2, 在信息集内每一个历史的行动集是相同的。

<img src="/img/2020-04-18-Game.assets/image-20200509194128767.png" alt="image-20200509194128767" style="zoom:50%;" />

在这些例子中，其中一个玩家拥有包含不止一个历史的信息集。每个玩家的每个信息集包含单个历史的博弈等价于其有完全信息的展开理博弈。

例,  进入博弈的变种 , 挑战者有三种选择: 在外面，准备好了再进入，无准备地进入。准备是昂贵的，但减少了斗争的损失。 不管进入者准备与否，在位者宁愿默许而不想斗争。在位者观察到挑战者是否进入，但现察不到进入者准备与否。 建模如下图.  挑战者的信息集由空集组成，在位者的信患集由"准备" 和"无准备"这两个历史组成. 这里少了Out后的结果

<img src="/img/2020-04-18-Game.assets/image-20200509234603670.png" alt="image-20200509234603670" style="zoom:50%;" />



#### 10.2	Strategies  策略

策略确定了每当轮到玩家行动时所来取的行动. 

定义 10.6 (展开型博弈的策略) 在展开型博弈中，玩家 i 的一个(纯)策略是这样的一个函数，它对玩家 i 的每一个信息集 $I_i$ 分配一个$A(I_i)$   (玩家 i 在信息集 $I_i$ 中可选择的行动集〉中的行动。

上面例子中,  BoS中, 每个玩家有两个策略, B和S ;   纸牌, 玩家1 有两个信息集 大牌,小牌, 每个信息集上有两个行动, 加注,摊牌 , 因此有4个策略 ((大)加注, (小)加注), ((大)加注, (小)摊牌), ((大)摊牌, (小)加注),((大)摊牌,(小)摊牌); 玩家2有2个策略: 跟进, 放弃



如果允许混合策略. 

定义 10.8 (展开型博弈的混合策略) 在展开型博弈中，玩家的混合策略是在纯策略上的一个概率分布。

所以, 混合策略包含了概率为1的纯策略.



#### 10.3	Nash equilibrium   纳什均衡

定义 10.9 (**展开型博弈的纳什均衡**) 展开型博弈的混合策略配置$$\alpha^*$$ 如果满足下述条件，则称为**(混合策略)纳什均衡**: 对于每一个玩家 $i$ 和 玩家$i$的每一个混合策略$\alpha_i$,  玩家i关于$$\alpha^*$$的期望收益至少与$$(\alpha_i, \alpha_{-i}^*)$$的期望收益一样大。

求展开型博弈纳什均衡的一个方法是构造博弈的策略型形式，并且将它作为一个策略型博弈来分析.

例题 10.10(BoS 作为展开型博弈)   博弈有两个纯纳什均衡(B,B)和(S,S),  以及一个混合均衡，玩家1 以 $\frac{2}{3}$ 采用 $B$, 玩家 2 以 $\frac{1}{3}$ 采用 $B$  .  这个例子, 玩家 2 在采取行动时,不知道玩家 1 所选择的行动。 玩家 2 信息的空缺体现在他的信息集中,它包含了历史 B 和历史 S 这两个部分.  但是, 即使玩家 2 不知道玩家 1 的行动，他的**博弈经验**也会告诉他**预期的历史**(或关于历史的概率分布)。关键在于，玩家的信息划分反映了他在博弈时对另一个玩家行动的观察所得出的信息; 他的博弈经验使他产生有关其他玩家的稳定状态行动的更多信患。

例题 10.11(纸牌游戏)   10.3的例子, 策略形式如下图. 0和博弈.

<img src="/img/2020-04-18-Game.assets/image-20200510044458414.png" alt="image-20200510044458414" style="zoom:50%;" />

该例没有纯策略的均衡, 因为各个点都会跑向其他地方.  玩家1的策略(摊牌，摊牌) **严劣**于 1/2(加注,加注), 1/2(加注,摊牌) 这一混合策略. 因此, 在任何纳什均衡中, 玩家1不会选择该纯策略.   玩家1的策略(摊牌,加注) 对于玩家 2 分配正概率给“跟进”的任何混合策略不是一个最优反应,  所以, 考虑到没有纯策略的均衡，在所有的纳什均衡中，玩家1一定在(加注，加注)和(加注，摊牌)之间随机选择。令p为玩家1选择(加,加)的概率, q为玩家2 选放弃的概率. 因为达到均衡以后,  玩家1的每个动作的预期收益都是一样; 玩家2也同样. 所以有 $q=\frac{1}{2}(1-q)$ 和 $-p=-\frac{1}{2}(1-p)$  ,   求得 $p=q=\frac{1}{3}$ .



例 10.14 (承诺与可观察性) 两个人各有两个动作，X 和 Y。他们关于四个行动对的收益如下:

<img src="/img/2020-04-18-Game.assets/image-20200510060534355.png" alt="image-20200510060534355" style="zoom: 67%;" />

首先, 假设他们同时选择行动。模拟该情况的策略型博弈有唯一的均衡,   Y, Y。(注意,对于玩家 1 来说, X 严劣于 Y) 

现在, 假设玩家先后选择行动，玩家 1 最先选择, 玩家 2 在 选择自己的行动之前观察到玩家 1 的行动。将这种情况建模而成的完全信息展开型博弈有单一的子博弈完美均衡，X, X。在这个均衡中,玩家 1 的收益好于他在同时行动博弈的均衡中的。

最后，假设玩家 1 最先行动，不过他的行动没有被玩家 2 完全观察到。如果玩家 1 选择了 X，玩家 2 可能认为他选择的是 Y,或者情况正 好相反。我们可以将这种情况建模为不完全信息展开型博卒,其中玩家 1 的行动后面跟随一个**随机行动**，它选择可被玩家 2 观察到的**信号**。玩家 2 观察到的是信号而不是玩家 1 的行动。假定信号为正确的概率关于两个行动是一样的，且小于 1。将此概率记作 1 - $\varepsilon$ 。(于是,如果玩家 1 选择 $X$, 那么信号为 $X$ 的概率是 $1-\varepsilon$,信号为 $Y$ 的概率是 $\varepsilon$ ; 对Y也一样 ) 。假设 $0 \leqslant \varepsilon<\frac{1}{4}$  

这个展开型博弈和它的策略型形式，以及它的纳什均衡都显示在图10.6中。玩家2的策略,$IJ$,表示玩家2看到了信号X之后,选择$I$, 看到信号Y之后,选择$J$;      因为玩家2没法看到玩家1的情况, 其extensive策略只能以这种方式表现.

特别地，我们看到,对所有满足 0 $\leqslant \varepsilon<\frac{1}{4}$ 的 $\varepsilon,$  有一个纯策略纳什均衡 ( $Y, Y Y)$ 

> 即,玩家2如果看不到玩家1的行动, 那么跟一起行动其实差不多.

![image-20200510142529882](/img/2020-04-18-Game.assets/image-20200510142529882.png)



概括地说，玩家 1 先行动以及他的行动完全可被观察的博弈有唯一的子博弈完美均衡，X, X.   玩家1的行动可观察, 但存在误差的博弈有一个纯策略纳什均衡，其结局是不管误差有多小,两个人都选Y.

因此，如在完全信息博弈的子博弈完美均衡中所显示的作为，先动者通过承诺获益的优势，在第二行动的玩家对先动者行动的观察即使有一点点不完全，情况的博弈中的纯策略纳什均衡里完全丧失殆尽???。为什么呢?  
假定玩家1 和 2 都选择Y，并且考虑玩家1 转向 X 的含义。在完全信息博弈中，玩家 2"观察到 X"与均衡是不相容的: 他会将这种情况解释为发生了偏差。对此，他通过选择 X 做出最优反应，使得玩家 1 的这个"偏差" 是值得的。在不完全信息博弈中，玩家 2"观察到X"与均衡是相容的: 他将这种情况解释为一个错误的信号(无论这样的信号多么不可能) ，并继续选择 Y，使得玩家 1 的偏离不利于玩家 1 自己. 

我们看到，在所有的完全信息展开博弈中，纳什均衡概念是不够的，我们提出了子博弈完美均衡的概念去处理问题。我们怎样把子博弈完美均衡的思想延伸到更广泛的 具有(可能)不完全信息的展开型博弈中去呢?



例题10.15(进入博弈) 

<img src="/img/2020-04-18-Game.assets/image-20200510205907796.png" alt="image-20200510205907796" style="zoom:50%;" />

博弈有两个纯策略纳什均衡， (无准备，默许) 和(在外，斗争) ,还一个混合策略纳什均衡，其中，挑战者采用纯策略 在外，而在位者给 默许 的概率至多为1/2 . 

如在第五章中研究的具有完全信息的进入博弈的版本中，纳什均衡(在外，斗争〉似乎是不合理的。倘若事实上挑战者进入，在位者的最优反应是"默许"。在具有完 全信息的博弈中，我们通过定义子博弈完美均衡概念剔除了这种均衡，因为 子博弈完美均衡要求，对于轮到玩家行动的每个历史，在给定其他玩家 的策略时，玩家的策略是最佳的，而不管当  玩家坚持他们的策略时这个 历史是否发生。 

这个思想关于不完全信息博弈的自然推广，要求每个玩家在其每个信息集上的策略是最优的。

在其他博弈中，这个思想的贯彻不是直接的，因为在信息集上行动的最优性可能取决于已经发生的历史。

下面一个变体，其中在位 喜欢斗争甚于 默许一个无准备的进入者. 

<img src="/img/2020-04-18-Game.assets/image-20200510224622459.png" alt="image-20200510224622459" style="zoom:50%;" />





#### 10.4	Beliefs and sequential equilibrium    信念和连续均衡

策略型博弈的纳什均衡可以用两个条件来刻画:  每个玩家在给定他 关于其他玩家的倍念时选择的最优行动，和每个玩家的信念都是正确的。现在对展开型博弈定义的均衡概念体现了问样的两个要求，并且像完全信息展开型搏弈的子搏弈完美均衡概念一样，强调在玩家必须选择行动的每一点，它们都成立。在精确定义策略型博弈的纳什均衡时，我们不必将玩家的信念与他们的策略分开来考虑，因为"**信念是正确的**"这个要求完全确定了它们:**每个玩家关于其他玩家策略的信念简单地等于那个策略**。对于展开型博弈，正如我们在图 10. 8 中的博弈中已经看到的那样，玩家策略不能完全确定他们的信念。因此，导致我们对策略配置和信念集合组成的"配置"来定义均衡概念。

##### 10.4.1 信念

两种叫法.

A **belief system (认知系统)** in an extensive game is a function that assigns to each information set of each player a probability distribution over the histories (or decision nodes) in that information set.

定义 10.16 展开型博弈中的**信念体系 belief system**是一个函数，它给每个信息集分配一个在那个信息集上的历史的模率分布。

就是, 玩家无法区分的一个信息集, 那么, 自己认为的, 这个信息集里面每个历史的概率.

例如，考虑例题 10.5 中的进入博弈。有两个信患集:一个包含 空历史，另一个包含"准备"和"无准备"这两个历史。因此，博弈的信念体系由 一对概率分布组成:一个分配概率 1 到空历史(挑战者在博弈起始时的信念) , 另一个分配概率到历史"准备"和"无准备"(挑战者进入之后，在位者的信念)。



##### 10.4.2 策略

对一个信息集分配一个该信息集中可使用行动的概率分布。称这样的映射为"行为策略"  (***behavioral* strategy**) 。

A **behavioral strategy (行为策略)** of player i in an extensive game is a function that assigns to each of i’s information set (denoted as $I_i$) a probability distribution over the set of actions to player i at that information set (denoted as $A(I_i)$), with the property that each probability distribution is independent of every other distribution.

定义 10. 17(展开型博弈中的行为策略) 展开型博弈中玩家 i 的行为策略是一个函数，为玩家 i 的每一个信息集$I_i$ 分配一个 $A(I_i)$中行动上的概率分布，具有"每个概率分布与其他每个分布独立"的性质。

每个概率分布分配概率 1 至单一行动的行为策略与纯策略等价 ; 在研究的所有博弈中，混合策略与行为策略是等价的.

**Difference** between **behavioral strategy** and **mixed strategy**: a mixed strategy refers to a probability distribution over pure strategies, whereas a behavioral strategy refers to the collection of probability distributions over the actions at the information sets.



##### 10.4.3 均衡

An **assessment (评估)** in an extensive game is a pair consisting of (1) a profile of (behavioral) strategies and (2) a belief system.

定义 [**评估 (Assessment)**] 展开型博弈中的"评估"是由行为策略配置和信念体系组成的"对"

如果 评估 满足下述两个条件, 那么它是一个均衡:

1. **Sequential rationality (连续理性; 序贯理性)**: each player’s strategy is optimal whenever she has to move, given her beliefs and the other players’ strategies.  
   - The strategy has to be optimal in every information set, regardless of whether that information set is reached if the players follow their strategies.
2. **Consistency of beliefs with strategies(信念与策略一致)**: each player’s belief is consistent with the strategy profile. 每个玩家的信念与策略配置是一致的。
   - Each player’s belief must be correct in equilibrium.



下图中的例子,  假设玩家1 的策略,  开始时选取 E，在历史 (C，F)之后选择 $J$ ; 玩家2关于玩家1的信念玩家1会2/3选C, 1/3选D; 连续理性要求:给定由玩家1的策略所确定的后续行为，即使当玩家1遵循自己的策略时玩家2的信息集达不到，但是玩家2在这个信息集上的策略应当是最优的.   给定了玩家 2 的信念,在从玩家2的信息集出发的博弈部分,关于策略 $F$ 的期望盈利是 $\frac{2}{3} \cdot 0+\frac{1}{3} \cdot 1=\frac{1}{3}$ , 关于策略$G$ 的期望盈利是 $\frac{2}{3} \cdot 1+\frac{1}{3} \cdot 0=\frac{2}{3}$ 。 因此,连续理性要求她选择 $G$ . 在给定 2 的策略下, 连续理性也要求 1 在他的两个信息集上的策略是最优的。1 在历史(C,F)之后的最优行动是 $J$ ; 如 2 的策略是 G , 那么 1 在开始时的最优行动是 $D$ 和 $E$  ; 于是,给定了 2 的策略 G,  1 有两个最优策略一 $DJ$ 和 $E J$



<img src="/img/2020-04-18-Game.assets/image-20200511014917272.png" alt="image-20200511014917272" style="zoom: 33%;" />



记, **behavioral strategy profile** as $\beta$ and a **belief system** as $\mu$ , $I_i$ 为玩家i的一个信息集. 若$I_i$中每个历史发生的概率就是 $\mu_i$ , 并且随后玩家坚持策略 $\beta$, 那么得到的terminal 历史上的一个概率分布, 记为 $O_{l_i}(\beta, \mu)$ ;   

玩家的信念与策略一致的要求是新的。其思想是，在一个稳定状态中，每个玩家的**信念必须是正确的: 玩家认为任何历史发生的概率必定 等于 当玩家坚持她们的策略时这个历史真实发生的概率**。 如果玩家遵循策略，那么在达到的信息集中，这一思想是显然的; 但是，在玩家遵循策略而没有能够达到的信息集上，这一思想就不那么清楚了。 

**基于统计一致的信念**; 下面精确地阐述一致(相容)要求，**把信念体系仅限制在如果每个玩家坚持自己的策略将以正概率达到的信息集上**。明确地讲，由在这样的信息集上行动的玩家的信念指派给该信息集中每个历史$$h^*$$的概率， 应该等于在到达信息集的条件下按照策略使$$h^*$$发生的概率。
$$
\frac{P\left(h^{*} \text { according to } \beta\right)}{\sum_{h \in I_{i}} P(h \text { according to } \beta)}  \tag{10.19}
$$
再考虑上图的博弈,  如果玩家1的策略在开始时选行动 E，则根据一致性要求, 对 2 的信念没有限制，can hold any belief at her information set. 因为根本没走到,没应对不用管.  
然而，如 1 在开始时的 概率p 选C ,  q选D, 1-p-q 选E;  那么 $Pr(C  \text { according to } \beta)=p$,  $Pr(D) = q$ , 那么根据上面公式,  玩家2的信念则为 : p/(p+q) 到C,  q/(p+q) 到D. 



例题 10.20(BoS 中的一致信念) 例10.2, 对于1 的每一个策略, 2 的信息集以概率 1 达到。在这个博弈中,一致性(或相容性)要求 2 的信念总是正确的。对于所有同时行动的任何博弈,这个结论都成立。

例题 10.21(纸牌游戏中的相容性信念)  例10.3, 如果玩家 1 不管自己的牌是“王牌”还是“小牌”,她的策略都是选取“摊牌”,  那么相容性条件不限制玩家 2 的信念,因为玩家 2 的信息集达不到。 如果 1 的牌是“王牌”,选“加注”的概率记作 $p_{H},$ 如果玩家 1 的牌 是“小王”, 选择“加注”的概率记为 $p_{L}$ 。那么,$Pr (按照 \beta 发生(王牌, 加注))= \frac{1}{2} p_{H}, \operatorname{Pr}(\text { 按照 } \beta \text { 发生(小王,追加堵注) })=\frac{1}{2} p_{L}$ 。因此,玩家 2 的信念指派概率 $p_{H} /\left(p_{H}+p_{L}\right)$ 到历史 $H$ ,  指派概率 $p_{L} /\left(p_{H}+p_{L}\right)$ 到历史 $L$ .



<img src="/img/2020-04-18-Game.assets/image-20200511014917272.png" alt="image-20200511014917272" style="zoom: 33%;" />

例题 10.22(进入博弈的相容性信念) 记 $p_{R}, p_{U}$ 和 $p_{O}$ 为挑战者指派到“准备”、"无准备”和“在外”的概率。  
如果 $p_{O}=1,$ 相容性条件不限制在位者的信念。  
否则, 条件要求指派概率 $p_{R} /\left(p_{R}+p_{U}\right)$ 到“准备”,指派概率 $p_{U} /\left(p_{R}+p_{U}\right)$ 到“无准备”。



定义 : an **assessment 评估** $(\beta, \mu)$ is a **weak sequential equilibrium 弱连续均衡** if it satisfies the following two conditions:

1. **Sequential rationality 连续理性**: for each player $i$ and each information set $l_{i}$ of player $i,$ her expected payoff to the probability distribution $O_{l_i}(\beta, \mu)$ over terminal histories generated by her belief $\mu_{i}$ and $l_{i}$ and the behavior prescribed subsequently by the strategy profile $\beta$ is at least as large as her expected payoff to the probability distribution $O_{l_i}\left(\left(\gamma_{i}, \beta_{-i}\right), \mu\right)$ generated by her belief $\mu_{i}$ at $l_{i}$ and the behavior prescribed subsequently by the strategy profile $\left(\gamma_{i}, \beta_{-i}\right),$ for each of her behavioral strategies $\gamma_{i}$    
   对每个人, 在该评估下, 预期收益是最好的.>理性
2. **Weak consistency of beliefs with strategies 弱信念与策略一致性** : for every information set $I_i$ reached with positive probability given the strategy profile $β$, the probability assigned by the belief system to each history $$h^*$$ in $I_i$ is given by (10.19).  
   即信念是基于概率统计的.



<img src="/img/2020-04-18-Game.assets/image-20200511014917272.png" alt="image-20200511014917272" style="zoom: 33%;" />

该例, 体现了弱连续均衡.  

1. 给定 2 的策略 G，1 的策略 EJ 是序贯理性的;  给定图上玩家2的信念以及玩家1的策略 EJ, 玩家2的策略G是 连续理性的.  进而, 玩家2的信念与策略配置(EJ,G) 一致. 因此,该博弈有一个弱连续均衡, 其中策略是(EJ,G), 信念是上图的(或者其他使得能选G的信念). 
2. 对(DJ,G) ,  对玩家2的G, 玩1是连续理性的; 给定玩2的信念与玩1的策略, 玩2 策略是连续理性; 但玩2信念与策略配置不一致.   唯一一致的信念是概率1到D, 使得玩2的F是最优.

在完全信息的展开型博弈中，只有一个信念体系是可能的: 每一个玩家在每个信息集上相信"单一适合的历史以概率 1 发生"。

**在完全信息的展开型博弈中，任意弱连续均衡的策略配置就是子博弈完美均衡。**

**任何弱连续均衡的策略配置是纳什均衡。**



#### 10.5	Signaling games   信号博弈

**Signaling game**: 有些玩家对影响到每个人的变量都是知情的，而其他玩家则不知道。知情的玩家（"发送者sender"）先采取行动，而不知情的玩家（"接收者receiver"）在观察到知情玩家的行动后采取行动。知情玩家的行动可能会给他们的信息（例如，他们的类型）发出 "信号signal"。 

这样的情况可以建模为展开型博弈，其中发送者有若干个可能的"类型"，每一个类型对应于她知道的变数的一个值。她观察到的值，也就是她的类型，由随机的方式确定。接收者观察不到发送者的类型，可是能看到发送者所采取的行动，然后接收者自己再采取行动。



例10.27(进入作为信号博奔)  挑战者 呈现"强"的概率等于p，而呈现"弱"的概率为 1-p ;挑战者知道自己的类型，可是在位者并不知道。挑战者要么"准备"，要么保持"无准备"状态。(没有 "外面"的选择。) 在位者观察到挑战者是否准备就绪，但观察不到她的类型 . 

<img src="/img/2020-04-18-Game.assets/image-20200511120127099.png" alt="image-20200511120127099" style="zoom:50%;" />

<img src="/img/2020-04-18-Game.assets/image-20200511120206589.png" alt="image-20200511120206589" style="zoom:50%;" />

现在求这个博弈的纯弱序贯均衡。  



概括来说，博弈有两类弱序贯均衡。 倘若挑战者强，她就选择"准备"，而如果挑战者是弱的, 就选择"无准备"。在位者相信，有准备的挑战者是强的，而无准备的为弱的，并且默许有准备的挑战者, 对无准备的挑战者斗争。



这个例子描述了可能存在于信号博弈中的两类纯策略均衡: 











#### 10.6	Illustration: conspicuous expenditure as a signal of quality   

#### 10.7	Illustration: education as a signal of ability   

#### 10.8	Illustration: strategic information transmission   

#### 10.9	Illustration: agenda control with imperfect information   







## Part III: Variants and Extensions  变体和推广

### 11 Strictly Competitive Games and Maxminimization 严格竞争博弈和最大最小化

**minimax: 悲观保守**  非常重要的方法.



纳什均衡, 其思想是，每个玩家通过自己与各种对手的博弈经验，知道游戏中其他玩家会采取的行动，并根据这些知识选择自己的行动。
在本章和下一章中，我们从不同的角度来研究博弈的可能结果。我们考虑每个博弈者对其他博弈者的行动所形成的信念，不是从他的经验出发，而是从他对博弈的分析出发，来考虑其意义。
这一章重点讨论的是严格意义上的二人游戏，在这种游戏中，玩家的利益是截然相反的。在这种博弈中，一个简单的决策程序导致每个玩家选择一个纳什均衡行动。



#### 11.1  Maxminimization  最大最小化

你**第一次**面临博弈;**对于你的对手**将采取什么行动**没有任何信念**。你应该怎样选择你的行动呢?给你一个非常**保守的方案** :对于你的每一个行 动，当其他玩家的行动变化时，找出对你来说是最差的结局，然后在这些最差的结局中找出一个最好的，相应的行动就是你的选择。这种方法称为 "**最大最小化maxminimization**"法。

DEFINITION 336.1  A **maxminimizing mixed strategy** for player $i$ in a strategic game (with vNM payoffs) is a mixed strategy $\alpha_{i}^{*}$ that solves the problem

$$
\max_{\alpha_{i}} \min_{\alpha_{-i}} U_{i}\left(\alpha_{i}, \alpha_{-i}\right)
$$

where $U_{i}$ is player $i$ 's vNM payoff function.

一句话，玩家$i$的最大最小化策略是, 无论他做什么，其他玩家都会以最小化他的预期回报的方式行动, 在这样**悲观的假设下**, 去最大化了自己的回报. 



另一个角度看到minimax.  如果一个混合策略保证玩家i 的回报保障是$$\bar{u}_{i}$$ , 那么不管其他玩家采样什么策略, 即:
$$u_{i}\left(\alpha_{i}, \alpha_{-i}\right) \geq \bar{u}_{i}$$ for every list $$\alpha_{-i}$$ of the other players' mixed strategies. 

minimax策略能够最大限度地保证玩家的回报: 如果 $\alpha_{i}^{*}$ 是minimax策略, 则有
$$\min _{\alpha_{-i}} u_{i}\left(\alpha_{i}^{*}, \alpha_{-i}\right) \geq \min _{\alpha_{-i}} u_{i}\left(\alpha_{i}, \alpha_{-i}\right)$$ for every mixed strategy $\alpha_{i}$ of player $i$

**就是说, minimax是所有策略里面,  玩家能得到最好的回报保障.**



EXAMPLE 337.1  maxminimizers的例子. 

<img src="/img/2020-04-18-Game.assets/image-20200508011853619.png" alt="image-20200508011853619" style="zoom:33%;" />

显然, 如果策略限制玩家1要么选择T,要么选择B, 最坏的情况, 收益保障是-1.  然后, 玩家1在T和B中随机化, 收益可能更好一点. 比如1/2选T, 1/2选B, 则玩家2固定选择L,玩家1的预期收益是1/2, 玩家2选择R,玩家1的预期收益是0;   令$p$ 为玩家1选择T的概率.  下图中两条线分别表示玩家2选择L,R时候,玩家1的随着p的改变的收益. 黑色的倒V线表示玩家1所能获得的被玩家2针对下的收益保障,即 $\min_{\alpha_2}u_1(\alpha_1,\alpha_2)$  , 而玩家1需要max这个保障, 所以选择p=2/5. 

<img src="/img/2020-04-18-Game.assets/image-20200508012459016.png" alt="image-20200508012459016" style="zoom: 33%;" />



#### 11.2  Maxminimization and Nash equilibrium  最大最小化与纳什均衡

下面讨论纳什均衡与minimax策略之间的关系.  重要结论

**LEMMA 338.1**  **对策略博弈, 任何纳什均衡策略的收益都大于等于minimax策略的收益**.  *The payoff of each player in any Nash equilibrium of a strategic game is at least equal to her maxminimized payoff*. 
Proof.  Let $$\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right)$$ be a Nash equilibrium. Consider player 1. First note that by the definition of a Nash equilibrium, 
$$U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right) \geq U_{1}\left(\alpha_{1}, \alpha_{2}^{*}\right)$$ 	for every mixed strategy $$\alpha_{1}$$ of player 1
so that
$$U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right) \geq \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)$$ 	for every mixed strategy $$\alpha_{1}$$ of player 1
since the inequality holds for every mixed strategy $$\alpha_{1}$$ of player 1,  we conclude that
$$
U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right) \geq \max _{\alpha_{1}} \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)
$$



#### 11.3 Strictly competitive games 严格竞争博弈

在许多博弈中，玩家没有充分的理由去相信其他人将采取使其收益最小化的行动。可是在玩家的利益完全对立的两人博弈中，这个假设是合理的 . 

DEFINITION 339.1 (**序数偏好的严格竞争策略型博弈 Strictly competitive strategic game with ordinal preferences**)  一个策略型博弈是严格竞争的, 如果有两个玩家, 并且有
$$
u_{1}\left(a_{1}, a_{2}\right) \geqslant u_{1}\left(b_{1}, b_{2}\right) \quad \text { 当且仅当 } \quad u_{2}\left(b_{1}, b_{2}\right) \geqslant u_{2}\left(a_{1}, a_{2}\right)
$$
其中 $\left(a_{1}, a_{2}\right)$ 和 $\left(b_{1}, b_{2}\right)$ 是一对行动;  主要就是这两个人的收益函数是方向相反的.

注意，如果 $u_{1}$ 是描述严格竟争博弈中玩家1偏好的收益函数,那么收益函数$-u_1$ 则描述了玩家2 的偏好。也就是说，在任何严格竟争博弈中,**存在**玩家的收益函数$u_1$ 和 $u_2$,  使得对于任意的行动配置 $\left(a_{1}, a_{2}\right)$ 成立 $u_{1}\left(a_{1}, a_{2}\right)+u_{2}\left(a_{1}, a_{2}\right)=0$ 。出于这个原因, 严格竞争博弈有时叫作"**零和 zerosum**" 博弈。 零和博弈是严格竞争博弈在收益函数为0时的特殊情况. 因为收益函数是序数偏好, 其实 (-1,2) 这种的也是严格竞争的. 但肯定可以设计出sum为0的收益函数.

囚徒困境,BOS都不是严格竞争;  匹配硬币是的. 

下例,  也是严格竞争, 纯策略的时候.  玩家1喜欢(B, R) > (T, L) > (B, L) > (T, R) , 玩家2正好相反. 但考虑混合策略,则不是严格竞争.

<img src="/img/2020-04-18-Game.assets/image-20200509020106893.png" alt="image-20200509020106893" style="zoom:50%;" />



DEFINITION 339.2 (**vNM 偏好的严格竞争策略型博弈 Strictly competitive strategic game with vNM preferences**) 一个具有 vNM 偏好的策略型博弈是严格竞争的，如果它有两个玩家,并且 

$$
U_{1}\left(\alpha_{1}, \alpha_{2}\right) \geqslant U_{1}\left(\beta_{1}, \beta_{2}\right) \quad \text { 当且仅当 } \quad U_{2}\left(\beta_{1}, \beta_{z}\right) \geqslant U_{2}\left(\alpha_{1}, \alpha_{2}\right)
$$

这里，( $\alpha_{1}, \alpha_{2}$ ) 和 $\left(\beta_{1}, \beta_{2}\right)$ 是一对混合策略 ;并且对于 $i=1,2$,  $U_{i}$ 是描述玩家 $i$ 关于随机结局偏好的期望收益函数。

如同具有有序数偏好的博弈那样，在具有 vNM 偏好的严格竞争博弈中， 存在具有如下性质的描述玩家偏好的收益函数:对于每个行动配置，玩家的收益之和等于 0。即，如果$u_1$是伯努利收益函数，它的期望值描述了玩家1关于随机结局的偏好，那么$-u_1$ 就是其期望值描述了玩家2偏好 的伯努利收益函数。

当混合策略时为严格竟争的任何博弈，在限于纯策略时 显然也是严格竞争的,但是反之不成立。例如,考虑图339.1中的博奕，现在将方框内的数字解释为伯努利盈利。玩家1对于如下两种结果感觉没有差别 : 一种是结局 ( $T, L$ ); 另一种是“( $T, R$ ) 以概率 $\frac{3}{5}$ 发生和$(B, R)$以概率$\frac{2}{5}$ "的随机结局, 因为$\frac{3}{5} \cdot 0+\frac{2}{5} \cdot 5=2$,  可是玩家2 对于这两个结局感觉有差异[他关于(T,L)的盈利是 1，而相应于那个随机结局，他的期望盈利是 $\left.\frac{3}{5} \cdot 5+\frac{2}{5} \cdot 0=3\right]$



##### 11.4	Maxminimization and Nash equilibrium in strictly competitive games  严格竞争博弈中的最大最小化与纳什均衡

在任何博弈中，纳什均衡盈利 >= 最大最小化盈利

下面证明，在具有混合策略纳什均衡的严格竞争博弈中，这两个盈利是相同的。事实上有:

在具有混合策略纳什均衡的严格竞争博弈中，一对混合策略配置是混合策略纳什均衡，当且仅当每个玩家的策略是最大最小化解。



PROPOSITION 341.1 (**严格竟争博弈中的纳什均衡策略和最大最小化解**) 考虑具有 vNM 偏好的严格竟争策略型博亲。令$U_1$ 为描述玩家1偏好的期望收益函数,令$U_{2}=-U_{1}$ ,$U_{2}$ 描述玩家2的偏好  
a. 如果 $$ (\alpha_{1}^*, \alpha_{2}^*)$$是混合策略纳什均衡,  那么  $$\alpha_{1}^*$$是玩家1的最大最小化解 , $$\alpha_{2}^*$$是玩家2的最大最小化解, 并且:
$$
\max _{\alpha_{1}} \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)=\min _{\alpha_{2}} \max _{\alpha_{1}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)=U_{1}\left(\alpha_{1}^{*}, \alpha_{2}^{*}\right)
$$

b. 如果$$\max _{\alpha_{1}} \min _{\alpha_{2}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)=\min _{\alpha_{2}} \max _{\alpha_{1}} U_{1}\left(\alpha_{1}, \alpha_{2}\right)$$ , [特别地,如果博弈有一个混合策略纳什均衡,那么 a 条件满足(见 a 部分)], $$\alpha_{1}^*$$ 是玩家1的最大最小化解, $$\alpha_{2}^*$$ 是玩家2的最大最小化解,  那么($$\alpha_{1}^{*}, \alpha_{2}^{*}$$)是混合策略纳什 均衡。



**首先**，结果的a部分意味着在严格竞争博弈中，每个人的混合策略纳什均衡**收益是唯一**的。

COROLLARY  342.1  严格竞争博弈中的每个混合策略纳什均衡产生相同的期望盈利配置。 Every Nash equilibrium of a strictly competitive game yields the same pair of payoffs.

如同我们已经着到的，在非严格竞争博弈中，不是所有的纳什均衡都必然产生相同的收益配置(例,考虑 BoS)



**其次**，假设 $\left(\alpha_{1}, \alpha_{2}\right)$  和 $\left(\alpha_{1}^{\prime}, \alpha_{2}^{\prime}\right)$ 都是严格竞争博弈中的混合策略纳什均衡。 那么由命题341.1 中的a部分可知，策略$\alpha_{1}$ 和$ \alpha_{1}^{\prime}$ 是玩家1 的最大最小化解，$\alpha_{2}$ 和$ \alpha_{2}^{\prime}$ 是玩家2 的最大最小化解。然而由 b部分的结果可知，$\left(\alpha_{1}, \alpha_{2}^{\prime}\right)$和$\left(\alpha_{1}^{\prime}, \alpha_{2}\right)$ 都是博弈的混合策略纳什均衡。也就是说，我扪有下述结果。

如果玩家1有两个套路, 则每个都适用.

COROLLARY 342.2  严格竞争博弈中的混合策略纳什均衡是可以**互换**的: 如果  $\left(\alpha_{1}, \alpha_{2}\right)$ 和$\left(\alpha_{1}^{\prime}, \alpha_{2}^{\prime}\right)$  是混合策略纳什均衡，那么$\left(\alpha_{1}, \alpha_{2}^{\prime}\right)$和$\left(\alpha_{1}^{\prime}, \alpha_{2}\right)$ 也是博弈的混合策略纳什均衡。

博弈 BoS 显示，非严格竞争博弈的纳什均衡不一定可以互换。



**第三**，记严格竞争博弈中玩家 1 的均衡盈利为$$U_1^*$$ ,  命题 341.1 中的 a 部分意味着，玩家1的任何纳什均衡策略确保其盈利至少为$$U_1^*$$，玩家 2 的任何纳什均衡策略确保其收益至少是 $$-U_1^*$$ 。第二个含义是，玩家 2 的任何纳什均衡策略保证玩家1的收益至多为$$U_1^*$$ .

COROLLARY 343.1  在严格竞争博弈中，玩家1的任何纳什均衡策略可以保证他的收益至少是其均衡收益; 玩家2的任何纳什均衡策略可以保证玩家1的收益至多是其均衡收益。 

**均衡收益0和**.





### 12 Rationalizability 理性化



### 13  Evolutionary equilibrium  演化均衡

用博弈论来研究生物演化.

本章中我们描述了基于策略盟博弈的模型。玩家是进化中生物总体 的成员(人类、动物、植物、细菌......) ，彼此相互影响。每个玩家的行动集 由生物体通过变化获得的行为模式组成，它的盈利度量了它的生物学适应性或繁衍能力〈健康后代的期望个数〉。







### 14  Repeated games: The Prisoner’s Dilemma 重复博弈: 囚徒困境

**无名氏定理（Folk Theorem）**即在[重复博弈](https://wiki.mbalib.com/wiki/重复博弈)中，只要博弈人具有足够的耐心（[贴现因子](https://wiki.mbalib.com/wiki/贴现因子)足够大），那么在满足博弈人个人理性约束的前提下，博弈人之间就总有多种可能达成合作均衡。存在无穷多对有限自动机策略，可以成为[无限重复博弈](https://wiki.mbalib.com/wiki/无限重复博弈)的平衡点，并同时实现双方的合作。无名氏定理之所以得名，是由于[重复博弈](https://wiki.mbalib.com/wiki/重复博弈)促进合作的思想，早就有很多人提出，以致无法追溯到其原创者，于是以“无名氏”命名之。



#### 14.1 The main idea 

之前的博弈对应一次性关系;  重复博弈对应 长期关系. 

**理论的主要思想是，玩家可能会因为 "惩罚"的"威胁": 降低自己的长期回报, 而不敢利用自己的短期优势.   要开始考虑长期利益以及什么时候跑路.**    



给定一个基本博弈G (静态博弈或动态博弈)，重复进行T次G，并且在每次重复G时博弈方都
能观察到之前博弈的结果，这样的博弈过程称为“G的T次重复博弈”,记为G(T)。而G则称为G(T)的“原博弈, G(T)中的每次重复称为G(T)的一个“**阶段**”。





例如，假设两个人重复地"玩"囚徒困境, 

<img src="/img/2020-04-18-Game.assets/image-20200509035308686.png" alt="image-20200509035308686" style="zoom:33%;" />

这个策略型博弈有唯一的纳什均衡，其中，每个玩家选择 D;  现在我们来考虑重复博弈中的下述策略，被称为**"冷酷触发策略" *(the* *grim trigger strategy)*** *:*

- 只要另一个玩家选择 C，就一直选择 C 
- 如果在任何周期中，另一个玩家选择 D，那么在以后的每一个周都选择 D。

这个策略从双方合作开始，并且继绩合作下去，直至对方背叛;  对手的一次背叛触发了无情的背叛，我们可以把这解释为对对手的报复性"惩罚" . 如果对手采用这种策略，他应该怎样反应呢? 如果 他在每一个周期选择 C，那么结果是(C, C) ，他在每一周期的盈利为 2。倘若他在某个周期转向 D，那么他在那个周期得到盈利 3(短期的获利) ，并且在以后每一个周期得到盈利1(长期的损失)。只要他赋予未来盈利的值比起他赋予当前盈利的值不会太小，那么对于他来说，盈利系列 (3，1，1，...)比起盈利系列 (2，2，2，...)要糟糕些，因此，他在每一个周期选择 C 比在某个周期转而选择 D ，情况要好得多。

然而，这个"策略对"不是重复博弈中唯一的纳什均衡。另外一个纳什均衡是在每个历史之后每个玩家都选择 D的"策略对":  如果一个玩家采取这个策略，那么另一个玩家只能选D. 



这个分析提出了许多问题:

- 为了重复囚徒困境有每个周期的结局都是 (C，C) 的纳什均衡，确切地，玩家必须有多大耐心?  对未来的预期
- 其他什么结局是由纳什均衡产生的? 
- 在第五章中，展开型博弈的纳什均衡直觉上并不总是吸引人，因为在发生偏离的历史之后，他们指令的行动可能不是最优的。 子博弈完美均衡要求在每个可能的历史之后的策略是最优的，不仅是那些玩家坚持自己的策略而达到的历史，因此这个概念更加吸引 人。每个玩家都使用冷酷触发策略的"策略对"是子博弈完美均衡 吗?也就是说，每个玩家会最优地惩罚其他玩家的偏离吗?如果不会，博弈有支持称心合意结局的子博弈完柴均衡吗?
- 冷酷触发策略规定了相当严厉的报复。是否存在"玩家的策略惩罚偏离不太严厉"的纳什均衡或子博弈完美均衡?
- 论证如何适用于非囚徒困境的博弈?



#### 14.2 Preferences 偏好

##### 14.2.1 Discounting  折扣

对未来预期的数学表达方式.  **discounted sum**  折扣和,**贴现**和;   
有局限性, 偏好不一定是这样的,但能体现重视当下的偏好特征.
$$
u_{i}\left(a^{1}\right)+\delta u_{i}\left(a^{2}\right)+\delta^{2} u_{i}\left(a^{3}\right)+\cdots+\delta^{T-1} u_{i}\left(a^{T}\right)=\sum_{t=1}^{T} \delta^{t-1} u_{i}\left(a^{t}\right)
$$

假设是玩家关于盈利序列$\left(w^{1}, w^{2}, \cdots\right)$的偏好由这些盈利的"贴现和" $\sum_{t=1}^{\infty} \delta^{t-1} w^{t}$ 进行描述,这里 $0<\delta<1$ 。对于任何给定的序列 $\left(w^{1}, w^{2}, \cdots\right)$ 是否存在一个 c 值使得玩家认为收益序列和常数序列 $(c, c, \cdots)$ 之间是**等价**的.  记 $\left(w^{1}, w^{2}, \cdots\right)$  的和为V,  $(c, c, \cdots)$ 的和是$c /(1-\delta)$ , 因此,若 $c=(1-\delta) V$,那么玩家认为这两个序列之间不存在差异。所以被称为**贴现平均值discounted average**. 

准确的说, 贴现平均值为 $(1-\delta) \sum_{i=1}^{\infty} \delta^{i-1} w^{\prime}$ 。 注意,对于任何位于 0 与 1 之间的贴现因子 $\delta$以及任何数 c，常数盈利序列$(c,c,\cdots)$的贴现平均值 $(1-\delta)(c+\delta c+ \delta^2 c+ \dots) =c$。



##### 14.2.2 Equivalent payoff functions 等价收益函数

考虑在不受时间影响的**确定性**结局上的偏好时，我们发现许多收益函数描述了同一个偏好。尤其是，假如 $u$ 是描述决定性结局上的偏好的收益函数，那么  $u$ 的任意递增函数也描述了该偏好. 

当考虑不受时间影响的随机结局的偏好时，发现收益函数的等价性更具有局限性, 如果 $u$ 是一个的伯努利收益函数，它的期望值描述了关于随机结局的偏好，那么每一个期望值描述了他的偏好的其他盈利函数是 $u$ 的递增线性函数 .  (4. 12. 2) 下面证明.

对重复博弈 , 收益是序列的, 考虑等价函数.  如果两个结果序列 $\left(x^{1}, x^{2}, \ldots\right)$ and $\left(y^{1}, y^{2}, \ldots\right)$ 是等价的, 有
$$
\sum_{t=0}^{\infty} \delta^{t-1} u\left(x^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1} u\left(y^{t}\right)
$$
令 $v$  为一个 increasing affine function of $u: v(x)=\alpha+\beta u(x)$ with $\beta>0$ ,  即线性正相关.
$$
\sum_{t=0}^{\infty} \delta^{t-1} v\left(x^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1}\left[\alpha+\beta u\left(x^{t}\right)\right]=\sum_{t=0}^{\infty} \delta^{t-1} \alpha+\beta \sum_{t=0}^{\infty} \delta^{t-1} u\left(x^{t}\right)
$$

$$
\sum_{t=0}^{\infty} \delta^{t-1} v\left(y^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1}\left[\alpha+\beta u\left(y^{t}\right)\right]=\sum_{t=0}^{\infty} \delta^{t-1} \alpha+\beta \sum_{t=0}^{\infty} \delta^{t-1} u\left(y^{t}\right)
$$

则有, 
$$
\sum_{t=0}^{\infty} \delta^{t-1} v\left(x^{t}\right)=\sum_{t=0}^{\infty} \delta^{t-1} v\left(y^{t}\right)
$$


LEMMA 393.1 (**折扣收益函数的等效性Equivalence of payoff functions under discounting**) The discounted sum of payoffs with the **payoff function u** and discount factor δ represents the **same preferences** over streams of payoffs as the discounted sum of payoffs with the **payoff function v** and discount factor δ if and only if there exist α and β > 0 such that u(x) = α + βv(x) for all x.



这个结果的意义在于，对重复博弈的策略型博弈中,  即使结果是deterministic，收益也不再是简单的序数。  例如, 囚徒困境, 将下图中收益表 (0, 3),(0, 3) 换成 (0, 5), (0, 5) , 基于这个得到一个新的囚徒重复博弈, 则这两个重复博弈的玩家偏好是不一样的.   比如，当折扣因子接近于1时，在第一种情况下，每个玩家喜欢结局序列((C, C), (C, C)) 超过((D, C), (C, D))  , 在第二种情况下则不是这样。

<img src="/img/2020-04-18-Game.assets/image-20200509035308686.png" alt="image-20200509035308686" style="zoom:33%;" />



所以, 下面都要用收益函数来定义策略型博弈, 而不是偏好. 



#### 14.3 Infinitely repeated games 无限重复博弈

将一次性的strategic博弈的重复博弈,  看成perfect信息的extensive博弈. 

DEFINITION 394.1   	G , a strategic game.  **The infinitely repeated game** of $G$ for the discount factor $\delta$ is the **extensive game** with **perfect information** and **simultaneous moves** in which
- the set of players is $N$
- the set of terminal histories is the set of **infinite** sequences $\left(a^{1}, a^{2}, \ldots\right)$ of action profiles in $G$
- the player function assigns the set of all players to every proper subhistory of every terminal history
- the set of actions available to player $i$ after any history is $A_{i}$
- each player $i$ evaluates each terminal history $\left(a^{1}, a^{2}, \ldots\right)$ according to its discounted average $(1-\delta) \sum_{t=1}^{\infty} \delta^{t-1} u_{i}\left(a^{t}\right)$



把上面的无限改为T, 则为T周期重复博弈 ;

terminal history 也被 称为 结局路径. 



#### 14.4 Finitely repeated *Prisoner's Dilemma* 有限重复囚徒困境

<img src="/img/2020-04-18-Game.assets/image-20200509035308686.png" alt="image-20200509035308686" style="zoom:33%;" />

考虑囚徒困境的T周期重复博弈。假设对于每一个可能的历史，一个玩家的策略是在每一个周期选D, 那么其他人肯定也选D. 因为其他人选C更差.  因此，(D,D) 的"策略对" 是T 周期的纳什均衡。

每一个纳什均衡产生相同的结局路径. 所以该博弈不能体现本章开始所讨论的思想，即合作的结局, 可以通过对偏离进行惩罚。证明: 在两个人都选择 C 的最后一个周期里，从 C 转 向 D 的偏离**不可能受到惩罚**一一即在以后每一个周期，结局都是 (D，D) 一因此在任何周期中没有一个人会最优地选择 C.    

有限周期, 最后一个周期T是明确早就知道的, 那么绝对占便宜的人肯定会耍花样, 有理由会转向D. 那么一直倒推.   就跟一次性的囚徒困境一样. 对均衡而言, 只能是选D .    这里讨论的是由 纳什均衡 得到的策略. 纳什均衡只是想自己不比别人亏, 不考虑总体收益最大. 



#### 14.5 Infinitely repeated *Prisoner's Dilemma*  无限重复囚徒困境

无限的博弈有这样的结局路径，其中对于每一个人和每一个周期 t，存在一个"玩家的行动是 C"的未来周期，所以通过选择 D 取代 C ，她可以惩罚另一个人在周期 t 的偏离。这个事实启示了，无限重复博弈可能是体现下述想法的一个合适模型: 可以通过"惩罚"策略 使合作得以维系. 

 大多数的相互作用既不会维持一个预定的有限周期数(一个明确的T), 也不会真的无限, 那怎么建模. 那最好就是不知道什么时候结束.  直觉提出，在许多经过很长时期才结束的相互作用里，在终止期没有到来之前，终止期本身对参与者的策略算计几乎不起作用。



#### 14.6  Strategies in an infinitely repeated Prisoner's Dilemma   无限重复囚徒困境中的策略

**grim trigger strategy** 冷酷触发策略
$$
s_{i}(\varnothing)=C \\ 
\ \\
s_{i}\left(a^{1}, \ldots, a^{t}\right)=\left\{\begin{array}{ll}
C & \text { if } a_{j}^{\tau}=C \text { for } \tau=1, \ldots, t \\
D & \text { otherwise }
\end{array}\right.
$$


该策略有两个 **states 状态** : 一个是 $\mathcal{C}$ ,   在该状态选 $C$ ; 另一个是 $\mathcal{D}$ , 选 $D$  . 

用图表示,  如果一个人选D, 则状态改变.

![image-20200513045525223](/img/2020-04-18-Game.assets/image-20200513045525223.png)

下面是个变体, 没有之前那么严厉, 只处罚3个周期

<img src="/img/2020-04-18-Game.assets/image-20200513045724173.png" alt="image-20200513045724173" style="zoom:50%;" />

下面一个变体,   tit-for-tat  针锋相对策略,  一个人在前一个周期做什么, 另外一个人也做什么

<img src="/img/2020-04-18-Game.assets/image-20200513045916224.png" alt="image-20200513045916224" style="zoom:50%;" />



#### 14.7 Some Nash equilibria of an infinitely repeated *Prisoner's Dilemma*  无限囚徒困境中的一些纳什均衡

14.7.1 Grim trigger strategies











### 15 重复博弈：一般性结果



### 16 讨价还价





### 17 Appendix: Mathematics 附录：数学

#### 17.3  Sets

##### **partition 划分**    

A partition of a set $A$ is a collection $$\left\{A_{1}, \ldots, A_{k}\right\}$$ of subsets of $A$ such that every member of $A$ is in exactly one of the sets $A_{j}$. 



设n个元素的集合可以划分为F(n,m)个不同的由m个非空子集组成的集合。  
考虑3个元素的集合，可划分为  

- 1个子集的集合：$$\{\{1，2，3\}\}$$  

- 2个子集的集合：$$\{\{1，2\}，\{3\}\}，\{\{1，3\}，\{2\}\}，\{\{2，3\}，\{1\}\}$$
- 3个子集的集合：$$\{\{1\}，\{2\}，\{3\}\}$$



####  17.4 Functions

affine 仿射函数  f (x) = ax + b

quadratic 二次函数 



#### 17.5 Profiles  配置

For example, players are Ernesto, action is $R,$ and Hilda,  $S$,  function $a$ defined by $a(\text { Ernesto })=R$ and $a(\text { Hilda })=S .$  可以将 $a$ 表示为 $\left(a_{\text {Ernesto }}, a_{\text {Hilda }}\right)=(R, S) $ , 称函数 $a$ 为一个**配置profile**.  

一个常用的配置, 与$\left(a_{1}, \ldots, a_{n}\right)$  不同,因为player $i$ 的动作是 $b_{i}$  , 可以记为$\left(b_{i}, a_{-i}\right)$ ; -i 表示除i以外.   
例如  (a1, a2, a3) = (T, L, M) and b2 = R, for example, then $(b_2, a_{−2}) = (T, R, M)$.





#### 17.8 Proofs

Lemma  引理

Proposition  命题

Corollary  推论






